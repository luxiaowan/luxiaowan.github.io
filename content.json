{"meta":{"title":"串一串","subtitle":"断舍离","description":null,"author":"cc","url":"http://luxiaowan.github.io","root":"/"},"pages":[{"title":"关于本人","date":"2019-10-21T15:26:09.000Z","updated":"2019-10-21T15:28:30.066Z","comments":true,"path":"about/index.html","permalink":"http://luxiaowan.github.io/about/index.html","excerpt":"","text":"串一串 浪人 非常懒，偶尔写一下 文笔很烂，写的不好 凑合看吧"},{"title":"推荐书单","date":"2019-10-21T15:38:29.000Z","updated":"2019-10-21T15:56:47.928Z","comments":true,"path":"books/index.html","permalink":"http://luxiaowan.github.io/books/index.html","excerpt":"","text":"书名 购买地址 JavaScript权威指南（第6版） JavaScript高级程序设计 Java编程思想（第4版） java并发编程实战 Netty权威指南（第2版） Spring Boot实战 Spring微服务实战 Word Excel PPT 2016入门与提高 编程珠玑（第2版） 操作系统真象还原 大型网站系统与Java中间件实践 高性能JavaScript 高性能MySQL（第3版） 机器学习 极简思维 技术运营 人性的弱点 设计模式解析（第2版） 设计模式之禅 深度思维 深入理解Java虚拟机 深入浅出Node.js 深入浅出React和Redux 移动Web前端高效开发实战 亿级流量网站架构核心技术 原则 怎样管精力就怎样过一生 重构改善既有代码的设计 Excel高效办公：数据处理与分析（修订版） 项目管理艺术 周鸿祎自述 我的互联网方法论 奇点临近 高效能人士的七个习惯 三板斧：阿里巴巴管理之道 掘金移动互联：跨境电商如何挑战海外市场 微信思维 系统之美:决策者的系统思考 思考，快与慢 创新者的窘境 微服务设计 Scrum敏捷软件开发 管理的实践"},{"title":"分类","date":"2019-10-21T15:29:38.000Z","updated":"2019-10-21T15:32:44.295Z","comments":true,"path":"categories/index.html","permalink":"http://luxiaowan.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-10-21T15:42:43.000Z","updated":"2019-10-21T15:57:01.607Z","comments":true,"path":"links/index.html","permalink":"http://luxiaowan.github.io/links/index.html","excerpt":"","text":"本人还没友链，孤独小客"},{"title":"个人项目","date":"2019-10-21T15:54:25.000Z","updated":"2019-10-21T15:57:51.353Z","comments":true,"path":"repository/index.html","permalink":"http://luxiaowan.github.io/repository/index.html","excerpt":"","text":"https://github.com/luxiaowan"},{"title":"标签","date":"2019-10-21T15:35:35.000Z","updated":"2019-10-21T15:35:54.071Z","comments":true,"path":"tags/index.html","permalink":"http://luxiaowan.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JVM之OOM","slug":"Java之OOM","date":"2019-11-28T14:23:00.000Z","updated":"2019-12-03T16:02:01.295Z","comments":true,"path":"2019/11/28/Java之OOM/","link":"","permalink":"http://luxiaowan.github.io/2019/11/28/Java之OOM/","excerpt":"","text":"java.lang.StackOverflowError 栈溢出错误，这个错误很容易模拟，且看下面的代码： 1234567891011121314151617public static void main(String[] args) &#123; new StackOverflowTest().test();&#125;private static int high = 0;private void test() &#123; try &#123; ++high; test(); &#125; finally &#123; System.out.println(\"栈的深度为: \" + high); &#125;&#125;---JVM ARGS: -server -Xmn2m -Xss1m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+DoEscapeAnalysis -XX:+EliminateAllocations -XX:-UseTLAB 释 我们都知道方法的调用是通过入栈和计算出栈来实现的，所以我们在方法递归调用一定次数时，必然会发生栈溢出，栈溢出后，程序自动停止，是一类不可补货和恢复的Error类型的错误，所以我们在使用递归算法时，应当注意递归的深度，防止出现栈溢出错误导致服务错误 java.lang.OutOfMemoryError:java heap space JVM堆空间不足引起的内存溢出错误，这类错误比较常见，此处就不做太多的解释，出现这类错误，你就去看GC日志，看看新生代、老年代、永久代/Metaspace的使用情况，如果是想查看GC的情况，使用如下JVM指令： -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:./gclog.log，gc的所有信息都会输出到gclog.log文件中 gclog.log 123456789101112131415161718192021222324252627*JVM信息*Java HotSpot(TM) 64-Bit Server VM (25.161-b12) for bsd-amd64 JRE (1.8.0_161-b12), built on Dec 19 2017 16:22:20 by \"java_re\" with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)Memory: 4k page, physical 16777216k(2991720k free)/proc/meminfo:*JVM ARGS*CommandLine flags: -XX:+DoEscapeAnalysis -XX:+EliminateAllocations -XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:MaxNewSize=2097152 -XX:NewSize=2097152 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:ThreadStackSize=1024 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC -XX:-UseTLAB *GC日志信息*0.125: [GC (Allocation Failure) [PSYoungGen: 1023K-&gt;512K(1536K)] 1023K-&gt;536K(261632K), 0.0010704 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 0.157: [GC (Allocation Failure) [PSYoungGen: 1535K-&gt;493K(1536K)] 1559K-&gt;847K(261632K), 0.0010655 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] ...0.360: [GC (Allocation Failure) [PSYoungGen: 1247K-&gt;256K(1536K)] 2614K-&gt;1727K(261632K), 0.0008285 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap *年轻代* PSYoungGen total 1536K, used 396K [0x00000007bfe00000, 0x00000007c0000000, 0x00000007c0000000) eden space 1024K, 13% used [0x00000007bfe00000,0x00000007bfe23268,0x00000007bff00000) from space 512K, 50% used [0x00000007bff00000,0x00000007bff40000,0x00000007bff80000) to space 512K, 0% used [0x00000007bff80000,0x00000007bff80000,0x00000007c0000000) *老年代* ParOldGen total 260096K, used 1471K [0x00000006c0000000, 0x00000006cfe00000, 0x00000007bfe00000) object space 260096K, 0% used [0x00000006c0000000,0x00000006c016fc00,0x00000006cfe00000) *Metaspace空间，jdk8+* Metaspace used 3402K, capacity 4500K, committed 4864K, reserved 1056768K class space used 368K, capacity 388K, committed 512K, reserved 1048576K 代码 12345678910111213public static void main(String[] args) &#123; new StackOverflowTest().heapSpace();&#125;private void heapSpace() &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new String(\"abc\")); &#125;&#125;--- JVM ARGS: -server -Xmn2m -Xss1m -Xms1m -Xmx1m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:-DoEscapeAnalysis -XX:-EliminateAllocations -XX:-UseTLAB java.lang.OutOfMemoryError:GC overhead limit exceeded 超出了GC开销限制引起的内存溢出，这个错误不是特别常见，Sun 官方对此的定义：超过98%的时间用来做GC并且回收了不到2%的堆内存时会抛出此异常，可以使用参数-XX:-UseGCOverheadLimit 禁用这个检查，但是这个参数解决不了内存问题，只是把错误的信息延后，替换成 java.lang.OutOfMemoryError: Java heap space java.lang.OutOfMemoryError:Metaspace Metaspace内存溢出，Metaspace是jdk8+特有的东西，用来代替之前的PermGen，主要存储class名称、字段、方法、字节码、常量池、JIT优化代码等等，我们可以使用-XX:MetaspaceSize和-XX:MaxMetaspaceSize来指定其大小，一般情况下Metaspace不会发生OOM，Metaspace的使用量与JVM加载的class数量有很大关系： 代码 12345678910111213141516static ClassPool cp = ClassPool.getDefault();public static void main(String[] args) throws CannotCompileException &#123; int i = 0; try &#123; for (;; i++) &#123; Class cz = cp.makeClass(\"com.example.demo.bean.DemoBean\" + i).toClass(); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; System.out.println(i); &#125;&#125;--- JVM ARGS: -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps 输出 1234567891011121314151617181920210.598: [GC (Metadata GC Threshold) [PSYoungGen: 39345K-&gt;10741K(76288K)] 39345K-&gt;15811K(251392K), 0.0111319 secs] [Times: user=0.05 sys=0.01, real=0.01 secs] 0.609: [Full GC (Metadata GC Threshold) [PSYoungGen: 10741K-&gt;0K(76288K)] [ParOldGen: 5069K-&gt;15550K(139776K)] 15811K-&gt;15550K(216064K), [Metaspace: 9735K-&gt;9735K(1056768K)], 0.0504762 secs] [Times: user=0.29 sys=0.01, real=0.05 secs] ...0.754: [GC (Last ditch collection) [PSYoungGen: 0K-&gt;0K(82944K)] 15477K-&gt;15477K(472064K), 0.0008113 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 0.755: [Full GC (Last ditch collection) [PSYoungGen: 0K-&gt;0K(82944K)] [ParOldGen: 15477K-&gt;15477K(607232K)] 15477K-&gt;15477K(690176K), [Metaspace: 9733K-&gt;9733K(1056768K)], 0.0204189 secs] [Times: user=0.08 sys=0.00, real=0.02 secs] 5341Exception in thread \"main\" java.lang.OutOfMemoryError: Metaspace at javassist.ClassPool.toClass(ClassPool.java:1170) at javassist.ClassPool.toClass(ClassPool.java:1113) at javassist.ClassPool.toClass(ClassPool.java:1071) at javassist.CtClass.toClass(CtClass.java:1275) at com.example.demo.jvm.MetaspceOOMTest.main(MetaspceOOMTest.java:13)Heap PSYoungGen total 82944K, used 2390K [0x000000076ab00000, 0x0000000772c00000, 0x00000007c0000000) eden space 82432K, 2% used [0x000000076ab00000,0x000000076ad55ab0,0x000000076fb80000) from space 512K, 0% used [0x0000000772b80000,0x0000000772b80000,0x0000000772c00000) to space 10752K, 0% used [0x0000000771700000,0x0000000771700000,0x0000000772180000) ParOldGen total 607232K, used 15477K [0x00000006c0000000, 0x00000006e5100000, 0x000000076ab00000) object space 607232K, 2% used [0x00000006c0000000,0x00000006c0f1d4c8,0x00000006e5100000) Metaspace used 9770K, capacity 10084K, committed 10240K, reserved 1056768K class space used 3165K, capacity 3214K, committed 3328K, reserved 1048576K 我们将Metaspace的初始大小和最大值都设置为10m，最终i的值大概会在5340左右的时候报OOM，从FGC的日志可以看出，Metaspace在整个GC阶段都未进行任务的内存回收，直至被全部用完，具体的关于Metaspace的介绍可以看下PerfMa社区的这篇文章：https://club.perfma.com/article/210111 java.lang.OutOfMemoryError:Direct buffer memory ByteBuffer. allocateDirect (int capability)是分配操作系统的本地内存，不在GC管辖范围之内，由于不需要内存拷贝所以速度相对较快，但如果不断分配本地内存，堆内存就会很少使用，那么JVM就不需要进行GC，那创建的DirectByteBuffer对象就不会被回收，就会出现堆内存充足但本地内存不足的情况，继续尝试分配本地内存就会出现OOM。 代码 1234567public static void main(String[] args) &#123; System.out.println(\"当前direct大小: \" + (VM.maxDirectMemory() / 1024 / 1024) + \" MB\"); ByteBuffer bb = ByteBuffer.allocateDirect(Math.toIntExact(VM.maxDirectMemory() + 10));&#125;--- JVM ARGS: -XX:MaxDirectMemorySize=10m 这里我们需要通过JVM参数-XX:MaxDirectMemorySize=10将JVM本地最大使用内存设置为10MB，不然如果你本地剩余内存很大，那么就很难模拟出此错误 输出 123456当前direct大小: 10 MBException in thread \"main\" java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:694) at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311) at com.example.demo.jvm.DirectBufferOOMTest.main(DirectBufferOOMTest.java:11) java.lang.OutOfMemoryError:unable create new native thread 线程创建的太多，导致无法继续创建线程，出现这个问题就要去使用jstack导出线程栈查看具体情况 代码 12345678910111213public static void main(String[] args) &#123; while (true) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(100000); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125;).start(); &#125;&#125; 这一段代码必然会出现该ERROR，不论你的机器有多牛掰，你会发现出现了OOM之后，进程并未终止，这个时候你可以用jps命令查看进程号，然后使用jstack pid查看线程栈，会发现有非常多的线程处于TIMED_WAITING (sleeping)状态： 12345\"Thread-256\" #267 prio=5 os_prio=31 tid=0x00007fccdd8cc000 nid=0x27d03 waiting on condition [0x0000700019b85000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.example.demo.jvm.NativeThreadOOMTest$1.run(NativeThreadOOMTest.java:11) at java.lang.Thread.run(Thread.java:748)","categories":[{"name":"Java","slug":"Java","permalink":"http://luxiaowan.github.io/categories/Java/"}],"tags":[]},{"title":"SpringBoot官方配置文档(英文版)","slug":"SpringBoot官方配置文档(英文版)","date":"2019-11-22T17:13:00.000Z","updated":"2019-11-25T17:18:31.849Z","comments":true,"path":"2019/11/23/SpringBoot官方配置文档(英文版)/","link":"","permalink":"http://luxiaowan.github.io/2019/11/23/SpringBoot官方配置文档(英文版)/","excerpt":"","text":"BANNER banner.charset=UTF-8 # Banner file encoding. banner.location=classpath:banner.txt # Banner file location. banner.image.location=classpath:banner.gif # Banner image file location (jpg/png can also be used). banner.image.width= # Width of the banner image in chars (default 76) banner.image.height= # Height of the banner image in chars (default based on image height) banner.image.margin= # Left hand image margin in chars (default 2) banner.image.invert= # If images should be inverted for dark terminal themes (default false) LOGGING logging.config= # Location of the logging configuration file. For instance classpath:logback.xml for Logback logging.exception-conversion-word=%wEx # Conversion word used when logging exceptions. logging.file= # Log file name. For instance myapp.log logging.level.*= # Log levels severity mapping. For instance logging.level.org.springframework=DEBUG logging.path= # Location of the log file. For instance /var/log logging.pattern.console= # Appender pattern for output to the console. Only supported with the default logback setup. logging.pattern.file= # Appender pattern for output to the file. Only supported with the default logback setup. logging.pattern.level= # Appender pattern for log level (default %5p). Only supported with the default logback setup. logging.register-shutdown-hook=false # Register a shutdown hook for the logging system when it is initialized. AOP spring.aop.auto=true # Add @EnableAspectJAutoProxy. spring.aop.proxy-target-class=true # Whether subclass-based (CGLIB) proxies are to be created (true) as opposed to standard Java interface-based proxies (false). IDENTITY (ContextIdApplicationContextInitializer) spring.application.index= # Application index. spring.application.name= # Application name. ADMIN (SpringApplicationAdminJmxAutoConfiguration) spring.application.admin.enabled=false # Enable admin features for the application. spring.application.admin.jmx-name=org.springframework.boot:type=Admin,name=SpringApplication # JMX name of the application admin MBean. AUTO-CONFIGURATION spring.autoconfigure.exclude= # Auto-configuration classes to exclude. SPRING CORE spring.beaninfo.ignore=true # Skip search of BeanInfo classes. SPRING CACHE (CacheProperties) spring.cache.cache-names= # Comma-separated list of cache names to create if supported by the underlying cache manager. spring.cache.caffeine.spec= # The spec to use to create caches. Check CaffeineSpec for more details on the spec format. spring.cache.couchbase.expiration=0 # Entry expiration in milliseconds. By default the entries never expire. spring.cache.ehcache.config= # The location of the configuration file to use to initialize EhCache. spring.cache.infinispan.config= # The location of the configuration file to use to initialize Infinispan. spring.cache.jcache.config= # The location of the configuration file to use to initialize the cache manager. spring.cache.jcache.provider= # Fully qualified name of the CachingProvider implementation to use to retrieve the JSR-107 compliant cache manager. Only needed if more than one JSR-107 implementation is available on the classpath. spring.cache.type= # Cache type, auto-detected according to the environment by default. SPRING CONFIG - using environment property only (ConfigFileApplicationListener) spring.config.location= # Config file locations. spring.config.name=application # Config file name. HAZELCAST (HazelcastProperties) spring.hazelcast.config= # The location of the configuration file to use to initialize Hazelcast. PROJECT INFORMATION (ProjectInfoProperties) spring.info.build.location=classpath:META-INF/build-info.properties # Location of the generated build-info.properties file. spring.info.git.location=classpath:git.properties # Location of the generated git.properties file. JMX spring.jmx.default-domain= # JMX domain name. spring.jmx.enabled=true # Expose management beans to the JMX domain. spring.jmx.server=mbeanServer # MBeanServer bean name. Email (MailProperties) spring.mail.default-encoding=UTF-8 # Default MimeMessage encoding. spring.mail.host= # SMTP server host. For instance smtp.example.com spring.mail.jndi-name= # Session JNDI name. When set, takes precedence to others mail settings. spring.mail.password= # Login password of the SMTP server. spring.mail.port= # SMTP server port. spring.mail.properties.*= # Additional JavaMail session properties. spring.mail.protocol=smtp # Protocol used by the SMTP server. spring.mail.test-connection=false # Test that the mail server is available on startup. spring.mail.username= # Login user of the SMTP server. APPLICATION SETTINGS (SpringApplication) spring.main.banner-mode=console # Mode used to display the banner when the application runs. spring.main.sources= # Sources (class name, package name or XML resource location) to include in the ApplicationContext. spring.main.web-application-type= # Flag to explicitly request a specific type of web application. Auto-detected based on the classpath if not set. FILE ENCODING (FileEncodingApplicationListener) spring.mandatory-file-encoding= # Expected character encoding the application must use. INTERNATIONALIZATION (MessageSourceAutoConfiguration) spring.messages.always-use-message-format=false # Set whether to always apply the MessageFormat rules, parsing even messages without arguments. spring.messages.basename=messages # Comma-separated list of basenames, each following the ResourceBundle convention. spring.messages.cache-seconds=-1 # Loaded resource bundle files cache expiration, in seconds. When set to -1, bundles are cached forever. spring.messages.encoding=UTF-8 # Message bundles encoding. spring.messages.fallback-to-system-locale=true # Set whether to fall back to the system Locale if no files for a specific Locale have been found. OUTPUT spring.output.ansi.enabled=detect # Configure the ANSI output. PID FILE (ApplicationPidFileWriter) spring.pid.fail-on-write-error= # Fail if ApplicationPidFileWriter is used but it cannot write the PID file. spring.pid.file= # Location of the PID file to write (if ApplicationPidFileWriter is used). PROFILES spring.profiles.active= # Comma-separated list (or list if using YAML) of active profiles. spring.profiles.include= # Unconditionally activate the specified comma separated profiles (or list of profiles if using YAML). Reactor spring.reactor.stacktrace-mode.enabled=false # Set whether Reactor should collect stacktrace information at runtime. SENDGRID (SendGridAutoConfiguration) spring.sendgrid.api-key= # SendGrid api key (alternative to username/password) spring.sendgrid.proxy.host= # SendGrid proxy host spring.sendgrid.proxy.port= # SendGrid proxy port EMBEDDED SERVER CONFIGURATION (ServerProperties) server.address= # Network address to which the server should bind to. server.compression.enabled=false # If response compression is enabled. server.compression.excluded-user-agents= # List of user-agents to exclude from compression. server.compression.mime-types= # Comma-separated list of MIME types that should be compressed. For instance text/html,text/css,application/json server.compression.min-response-size= # Minimum response size that is required for compression to be performed. For instance 2048 server.connection-timeout= # Time in milliseconds that connectors will wait for another HTTP request before closing the connection. When not set, the connector’s container-specific default will be used. Use a value of -1 to indicate no (i.e. infinite) timeout. server.display-name=application # Display name of the application. server.max-http-header-size=0 # Maximum size in bytes of the HTTP message header. server.error.include-exception=false # Include the “exception” attribute. server.error.include-stacktrace=never # When to include a “stacktrace” attribute. server.error.path=/error # Path of the error controller. server.error.whitelabel.enabled=true # Enable the default error page displayed in browsers in case of a server error. server.jetty.acceptors= # Number of acceptor threads to use. server.jetty.accesslog.append=false # Append to log. server.jetty.accesslog.date-format=dd/MMM/yyyy:HH:mm:ss Z # Timestamp format of the request log. server.jetty.accesslog.enabled=false # Enable access log. server.jetty.accesslog.extended-format=false # Enable extended NCSA format. server.jetty.accesslog.file-date-format= # Date format to place in log file name. server.jetty.accesslog.filename= # Log filename. If not specified, logs will be redirected to “System.err”. server.jetty.accesslog.locale= # Locale of the request log. server.jetty.accesslog.log-cookies=false # Enable logging of the request cookies. server.jetty.accesslog.log-latency=false # Enable logging of request processing time. server.jetty.accesslog.log-server=false # Enable logging of the request hostname. server.jetty.accesslog.retention-period=31 # Number of days before rotated log files are deleted. server.jetty.accesslog.time-zone=GMT # Timezone of the request log. server.jetty.max-http-post-size=0 # Maximum size in bytes of the HTTP post or put content. server.jetty.selectors= # Number of selector threads to use. server.port=8080 # Server HTTP port. server.server-header= # Value to use for the Server response header (no header is sent if empty) server.use-forward-headers= # If X-Forwarded-* headers should be applied to the HttpRequest. server.servlet.context-parameters.= # Servlet context init parameters server.servlet.context-path= # Context path of the application. server.servlet.jsp.class-name=org.apache.jasper.servlet.JspServlet # The class name of the JSP servlet. server.servlet.jsp.init-parameters.= # Init parameters used to configure the JSP servlet server.servlet.jsp.registered=true # Whether or not the JSP servlet is registered server.servlet.path=/ # Path of the main dispatcher servlet. server.session.cookie.comment= # Comment for the session cookie. server.session.cookie.domain= # Domain for the session cookie. server.session.cookie.http-only= # “HttpOnly” flag for the session cookie. server.session.cookie.max-age= # Maximum age of the session cookie in seconds. server.session.cookie.name= # Session cookie name. server.session.cookie.path= # Path of the session cookie. server.session.cookie.secure= # “Secure” flag for the session cookie. server.session.persistent=false # Persist session data between restarts. server.session.store-dir= # Directory used to store session data. server.session.timeout= # Session timeout in seconds. server.session.tracking-modes= # Session tracking modes (one or more of the following: “cookie”, “url”, “ssl”). server.ssl.ciphers= # Supported SSL ciphers. server.ssl.client-auth= # Whether client authentication is wanted (“want”) or needed (“need”). Requires a trust store. server.ssl.enabled= # Enable SSL support. server.ssl.enabled-protocols= # Enabled SSL protocols. server.ssl.key-alias= # Alias that identifies the key in the key store. server.ssl.key-password= # Password used to access the key in the key store. server.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file). server.ssl.key-store-password= # Password used to access the key store. server.ssl.key-store-provider= # Provider for the key store. server.ssl.key-store-type= # Type of the key store. server.ssl.protocol=TLS # SSL protocol to use. server.ssl.trust-store= # Trust store that holds SSL certificates. server.ssl.trust-store-password= # Password used to access the trust store. server.ssl.trust-store-provider= # Provider for the trust store. server.ssl.trust-store-type= # Type of the trust store. server.tomcat.accept-count= # Maximum queue length for incoming connection requests when all possible request processing threads are in use. server.tomcat.accesslog.buffered=true # Buffer output such that it is only flushed periodically. server.tomcat.accesslog.directory=logs # Directory in which log files are created. Can be relative to the tomcat base dir or absolute. server.tomcat.accesslog.enabled=false # Enable access log. server.tomcat.accesslog.file-date-format=.yyyy-MM-dd # Date format to place in log file name. server.tomcat.accesslog.pattern=common # Format pattern for access logs. server.tomcat.accesslog.prefix=access_log # Log file name prefix. server.tomcat.accesslog.rename-on-rotate=false # Defer inclusion of the date stamp in the file name until rotate time. server.tomcat.accesslog.request-attributes-enabled=false # Set request attributes for IP address, Hostname, protocol and port used for the request. server.tomcat.accesslog.rotate=true # Enable access log rotation. server.tomcat.accesslog.suffix=.log # Log file name suffix. server.tomcat.additional-tld-skip-patterns= # Comma-separated list of additional patterns that match jars to ignore for TLD scanning. server.tomcat.background-processor-delay=30 # Delay in seconds between the invocation of backgroundProcess methods. server.tomcat.basedir= # Tomcat base directory. If not specified a temporary directory will be used. server.tomcat.internal-proxies=10\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}|\\ 192\\.168\\.\\d{1,3}\\.\\d{1,3}|\\ 169\\.254\\.\\d{1,3}\\.\\d{1,3}|\\ 127\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}|\\ 172\\.1[6-9]{1}\\.\\d{1,3}\\.\\d{1,3}|\\ 172\\.2[0-9]{1}\\.\\d{1,3}\\.\\d{1,3}|\\ 172\\.3[0-1]{1}\\.\\d{1,3}\\.\\d{1,3} # regular expression matching trusted IP addresses. server.tomcat.max-connections= # Maximum number of connections that the server will accept and process at any given time. server.tomcat.max-http-header-size=0 # Maximum size in bytes of the HTTP message header. server.tomcat.max-http-post-size=0 # Maximum size in bytes of the HTTP post content. server.tomcat.max-threads=0 # Maximum amount of worker threads. server.tomcat.min-spare-threads=0 # Minimum amount of worker threads. server.tomcat.port-header=X-Forwarded-Port # Name of the HTTP header used to override the original port value. server.tomcat.protocol-header= # Header that holds the incoming protocol, usually named “X-Forwarded-Proto”. server.tomcat.protocol-header-https-value=https # Value of the protocol header that indicates that the incoming request uses SSL. server.tomcat.redirect-context-root= # Whether requests to the context root should be redirected by appending a / to the path. server.tomcat.remote-ip-header= # Name of the http header from which the remote ip is extracted. For instance X-FORWARDED-FOR server.tomcat.uri-encoding=UTF-8 # Character encoding to use to decode the URI. server.undertow.accesslog.dir= # Undertow access log directory. server.undertow.accesslog.enabled=false # Enable access log. server.undertow.accesslog.pattern=common # Format pattern for access logs. server.undertow.accesslog.prefix=access_log. # Log file name prefix. server.undertow.accesslog.rotate=true # Enable access log rotation. server.undertow.accesslog.suffix=log # Log file name suffix. server.undertow.buffer-size= # Size of each buffer in bytes. server.undertow.direct-buffers= # Allocate buffers outside the Java heap. server.undertow.io-threads= # Number of I/O threads to create for the worker. server.undertow.eager-filter-init=true # Whether servlet filters should be initialized on startup. server.undertow.max-http-post-size=0 # Maximum size in bytes of the HTTP post content. server.undertow.worker-threads= # Number of worker threads. FREEMARKER (FreeMarkerAutoConfiguration) spring.freemarker.allow-request-override=false # Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name. spring.freemarker.allow-session-override=false # Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name. spring.freemarker.cache=false # Enable template caching. spring.freemarker.charset=UTF-8 # Template encoding. spring.freemarker.check-template-location=true # Check that the templates location exists. spring.freemarker.content-type=text/html # Content-Type value. spring.freemarker.enabled=true # Enable MVC view resolution for this technology. spring.freemarker.expose-request-attributes=false # Set whether all request attributes should be added to the model prior to merging with the template. spring.freemarker.expose-session-attributes=false # Set whether all HttpSession attributes should be added to the model prior to merging with the template. spring.freemarker.expose-spring-macro-helpers=true # Set whether to expose a RequestContext for use by Spring’s macro library, under the name “springMacroRequestContext”. spring.freemarker.prefer-file-system-access=true # Prefer file system access for template loading. File system access enables hot detection of template changes. spring.freemarker.prefix= # Prefix that gets prepended to view names when building a URL. spring.freemarker.request-context-attribute= # Name of the RequestContext attribute for all views. spring.freemarker.settings.*= # Well-known FreeMarker keys which will be passed to FreeMarker’s Configuration. spring.freemarker.suffix= # Suffix that gets appended to view names when building a URL. spring.freemarker.template-loader-path=classpath:/templates/ # Comma-separated list of template paths. spring.freemarker.view-names= # White list of view names that can be resolved. GROOVY TEMPLATES (GroovyTemplateAutoConfiguration) spring.groovy.template.allow-request-override=false # Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name. spring.groovy.template.allow-session-override=false # Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name. spring.groovy.template.cache= # Enable template caching. spring.groovy.template.charset=UTF-8 # Template encoding. spring.groovy.template.check-template-location=true # Check that the templates location exists. spring.groovy.template.configuration.*= # See GroovyMarkupConfigurer spring.groovy.template.content-type=test/html # Content-Type value. spring.groovy.template.enabled=true # Enable MVC view resolution for this technology. spring.groovy.template.expose-request-attributes=false # Set whether all request attributes should be added to the model prior to merging with the template. spring.groovy.template.expose-session-attributes=false # Set whether all HttpSession attributes should be added to the model prior to merging with the template. spring.groovy.template.expose-spring-macro-helpers=true # Set whether to expose a RequestContext for use by Spring’s macro library, under the name “springMacroRequestContext”. spring.groovy.template.prefix= # Prefix that gets prepended to view names when building a URL. spring.groovy.template.request-context-attribute= # Name of the RequestContext attribute for all views. spring.groovy.template.resource-loader-path=classpath:/templates/ # Template path. spring.groovy.template.suffix=.tpl # Suffix that gets appended to view names when building a URL. spring.groovy.template.view-names= # White list of view names that can be resolved. SPRING HATEOAS (HateoasProperties) spring.hateoas.use-hal-as-default-json-media-type=true # Specify if application/hal+json responses should be sent to requests that accept application/json. HTTP message conversion spring.http.converters.preferred-json-mapper=jackson # Preferred JSON mapper to use for HTTP message conversion. Set to “gson” to force the use of Gson when both it and Jackson are on the classpath. HTTP encoding (HttpEncodingProperties) spring.http.encoding.charset=UTF-8 # Charset of HTTP requests and responses. Added to the “Content-Type” header if not set explicitly. spring.http.encoding.enabled=true # Enable http encoding support. spring.http.encoding.force= # Force the encoding to the configured charset on HTTP requests and responses. spring.http.encoding.force-request= # Force the encoding to the configured charset on HTTP requests. Defaults to true when “force” has not been specified. spring.http.encoding.force-response= # Force the encoding to the configured charset on HTTP responses. spring.http.encoding.mapping= # Locale to Encoding mapping. MULTIPART (MultipartProperties) spring.servlet.multipart.enabled=true # Enable support of multipart uploads. spring.servlet.multipart.file-size-threshold=0 # Threshold after which files will be written to disk. Values can use the suffixes “MB” or “KB” to indicate megabytes or kilobytes respectively. spring.servlet.multipart.location= # Intermediate location of uploaded files. spring.servlet.multipart.max-file-size=1MB # Max file size. Values can use the suffixes “MB” or “KB” to indicate megabytes or kilobytes respectively. spring.servlet.multipart.max-request-size=10MB # Max request size. Values can use the suffixes “MB” or “KB” to indicate megabytes or kilobytes respectively. spring.servlet.multipart.resolve-lazily=false # Whether to resolve the multipart request lazily at the time of file or parameter access. JACKSON (JacksonProperties) spring.jackson.date-format= # Date format string or a fully-qualified date format class name. For instance yyyy-MM-dd HH:mm:ss. spring.jackson.default-property-inclusion= # Controls the inclusion of properties during serialization. spring.jackson.deserialization.= # Jackson on/off features that affect the way Java objects are deserialized. spring.jackson.generator.= # Jackson on/off features for generators. spring.jackson.joda-date-time-format= # Joda date time format string. If not configured, “date-format” will be used as a fallback if it is configured with a format string. spring.jackson.locale= # Locale used for formatting. spring.jackson.mapper.= # Jackson general purpose on/off features. spring.jackson.parser.= # Jackson on/off features for parsers. spring.jackson.property-naming-strategy= # One of the constants on Jackson’s PropertyNamingStrategy. Can also be a fully-qualified class name of a PropertyNamingStrategy subclass. spring.jackson.serialization.*= # Jackson on/off features that affect the way Java objects are serialized. spring.jackson.time-zone= # Time zone used when formatting dates. For instance America/Los_Angeles JERSEY (JerseyProperties) spring.jersey.application-path= # Path that serves as the base URI for the application. Overrides the value of “@ApplicationPath” if specified. spring.jersey.filter.order=0 # Jersey filter chain order. spring.jersey.init.*= # Init parameters to pass to Jersey via the servlet or filter. spring.jersey.servlet.load-on-startup=-1 # Load on startup priority of the Jersey servlet. spring.jersey.type=servlet # Jersey integration type. SPRING LDAP (LdapProperties) spring.ldap.urls= # LDAP URLs of the server. spring.ldap.base= # Base suffix from which all operations should originate. spring.ldap.username= # Login user of the server. spring.ldap.password= # Login password of the server. spring.ldap.base-environment.*= # LDAP specification settings. EMBEDDED LDAP (EmbeddedLdapProperties) spring.ldap.embedded.base-dn= # The base DN spring.ldap.embedded.credential.username= # Embedded LDAP username. spring.ldap.embedded.credential.password= # Embedded LDAP password. spring.ldap.embedded.ldif=classpath:schema.ldif # Schema (LDIF) script resource reference. spring.ldap.embedded.port= # Embedded LDAP port. spring.ldap.embedded.validation.enabled=true # Enable LDAP schema validation. spring.ldap.embedded.validation.schema= # Path to the custom schema. SPRING MOBILE DEVICE VIEWS (DeviceDelegatingViewResolverAutoConfiguration) spring.mobile.devicedelegatingviewresolver.enable-fallback=false # Enable support for fallback resolution. spring.mobile.devicedelegatingviewresolver.enabled=false # Enable device view resolver. spring.mobile.devicedelegatingviewresolver.mobile-prefix=mobile/ # Prefix that gets prepended to view names for mobile devices. spring.mobile.devicedelegatingviewresolver.mobile-suffix= # Suffix that gets appended to view names for mobile devices. spring.mobile.devicedelegatingviewresolver.normal-prefix= # Prefix that gets prepended to view names for normal devices. spring.mobile.devicedelegatingviewresolver.normal-suffix= # Suffix that gets appended to view names for normal devices. spring.mobile.devicedelegatingviewresolver.tablet-prefix=tablet/ # Prefix that gets prepended to view names for tablet devices. spring.mobile.devicedelegatingviewresolver.tablet-suffix= # Suffix that gets appended to view names for tablet devices. SPRING MOBILE SITE PREFERENCE (SitePreferenceAutoConfiguration) spring.mobile.sitepreference.enabled=true # Enable SitePreferenceHandler. MUSTACHE TEMPLATES (MustacheAutoConfiguration) spring.mustache.allow-request-override= # Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name. spring.mustache.allow-session-override= # Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name. spring.mustache.cache= # Enable template caching. spring.mustache.charset= # Template encoding. spring.mustache.check-template-location= # Check that the templates location exists. spring.mustache.content-type= # Content-Type value. spring.mustache.enabled= # Enable MVC view resolution for this technology. spring.mustache.expose-request-attributes= # Set whether all request attributes should be added to the model prior to merging with the template. spring.mustache.expose-session-attributes= # Set whether all HttpSession attributes should be added to the model prior to merging with the template. spring.mustache.expose-spring-macro-helpers= # Set whether to expose a RequestContext for use by Spring’s macro library, under the name “springMacroRequestContext”. spring.mustache.prefix=classpath:/templates/ # Prefix to apply to template names. spring.mustache.request-context-attribute= # Name of the RequestContext attribute for all views. spring.mustache.suffix=.mustache # Suffix to apply to template names. spring.mustache.view-names= # White list of view names that can be resolved. SPRING MVC (WebMvcProperties) spring.mvc.async.request-timeout= # Amount of time (in milliseconds) before asynchronous request handling times out. spring.mvc.date-format= # Date format to use. For instance dd/MM/yyyy. spring.mvc.dispatch-trace-request=false # Dispatch TRACE requests to the FrameworkServlet doService method. spring.mvc.dispatch-options-request=true # Dispatch OPTIONS requests to the FrameworkServlet doService method. spring.mvc.favicon.enabled=true # Enable resolution of favicon.ico. spring.mvc.formcontent.putfilter.enabled=true # Enable Spring’s HttpPutFormContentFilter. spring.mvc.ignore-default-model-on-redirect=true # If the content of the “default” model should be ignored during redirect scenarios. spring.mvc.locale= # Locale to use. By default, this locale is overridden by the “Accept-Language” header. spring.mvc.locale-resolver=accept-header # Define how the locale should be resolved. spring.mvc.log-resolved-exception=false # Enable warn logging of exceptions resolved by a “HandlerExceptionResolver”. spring.mvc.media-types.*= # Maps file extensions to media types for content negotiation. spring.mvc.message-codes-resolver-format= # Formatting strategy for message codes. For instance PREFIX_ERROR_CODE. spring.mvc.servlet.load-on-startup=-1 # Load on startup priority of the Spring Web Services servlet. spring.mvc.static-path-pattern=/** # Path pattern used for static resources. spring.mvc.throw-exception-if-no-handler-found=false # If a “NoHandlerFoundException” should be thrown if no Handler was found to process a request. spring.mvc.view.prefix= # Spring MVC view prefix. spring.mvc.view.suffix= # Spring MVC view suffix. SPRING RESOURCES HANDLING (ResourceProperties) spring.resources.add-mappings=true # Enable default resource handling. spring.resources.cache-period= # Cache period for the resources served by the resource handler, in seconds. spring.resources.chain.cache=true # Enable caching in the Resource chain. spring.resources.chain.enabled= # Enable the Spring Resource Handling chain. Disabled by default unless at least one strategy has been enabled. spring.resources.chain.gzipped=false # Enable resolution of already gzipped resources. spring.resources.chain.html-application-cache=false # Enable HTML5 application cache manifest rewriting. spring.resources.chain.strategy.content.enabled=false # Enable the content Version Strategy. spring.resources.chain.strategy.content.paths=/** # Comma-separated list of patterns to apply to the Version Strategy. spring.resources.chain.strategy.fixed.enabled=false # Enable the fixed Version Strategy. spring.resources.chain.strategy.fixed.paths=/** # Comma-separated list of patterns to apply to the Version Strategy. spring.resources.chain.strategy.fixed.version= # Version string to use for the Version Strategy. spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/ # Locations of static resources. SPRING SESSION (SessionProperties) spring.session.hazelcast.flush-mode=on-save # Sessions flush mode. spring.session.hazelcast.map-name=spring:session:sessions # Name of the map used to store sessions. spring.session.jdbc.initializer.enabled= # Create the required session tables on startup if necessary. Enabled automatically if the default table name is set or a custom schema is configured. spring.session.jdbc.schema=classpath:org/springframework/session/jdbc/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema. spring.session.jdbc.table-name=SPRING_SESSION # Name of database table used to store sessions. spring.session.redis.flush-mode=on-save # Sessions flush mode. spring.session.redis.namespace= # Namespace for keys used to store sessions. spring.session.store-type= # Session store type. SPRING SOCIAL (SocialWebAutoConfiguration) spring.social.auto-connection-views=false # Enable the connection status view for supported providers. SPRING SOCIAL FACEBOOK (FacebookAutoConfiguration) spring.social.facebook.app-id= # your application’s Facebook App ID spring.social.facebook.app-secret= # your application’s Facebook App Secret SPRING SOCIAL LINKEDIN (LinkedInAutoConfiguration) spring.social.linkedin.app-id= # your application’s LinkedIn App ID spring.social.linkedin.app-secret= # your application’s LinkedIn App Secret SPRING SOCIAL TWITTER (TwitterAutoConfiguration) spring.social.twitter.app-id= # your application’s Twitter App ID spring.social.twitter.app-secret= # your application’s Twitter App Secret THYMELEAF (ThymeleafAutoConfiguration) spring.thymeleaf.cache=true # Enable template caching. spring.thymeleaf.check-template=true # Check that the template exists before rendering it. spring.thymeleaf.check-template-location=true # Check that the templates location exists. spring.thymeleaf.enabled=true # Enable Thymeleaf view resolution for Web frameworks. spring.thymeleaf.encoding=UTF-8 # Template files encoding. spring.thymeleaf.excluded-view-names= # Comma-separated list of view names that should be excluded from resolution. spring.thymeleaf.mode=HTML5 # Template mode to be applied to templates. See also StandardTemplateModeHandlers. spring.thymeleaf.prefix=classpath:/templates/ # Prefix that gets prepended to view names when building a URL. spring.thymeleaf.reactive.max-chunk-size= # Maximum size of data buffers used for writing to the response, in bytes. spring.thymeleaf.reactive.media-types= # Media types supported by the view technology. spring.thymeleaf.servlet.content-type=text/html # Content-Type value written to HTTP responses. spring.thymeleaf.suffix=.html # Suffix that gets appended to view names when building a URL. spring.thymeleaf.template-resolver-order= # Order of the template resolver in the chain. spring.thymeleaf.view-names= # Comma-separated list of view names that can be resolved. SPRING WEB FLUX (WebFluxProperties) spring.webflux.static-path-pattern=/** # Path pattern used for static resources. SPRING WEB SERVICES (WebServicesProperties) spring.webservices.path=/services # Path that serves as the base URI for the services. spring.webservices.servlet.init= # Servlet init parameters to pass to Spring Web Services. spring.webservices.servlet.load-on-startup=-1 # Load on startup priority of the Spring Web Services servlet. SECURITY (SecurityProperties) security.basic.authorize-mode=role # Security authorize mode to apply. security.basic.enabled=true # Enable basic authentication. security.basic.path=/** # Comma-separated list of paths to secure. security.basic.realm=Spring # HTTP basic realm name. security.enable-csrf=false # Enable Cross Site Request Forgery support. security.filter-order=0 # Security filter chain order. security.filter-dispatcher-types=ASYNC, FORWARD, INCLUDE, REQUEST # Security filter chain dispatcher types. security.headers.cache=true # Enable cache control HTTP headers. security.headers.content-security-policy= # Value for content security policy header. security.headers.content-security-policy-mode=default # Content security policy mode. security.headers.content-type=true # Enable “X-Content-Type-Options” header. security.headers.frame=true # Enable “X-Frame-Options” header. security.headers.hsts=all # HTTP Strict Transport Security (HSTS) mode (none, domain, all). security.headers.xss=true # Enable cross site scripting (XSS) protection. security.ignored= # Comma-separated list of paths to exclude from the default secured paths. security.require-ssl=false # Enable secure channel for all requests. security.sessions=stateless # Session creation policy (always, never, if_required, stateless). security.user.name=user # Default user name. security.user.password= # Password for the default user name. A random password is logged on startup by default. security.user.role=USER # Granted roles for the default user name. SECURITY OAUTH2 CLIENT (OAuth2ClientProperties) security.oauth2.client.client-id= # OAuth2 client id. security.oauth2.client.client-secret= # OAuth2 client secret. A random secret is generated by default SECURITY OAUTH2 RESOURCES (ResourceServerProperties) security.oauth2.resource.filter-order= # The order of the filter chain used to authenticate tokens. security.oauth2.resource.id= # Identifier of the resource. security.oauth2.resource.jwt.key-uri= # The URI of the JWT token. Can be set if the value is not available and the key is public. security.oauth2.resource.jwt.key-value= # The verification key of the JWT token. Can either be a symmetric secret or PEM-encoded RSA public key. security.oauth2.resource.prefer-token-info=true # Use the token info, can be set to false to use the user info. security.oauth2.resource.service-id=resource # security.oauth2.resource.token-info-uri= # URI of the token decoding endpoint. security.oauth2.resource.token-type= # The token type to send when using the userInfoUri. security.oauth2.resource.user-info-uri= # URI of the user endpoint. SECURITY OAUTH2 SSO (OAuth2SsoProperties) security.oauth2.sso.filter-order= # Filter order to apply if not providing an explicit WebSecurityConfigurerAdapter security.oauth2.sso.login-path=/login # Path to the login page, i.e. the one that triggers the redirect to the OAuth2 Authorization Server FLYWAY (FlywayProperties) flyway.allow-mixed-migrations= # flyway.baseline-description= # flyway.baseline-on-migrate= # flyway.baseline-version=1 # version to start migration flyway.check-location=false # Check that migration scripts location exists. flyway.clean-disabled= # flyway.clean-on-validation-error= # flyway.enabled=true # Enable flyway. flyway.encoding= # flyway.ignore-failed-future-migration= # flyway.ignore-future-migrations= # flyway.ignore-missing-migrations= # flyway.init-sqls= # SQL statements to execute to initialize a connection immediately after obtaining it. flyway.installed-by= # flyway.locations=classpath:db/migration # locations of migrations scripts flyway.out-of-order= # flyway.password= # JDBC password if you want Flyway to create its own DataSource flyway.placeholder-prefix= # flyway.placeholder-replacement= # flyway.placeholder-suffix= # flyway.placeholders.*= # flyway.repeatable-sql-migration-prefix= # flyway.schemas= # schemas to update flyway.skip-default-callbacks= # flyway.skip-default-resolvers= # flyway.sql-migration-prefix=V # flyway.sql-migration-separator= # flyway.sql-migration-suffix=.sql # flyway.table= # flyway.target= # flyway.url= # JDBC url of the database to migrate. If not set, the primary configured data source is used. flyway.user= # Login user of the database to migrate. flyway.validate-on-migrate= # LIQUIBASE (LiquibaseProperties) liquibase.change-log=classpath:/db/changelog/db.changelog-master.yaml # Change log configuration path. liquibase.check-change-log-location=true # Check the change log location exists. liquibase.contexts= # Comma-separated list of runtime contexts to use. liquibase.default-schema= # Default database schema. liquibase.drop-first=false # Drop the database schema first. liquibase.enabled=true # Enable liquibase support. liquibase.labels= # Comma-separated list of runtime labels to use. liquibase.parameters.*= # Change log parameters. liquibase.password= # Login password of the database to migrate. liquibase.rollback-file= # File to which rollback SQL will be written when an update is performed. liquibase.url= # JDBC url of the database to migrate. If not set, the primary configured data source is used. liquibase.user= # Login user of the database to migrate. COUCHBASE (CouchbaseProperties) spring.couchbase.bootstrap-hosts= # Couchbase nodes (host or IP address) to bootstrap from. spring.couchbase.bucket.name=default # Name of the bucket to connect to. spring.couchbase.bucket.password= # Password of the bucket. spring.couchbase.env.endpoints.key-value=1 # Number of sockets per node against the Key/value service. spring.couchbase.env.endpoints.query=1 # Number of sockets per node against the Query (N1QL) service. spring.couchbase.env.endpoints.view=1 # Number of sockets per node against the view service. spring.couchbase.env.ssl.enabled= # Enable SSL support. Enabled automatically if a “keyStore” is provided unless specified otherwise. spring.couchbase.env.ssl.key-store= # Path to the JVM key store that holds the certificates. spring.couchbase.env.ssl.key-store-password= # Password used to access the key store. spring.couchbase.env.timeouts.connect=5000 # Bucket connections timeout in milliseconds. spring.couchbase.env.timeouts.key-value=2500 # Blocking operations performed on a specific key timeout in milliseconds. spring.couchbase.env.timeouts.query=7500 # N1QL query operations timeout in milliseconds. spring.couchbase.env.timeouts.socket-connect=1000 # Socket connect connections timeout in milliseconds. spring.couchbase.env.timeouts.view=7500 # Regular and geospatial view operations timeout in milliseconds. DAO (PersistenceExceptionTranslationAutoConfiguration) spring.dao.exceptiontranslation.enabled=true # Enable the PersistenceExceptionTranslationPostProcessor. CASSANDRA (CassandraProperties) spring.data.cassandra.cluster-name= # Name of the Cassandra cluster. spring.data.cassandra.compression=none # Compression supported by the Cassandra binary protocol. spring.data.cassandra.connect-timeout-millis= # Socket option: connection time out. spring.data.cassandra.consistency-level= # Queries consistency level. spring.data.cassandra.contact-points=localhost # Comma-separated list of cluster node addresses. spring.data.cassandra.fetch-size= # Queries default fetch size. spring.data.cassandra.keyspace-name= # Keyspace name to use. spring.data.cassandra.load-balancing-policy= # Class name of the load balancing policy. spring.data.cassandra.port= # Port of the Cassandra server. spring.data.cassandra.password= # Login password of the server. spring.data.cassandra.reactive-repositories.enabled=true # Enable Cassandra reactive repositories. spring.data.cassandra.read-timeout-millis= # Socket option: read time out. spring.data.cassandra.reconnection-policy= # Reconnection policy class. spring.data.cassandra.repositories.enabled= # Enable Cassandra repositories. spring.data.cassandra.retry-policy= # Class name of the retry policy. spring.data.cassandra.serial-consistency-level= # Queries serial consistency level. spring.data.cassandra.schema-action=none # Schema action to take at startup. spring.data.cassandra.ssl=false # Enable SSL support. spring.data.cassandra.username= # Login user of the server. DATA COUCHBASE (CouchbaseDataProperties) spring.data.couchbase.auto-index=false # Automatically create views and indexes. spring.data.couchbase.consistency=read-your-own-writes # Consistency to apply by default on generated queries. spring.data.couchbase.repositories.enabled=true # Enable Couchbase repositories. ELASTICSEARCH (ElasticsearchProperties) spring.data.elasticsearch.cluster-name=elasticsearch # Elasticsearch cluster name. spring.data.elasticsearch.cluster-nodes= # Comma-separated list of cluster node addresses. If not specified, starts a client node. spring.data.elasticsearch.properties.*= # Additional properties used to configure the client. spring.data.elasticsearch.repositories.enabled=true # Enable Elasticsearch repositories. DATA LDAP spring.data.ldap.repositories.enabled=true # Enable LDAP repositories. MONGODB (MongoProperties) spring.data.mongodb.authentication-database= # Authentication database name. spring.data.mongodb.database=test # Database name. spring.data.mongodb.field-naming-strategy= # Fully qualified name of the FieldNamingStrategy to use. spring.data.mongodb.grid-fs-database= # GridFS database name. spring.data.mongodb.host=localhost # Mongo server host. Cannot be set with uri. spring.data.mongodb.password= # Login password of the mongo server. Cannot be set with uri. spring.data.mongodb.port=27017 # Mongo server port. Cannot be set with uri. spring.data.mongodb.reactive-repositories.enabled=true # Enable Mongo reactive repositories. spring.data.mongodb.repositories.enabled=true # Enable Mongo repositories. spring.data.mongodb.uri=mongodb://localhost/test # Mongo database URI. Cannot be set with host, port and credentials. spring.data.mongodb.username= # Login user of the mongo server. Cannot be set with uri. DATA REDIS spring.data.redis.repositories.enabled=true # Enable Redis repositories. NEO4J (Neo4jProperties) spring.data.neo4j.auto-index=none # Auto index mode. spring.data.neo4j.embedded.enabled=true # Enable embedded mode if the embedded driver is available. spring.data.neo4j.open-in-view=false # Register OpenSessionInViewInterceptor. Binds a Neo4j Session to the thread for the entire processing of the request. spring.data.neo4j.password= # Login password of the server. spring.data.neo4j.repositories.enabled=true # Enable Neo4j repositories. spring.data.neo4j.uri= # URI used by the driver. Auto-detected by default. spring.data.neo4j.username= # Login user of the server. DATA REST (RepositoryRestProperties) spring.data.rest.base-path= # Base path to be used by Spring Data REST to expose repository resources. spring.data.rest.default-page-size= # Default size of pages. spring.data.rest.detection-strategy=default # Strategy to use to determine which repositories get exposed. spring.data.rest.enable-enum-translation= # Enable enum value translation via the Spring Data REST default resource bundle. spring.data.rest.limit-param-name= # Name of the URL query string parameter that indicates how many results to return at once. spring.data.rest.max-page-size= # Maximum size of pages. spring.data.rest.page-param-name= # Name of the URL query string parameter that indicates what page to return. spring.data.rest.return-body-on-create= # Return a response body after creating an entity. spring.data.rest.return-body-on-update= # Return a response body after updating an entity. spring.data.rest.sort-param-name= # Name of the URL query string parameter that indicates what direction to sort results. SOLR (SolrProperties) spring.data.solr.host=http://127.0.0.1:8983/solr # Solr host. Ignored if “zk-host” is set. spring.data.solr.repositories.enabled=true # Enable Solr repositories. spring.data.solr.zk-host= # ZooKeeper host address in the form HOST:PORT. DATASOURCE (DataSourceAutoConfiguration &amp; DataSourceProperties) spring.datasource.continue-on-error=false # Do not stop if an error occurs while initializing the database. spring.datasource.data= # Data (DML) script resource references. spring.datasource.data-username= # User of the database to execute DML scripts (if different). spring.datasource.data-password= # Password of the database to execute DML scripts (if different). spring.datasource.dbcp2.= # Commons DBCP2 specific settings spring.datasource.driver-class-name= # Fully qualified name of the JDBC driver. Auto-detected based on the URL by default. spring.datasource.generate-unique-name=false # Generate a random datasource name. spring.datasource.hikari.= # Hikari specific settings spring.datasource.initialize=true # Populate the database using ‘data.sql’. spring.datasource.jmx-enabled=false # Enable JMX support (if provided by the underlying pool). spring.datasource.jndi-name= # JNDI location of the datasource. Class, url, username &amp; password are ignored when set. spring.datasource.name=testdb # Name of the datasource. spring.datasource.password= # Login password of the database. spring.datasource.platform=all # Platform to use in the schema resource (schema-${platform}.sql). spring.datasource.schema= # Schema (DDL) script resource references. spring.datasource.schema-username= # User of the database to execute DDL scripts (if different). spring.datasource.schema-password= # Password of the database to execute DDL scripts (if different). spring.datasource.separator=; # Statement separator in SQL initialization scripts. spring.datasource.sql-script-encoding= # SQL scripts encoding. spring.datasource.tomcat.*= # Tomcat datasource specific settings spring.datasource.type= # Fully qualified name of the connection pool implementation to use. By default, it is auto-detected from the classpath. spring.datasource.url= # JDBC url of the database. spring.datasource.username= # Login user of the database. spring.datasource.xa.data-source-class-name= # XA datasource fully qualified name. spring.datasource.xa.properties= # Properties to pass to the XA data source. JEST (Elasticsearch HTTP client) (JestProperties) spring.elasticsearch.jest.connection-timeout=3000 # Connection timeout in milliseconds. spring.elasticsearch.jest.multi-threaded=true # Enable connection requests from multiple execution threads. spring.elasticsearch.jest.password= # Login password. spring.elasticsearch.jest.proxy.host= # Proxy host the HTTP client should use. spring.elasticsearch.jest.proxy.port= # Proxy port the HTTP client should use. spring.elasticsearch.jest.read-timeout=3000 # Read timeout in milliseconds. spring.elasticsearch.jest.uris=http://localhost:9200 # Comma-separated list of the Elasticsearch instances to use. spring.elasticsearch.jest.username= # Login user. H2 Web Console (H2ConsoleProperties) spring.h2.console.enabled=false # Enable the console. spring.h2.console.path=/h2-console # Path at which the console will be available. spring.h2.console.settings.trace=false # Enable trace output. spring.h2.console.settings.web-allow-others=false # Enable remote access. JOOQ (JooqAutoConfiguration) spring.jooq.sql-dialect= # SQLDialect JOOQ used when communicating with the configured datasource. For instance POSTGRES JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration) spring.data.jpa.repositories.enabled=true # Enable JPA repositories. spring.jpa.database= # Target database to operate on, auto-detected by default. Can be alternatively set using the “databasePlatform” property. spring.jpa.database-platform= # Name of the target database to operate on, auto-detected by default. Can be alternatively set using the “Database” enum. spring.jpa.generate-ddl=false # Initialize the schema on startup. spring.jpa.hibernate.ddl-auto= # DDL mode. This is actually a shortcut for the “hibernate.hbm2ddl.auto” property. Default to “create-drop” when using an embedded database, “none” otherwise. spring.jpa.hibernate.naming.implicit-strategy= # Hibernate 5 implicit naming strategy fully qualified name. spring.jpa.hibernate.naming.physical-strategy= # Hibernate 5 physical naming strategy fully qualified name. spring.jpa.hibernate.use-new-id-generator-mappings= # Use Hibernate’s newer IdentifierGenerator for AUTO, TABLE and SEQUENCE. spring.jpa.open-in-view=true # Register OpenEntityManagerInViewInterceptor. Binds a JPA EntityManager to the thread for the entire processing of the request. spring.jpa.properties.*= # Additional native properties to set on the JPA provider. spring.jpa.show-sql=false # Enable logging of SQL statements. JTA (JtaAutoConfiguration) spring.jta.enabled=true # Enable JTA support. spring.jta.log-dir= # Transaction logs directory. spring.jta.transaction-manager-id= # Transaction manager unique identifier. ATOMIKOS (AtomikosProperties) spring.jta.atomikos.connectionfactory.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool. spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag=true # Whether or not to ignore the transacted flag when creating session. spring.jta.atomikos.connectionfactory.local-transaction-mode=false # Whether or not local transactions are desired. spring.jta.atomikos.connectionfactory.maintenance-interval=60 # The time, in seconds, between runs of the pool’s maintenance thread. spring.jta.atomikos.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool. spring.jta.atomikos.connectionfactory.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit. spring.jta.atomikos.connectionfactory.max-pool-size=1 # The maximum size of the pool. spring.jta.atomikos.connectionfactory.min-pool-size=1 # The minimum size of the pool. spring.jta.atomikos.connectionfactory.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit. spring.jta.atomikos.connectionfactory.unique-resource-name=jmsConnectionFactory # The unique name used to identify the resource during recovery. spring.jta.atomikos.datasource.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool. spring.jta.atomikos.datasource.default-isolation-level= # Default isolation level of connections provided by the pool. spring.jta.atomikos.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection. spring.jta.atomikos.datasource.maintenance-interval=60 # The time, in seconds, between runs of the pool’s maintenance thread. spring.jta.atomikos.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool. spring.jta.atomikos.datasource.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit. spring.jta.atomikos.datasource.max-pool-size=1 # The maximum size of the pool. spring.jta.atomikos.datasource.min-pool-size=1 # The minimum size of the pool. spring.jta.atomikos.datasource.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit. spring.jta.atomikos.datasource.test-query= # SQL query or statement used to validate a connection before returning it. spring.jta.atomikos.datasource.unique-resource-name=dataSource # The unique name used to identify the resource during recovery. spring.jta.atomikos.properties.checkpoint-interval=500 # Interval between checkpoints. spring.jta.atomikos.properties.console-file-count=1 # Number of debug logs files that can be created. spring.jta.atomikos.properties.console-file-limit=-1 # How many bytes can be stored at most in debug logs files. spring.jta.atomikos.properties.console-file-name=tm.out # Debug logs file name. spring.jta.atomikos.properties.console-log-level=warn # Console log level. spring.jta.atomikos.properties.default-jta-timeout=10000 # Default timeout for JTA transactions. spring.jta.atomikos.properties.enable-logging=true # Enable disk logging. spring.jta.atomikos.properties.force-shutdown-on-vm-exit=false # Specify if a VM shutdown should trigger forced shutdown of the transaction core. spring.jta.atomikos.properties.log-base-dir= # Directory in which the log files should be stored. spring.jta.atomikos.properties.log-base-name=tmlog # Transactions log file base name. spring.jta.atomikos.properties.max-actives=50 # Maximum number of active transactions. spring.jta.atomikos.properties.max-timeout=300000 # Maximum timeout (in milliseconds) that can be allowed for transactions. spring.jta.atomikos.properties.output-dir= # Directory in which to store the debug log files. spring.jta.atomikos.properties.serial-jta-transactions=true # Specify if sub-transactions should be joined when possible. spring.jta.atomikos.properties.service= # Transaction manager implementation that should be started. spring.jta.atomikos.properties.threaded-two-phase-commit=false # Use different (and concurrent) threads for two-phase commit on the participating resources. spring.jta.atomikos.properties.transaction-manager-unique-name= # Transaction manager’s unique name. BITRONIX spring.jta.bitronix.connectionfactory.acquire-increment=1 # Number of connections to create when growing the pool. spring.jta.bitronix.connectionfactory.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired. spring.jta.bitronix.connectionfactory.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool. spring.jta.bitronix.connectionfactory.allow-local-transactions=true # Whether or not the transaction manager should allow mixing XA and non-XA transactions. spring.jta.bitronix.connectionfactory.apply-transaction-timeout=false # Whether or not the transaction timeout should be set on the XAResource when it is enlisted. spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled=true # Whether or not resources should be enlisted and delisted automatically. spring.jta.bitronix.connectionfactory.cache-producers-consumers=true # Whether or not produces and consumers should be cached. spring.jta.bitronix.connectionfactory.defer-connection-release=true # Whether or not the provider can run many transactions on the same connection and supports transaction interleaving. spring.jta.bitronix.connectionfactory.ignore-recovery-failures=false # Whether or not recovery failures should be ignored. spring.jta.bitronix.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool. spring.jta.bitronix.connectionfactory.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit. spring.jta.bitronix.connectionfactory.min-pool-size=0 # The minimum size of the pool. spring.jta.bitronix.connectionfactory.password= # The password to use to connect to the JMS provider. spring.jta.bitronix.connectionfactory.share-transaction-connections=false # Whether or not connections in the ACCESSIBLE state can be shared within the context of a transaction. spring.jta.bitronix.connectionfactory.test-connections=true # Whether or not connections should be tested when acquired from the pool. spring.jta.bitronix.connectionfactory.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE). spring.jta.bitronix.connectionfactory.unique-name=jmsConnectionFactory # The unique name used to identify the resource during recovery. spring.jta.bitronix.connectionfactory.use-tm-join=true Whether or not TMJOIN should be used when starting XAResources. spring.jta.bitronix.connectionfactory.user= # The user to use to connect to the JMS provider. spring.jta.bitronix.datasource.acquire-increment=1 # Number of connections to create when growing the pool. spring.jta.bitronix.datasource.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired. spring.jta.bitronix.datasource.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool. spring.jta.bitronix.datasource.allow-local-transactions=true # Whether or not the transaction manager should allow mixing XA and non-XA transactions. spring.jta.bitronix.datasource.apply-transaction-timeout=false # Whether or not the transaction timeout should be set on the XAResource when it is enlisted. spring.jta.bitronix.datasource.automatic-enlisting-enabled=true # Whether or not resources should be enlisted and delisted automatically. spring.jta.bitronix.datasource.cursor-holdability= # The default cursor holdability for connections. spring.jta.bitronix.datasource.defer-connection-release=true # Whether or not the database can run many transactions on the same connection and supports transaction interleaving. spring.jta.bitronix.datasource.enable-jdbc4-connection-test= # Whether or not Connection.isValid() is called when acquiring a connection from the pool. spring.jta.bitronix.datasource.ignore-recovery-failures=false # Whether or not recovery failures should be ignored. spring.jta.bitronix.datasource.isolation-level= # The default isolation level for connections. spring.jta.bitronix.datasource.local-auto-commit= # The default auto-commit mode for local transactions. spring.jta.bitronix.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection. spring.jta.bitronix.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool. spring.jta.bitronix.datasource.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit. spring.jta.bitronix.datasource.min-pool-size=0 # The minimum size of the pool. spring.jta.bitronix.datasource.prepared-statement-cache-size=0 # The target size of the prepared statement cache. 0 disables the cache. spring.jta.bitronix.datasource.share-transaction-connections=false # Whether or not connections in the ACCESSIBLE state can be shared within the context of a transaction. spring.jta.bitronix.datasource.test-query= # SQL query or statement used to validate a connection before returning it. spring.jta.bitronix.datasource.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE). spring.jta.bitronix.datasource.unique-name=dataSource # The unique name used to identify the resource during recovery. spring.jta.bitronix.datasource.use-tm-join=true Whether or not TMJOIN should be used when starting XAResources. spring.jta.bitronix.properties.allow-multiple-lrc=false # Allow multiple LRC resources to be enlisted into the same transaction. spring.jta.bitronix.properties.asynchronous2-pc=false # Enable asynchronously execution of two phase commit. spring.jta.bitronix.properties.background-recovery-interval-seconds=60 # Interval in seconds at which to run the recovery process in the background. spring.jta.bitronix.properties.current-node-only-recovery=true # Recover only the current node. spring.jta.bitronix.properties.debug-zero-resource-transaction=false # Log the creation and commit call stacks of transactions executed without a single enlisted resource. spring.jta.bitronix.properties.default-transaction-timeout=60 # Default transaction timeout in seconds. spring.jta.bitronix.properties.disable-jmx=false # Enable JMX support. spring.jta.bitronix.properties.exception-analyzer= # Set the fully qualified name of the exception analyzer implementation to use. spring.jta.bitronix.properties.filter-log-status=false # Enable filtering of logs so that only mandatory logs are written. spring.jta.bitronix.properties.force-batching-enabled=true # Set if disk forces are batched. spring.jta.bitronix.properties.forced-write-enabled=true # Set if logs are forced to disk. spring.jta.bitronix.properties.graceful-shutdown-interval=60 # Maximum amount of seconds the TM will wait for transactions to get done before aborting them at shutdown time. spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name= # JNDI name of the TransactionSynchronizationRegistry. spring.jta.bitronix.properties.jndi-user-transaction-name= # JNDI name of the UserTransaction. spring.jta.bitronix.properties.journal=disk # Name of the journal. Can be ‘disk’, ‘null’ or a class name. spring.jta.bitronix.properties.log-part1-filename=btm1.tlog # Name of the first fragment of the journal. spring.jta.bitronix.properties.log-part2-filename=btm2.tlog # Name of the second fragment of the journal. spring.jta.bitronix.properties.max-log-size-in-mb=2 # Maximum size in megabytes of the journal fragments. spring.jta.bitronix.properties.resource-configuration-filename= # ResourceLoader configuration file name. spring.jta.bitronix.properties.server-id= # ASCII ID that must uniquely identify this TM instance. Default to the machine’s IP address. spring.jta.bitronix.properties.skip-corrupted-logs=false # Skip corrupted transactions log entries. spring.jta.bitronix.properties.warn-about-zero-resource-transaction=true # Log a warning for transactions executed without a single enlisted resource. NARAYANA (NarayanaProperties) spring.jta.narayana.default-timeout=60 # Transaction timeout in seconds. spring.jta.narayana.expiry-scanners=com.arjuna.ats.internal.arjuna.recovery.ExpiredTransactionStatusManagerScanner # Comma-separated list of expiry scanners. spring.jta.narayana.log-dir= # Transaction object store directory. spring.jta.narayana.one-phase-commit=true # Enable one phase commit optimisation. spring.jta.narayana.periodic-recovery-period=120 # Interval in which periodic recovery scans are performed in seconds. spring.jta.narayana.recovery-backoff-period=10 # Back off period between first and second phases of the recovery scan in seconds. spring.jta.narayana.recovery-db-pass= # Database password to be used by recovery manager. spring.jta.narayana.recovery-db-user= # Database username to be used by recovery manager. spring.jta.narayana.recovery-jms-pass= # JMS password to be used by recovery manager. spring.jta.narayana.recovery-jms-user= # JMS username to be used by recovery manager. spring.jta.narayana.recovery-modules= # Comma-separated list of recovery modules. spring.jta.narayana.transaction-manager-id=1 # Unique transaction manager id. spring.jta.narayana.xa-resource-orphan-filters= # Comma-separated list of orphan filters. EMBEDDED MONGODB (EmbeddedMongoProperties) spring.mongodb.embedded.features=SYNC_DELAY # Comma-separated list of features to enable. spring.mongodb.embedded.storage.database-dir= # Directory used for data storage. spring.mongodb.embedded.storage.oplog-size= # Maximum size of the oplog in megabytes. spring.mongodb.embedded.storage.repl-set-name= # Name of the replica set. spring.mongodb.embedded.version=2.6.10 # Version of Mongo to use. REDIS (RedisProperties) spring.redis.cluster.max-redirects= # Maximum number of redirects to follow when executing commands across the cluster. spring.redis.cluster.nodes= # Comma-separated list of “host:port” pairs to bootstrap from. spring.redis.database=0 # Database index used by the connection factory. spring.redis.url= # Connection URL, will override host, port and password (user will be ignored), e.g. redis://user:password@example.com:6379 spring.redis.host=localhost # Redis server host. spring.redis.jedis.pool.max-active=8 # Max number of connections that can be allocated by the pool at a given time. Use a negative value for no limit. spring.redis.jedis.pool.max-idle=8 # Max number of “idle” connections in the pool. Use a negative value to indicate an unlimited number of idle connections. spring.redis.jedis.pool.max-wait=-1 # Maximum amount of time (in milliseconds) a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely. spring.redis.jedis.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive. spring.redis.lettuce.pool.max-active=8 # Max number of connections that can be allocated by the pool at a given time. Use a negative value for no limit. spring.redis.lettuce.pool.max-idle=8 # Max number of “idle” connections in the pool. Use a negative value to indicate an unlimited number of idle connections. spring.redis.lettuce.pool.max-wait=-1 # Maximum amount of time (in milliseconds) a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely. spring.redis.lettuce.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive. spring.redis.lettuce.shutdown-timeout=2000 # Shutdown timeout in milliseconds. spring.redis.password= # Login password of the redis server. spring.redis.port=6379 # Redis server port. spring.redis.sentinel.master= # Name of Redis server. spring.redis.sentinel.nodes= # Comma-separated list of host:port pairs. spring.redis.ssl=false # Enable SSL support. spring.redis.timeout=0 # Connection timeout in milliseconds. TRANSACTION (TransactionProperties) spring.transaction.default-timeout= # Default transaction timeout in seconds. spring.transaction.rollback-on-commit-failure= # Perform the rollback on commit failures. ACTIVEMQ (ActiveMQProperties) spring.activemq.broker-url= # URL of the ActiveMQ broker. Auto-generated by default. For instance tcp://localhost:61616 spring.activemq.in-memory=true # Specify if the default broker URL should be in memory. Ignored if an explicit broker has been specified. spring.activemq.password= # Login password of the broker. spring.activemq.user= # Login user of the broker. spring.activemq.packages.trust-all=false # Trust all packages. spring.activemq.packages.trusted= # Comma-separated list of specific packages to trust (when not trusting all packages). spring.activemq.pool.configuration.*= # See PooledConnectionFactory. spring.activemq.pool.enabled=false # Whether a PooledConnectionFactory should be created instead of a regular ConnectionFactory. spring.activemq.pool.expiry-timeout=0 # Connection expiration timeout in milliseconds. spring.activemq.pool.idle-timeout=30000 # Connection idle timeout in milliseconds. spring.activemq.pool.max-connections=1 # Maximum number of pooled connections. ARTEMIS (ArtemisProperties) spring.artemis.embedded.cluster-password= # Cluster password. Randomly generated on startup by default. spring.artemis.embedded.data-directory= # Journal file directory. Not necessary if persistence is turned off. spring.artemis.embedded.enabled=true # Enable embedded mode if the Artemis server APIs are available. spring.artemis.embedded.persistent=false # Enable persistent store. spring.artemis.embedded.queues= # Comma-separated list of queues to create on startup. spring.artemis.embedded.server-id= # Server id. By default, an auto-incremented counter is used. spring.artemis.embedded.topics= # Comma-separated list of topics to create on startup. spring.artemis.host=localhost # Artemis broker host. spring.artemis.mode= # Artemis deployment mode, auto-detected by default. spring.artemis.password= # Login password of the broker. spring.artemis.port=61616 # Artemis broker port. spring.artemis.user= # Login user of the broker. SPRING BATCH (BatchProperties) spring.batch.initializer.enabled= # Create the required batch tables on startup if necessary. Enabled automatically if no custom table prefix is set or if a custom schema is configured. spring.batch.job.enabled=true # Execute all Spring Batch jobs in the context on startup. spring.batch.job.names= # Comma-separated list of job names to execute on startup (For instance job1,job2). By default, all Jobs found in the context are executed. spring.batch.schema=classpath:org/springframework/batch/core/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema. spring.batch.table-prefix= # Table prefix for all the batch meta-data tables. SPRING INTEGRATION (IntegrationProperties) spring.integration.jdbc.initializer.enabled=false # Create the required integration tables on startup. spring.integration.jdbc.schema=classpath:org/springframework/integration/jdbc/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema. JMS (JmsProperties) spring.jms.jndi-name= # Connection factory JNDI name. When set, takes precedence to others connection factory auto-configurations. spring.jms.listener.acknowledge-mode= # Acknowledge mode of the container. By default, the listener is transacted with automatic acknowledgment. spring.jms.listener.auto-startup=true # Start the container automatically on startup. spring.jms.listener.concurrency= # Minimum number of concurrent consumers. spring.jms.listener.max-concurrency= # Maximum number of concurrent consumers. spring.jms.pub-sub-domain=false # Specify if the default destination type is topic. spring.jms.template.default-destination= # Default destination to use on send/receive operations that do not have a destination parameter. spring.jms.template.delivery-delay= # Delivery delay to use for send calls in milliseconds. spring.jms.template.delivery-mode= # Delivery mode. Enable QoS when set. spring.jms.template.priority= # Priority of a message when sending. Enable QoS when set. spring.jms.template.qos-enabled= # Enable explicit QoS when sending a message. spring.jms.template.receive-timeout= # Timeout to use for receive calls in milliseconds. spring.jms.template.time-to-live= # Time-to-live of a message when sending in milliseconds. Enable QoS when set. APACHE KAFKA (KafkaProperties) spring.kafka.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster. spring.kafka.client-id= # Id to pass to the server when making requests; used for server-side logging. spring.kafka.consumer.auto-commit-interval= # Frequency in milliseconds that the consumer offsets are auto-committed to Kafka if ‘enable.auto.commit’ true. spring.kafka.consumer.auto-offset-reset= # What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. spring.kafka.consumer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster. spring.kafka.consumer.client-id= # Id to pass to the server when making requests; used for server-side logging. spring.kafka.consumer.enable-auto-commit= # If true the consumer’s offset will be periodically committed in the background. spring.kafka.consumer.fetch-max-wait= # Maximum amount of time in milliseconds the server will block before answering the fetch request if there isn’t sufficient data to immediately satisfy the requirement given by “fetch.min.bytes”. spring.kafka.consumer.fetch-min-size= # Minimum amount of data the server should return for a fetch request in bytes. spring.kafka.consumer.group-id= # Unique string that identifies the consumer group this consumer belongs to. spring.kafka.consumer.heartbeat-interval= # Expected time in milliseconds between heartbeats to the consumer coordinator. spring.kafka.consumer.key-deserializer= # Deserializer class for keys. spring.kafka.consumer.max-poll-records= # Maximum number of records returned in a single call to poll(). spring.kafka.consumer.ssl.key-password= # Password of the private key in the key store file. spring.kafka.consumer.ssl.keystore-location= # Location of the key store file. spring.kafka.consumer.ssl.keystore-password= # Store password for the key store file. spring.kafka.consumer.ssl.truststore-location= # Location of the trust store file. spring.kafka.consumer.ssl.truststore-password= # Store password for the trust store file. spring.kafka.consumer.value-deserializer= # Deserializer class for values. spring.kafka.jaas.control-flag=required # Control flag for login configuration. spring.kafka.jaas.enabled= # Enable JAAS configuration. spring.kafka.jaas.login-module=com.sun.security.auth.module.Krb5LoginModule # Login module. spring.kafka.jaas.options= # Additional JAAS options. spring.kafka.listener.ack-count= # Number of records between offset commits when ackMode is “COUNT” or “COUNT_TIME”. spring.kafka.listener.ack-mode= # Listener AckMode; see the spring-kafka documentation. spring.kafka.listener.ack-time= # Time in milliseconds between offset commits when ackMode is “TIME” or “COUNT_TIME”. spring.kafka.listener.concurrency= # Number of threads to run in the listener containers. spring.kafka.listener.poll-timeout= # Timeout in milliseconds to use when polling the consumer. spring.kafka.producer.acks= # Number of acknowledgments the producer requires the leader to have received before considering a request complete. spring.kafka.producer.batch-size= # Number of records to batch before sending. spring.kafka.producer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster. spring.kafka.producer.buffer-memory= # Total bytes of memory the producer can use to buffer records waiting to be sent to the server. spring.kafka.producer.client-id= # Id to pass to the server when making requests; used for server-side logging. spring.kafka.producer.compression-type= # Compression type for all data generated by the producer. spring.kafka.producer.key-serializer= # Serializer class for keys. spring.kafka.producer.retries= # When greater than zero, enables retrying of failed sends. spring.kafka.producer.ssl.key-password= # Password of the private key in the key store file. spring.kafka.producer.ssl.keystore-location= # Location of the key store file. spring.kafka.producer.ssl.keystore-password= # Store password for the key store file. spring.kafka.producer.ssl.truststore-location= # Location of the trust store file. spring.kafka.producer.ssl.truststore-password= # Store password for the trust store file. spring.kafka.producer.value-serializer= # Serializer class for values. spring.kafka.properties.*= # Additional properties used to configure the client. spring.kafka.ssl.key-password= # Password of the private key in the key store file. spring.kafka.ssl.keystore-location= # Location of the key store file. spring.kafka.ssl.keystore-password= # Store password for the key store file. spring.kafka.ssl.truststore-location= # Location of the trust store file. spring.kafka.ssl.truststore-password= # Store password for the trust store file. spring.kafka.template.default-topic= # Default topic to which messages will be sent. RABBIT (RabbitProperties) spring.rabbitmq.addresses= # Comma-separated list of addresses to which the client should connect. spring.rabbitmq.cache.channel.checkout-timeout= # Number of milliseconds to wait to obtain a channel if the cache size has been reached. spring.rabbitmq.cache.channel.size= # Number of channels to retain in the cache. spring.rabbitmq.cache.connection.mode=channel # Connection factory cache mode. spring.rabbitmq.cache.connection.size= # Number of connections to cache. spring.rabbitmq.connection-timeout= # Connection timeout, in milliseconds; zero for infinite. spring.rabbitmq.dynamic=true # Create an AmqpAdmin bean. spring.rabbitmq.host=localhost # RabbitMQ host. spring.rabbitmq.listener.direct.acknowledge-mode= # Acknowledge mode of container. spring.rabbitmq.listener.direct.auto-startup=true # Start the container automatically on startup. spring.rabbitmq.listener.direct.consumers-per-queue= # Number of consumers per queue. spring.rabbitmq.listener.direct.default-requeue-rejected= # Whether rejected deliveries are requeued by default; default true. spring.rabbitmq.listener.direct.idle-event-interval= # How often idle container events should be published in milliseconds. spring.rabbitmq.listener.direct.prefetch= # Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used). spring.rabbitmq.listener.simple.acknowledge-mode= # Acknowledge mode of container. spring.rabbitmq.listener.simple.auto-startup=true # Start the container automatically on startup. spring.rabbitmq.listener.simple.concurrency= # Minimum number of listener invoker threads. spring.rabbitmq.listener.simple.default-requeue-rejected= # Whether or not to requeue delivery failures. spring.rabbitmq.listener.simple.idle-event-interval= # How often idle container events should be published in milliseconds. spring.rabbitmq.listener.simple.max-concurrency= # Maximum number of listener invoker. spring.rabbitmq.listener.simple.prefetch= # Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used). spring.rabbitmq.listener.simple.retry.enabled=false # Whether or not publishing retries are enabled. spring.rabbitmq.listener.simple.retry.initial-interval=1000 # Interval between the first and second attempt to deliver a message. spring.rabbitmq.listener.simple.retry.max-attempts=3 # Maximum number of attempts to deliver a message. spring.rabbitmq.listener.simple.retry.max-interval=10000 # Maximum interval between attempts. spring.rabbitmq.listener.simple.retry.multiplier=1.0 # A multiplier to apply to the previous delivery retry interval. spring.rabbitmq.listener.simple.retry.stateless=true # Whether or not retry is stateless or stateful. spring.rabbitmq.listener.simple.transaction-size= # Number of messages to be processed in a transaction; number of messages between acks. For best results it should be less than or equal to the prefetch count. spring.rabbitmq.listener.type=simple # Listener container type. spring.rabbitmq.password= # Login to authenticate against the broker. spring.rabbitmq.port=5672 # RabbitMQ port. spring.rabbitmq.publisher-confirms=false # Enable publisher confirms. spring.rabbitmq.publisher-returns=false # Enable publisher returns. spring.rabbitmq.requested-heartbeat= # Requested heartbeat timeout, in seconds; zero for none. spring.rabbitmq.ssl.enabled=false # Enable SSL support. spring.rabbitmq.ssl.key-store= # Path to the key store that holds the SSL certificate. spring.rabbitmq.ssl.key-store-password= # Password used to access the key store. spring.rabbitmq.ssl.trust-store= # Trust store that holds SSL certificates. spring.rabbitmq.ssl.trust-store-password= # Password used to access the trust store. spring.rabbitmq.ssl.algorithm= # SSL algorithm to use. By default configure by the rabbit client library. spring.rabbitmq.template.mandatory=false # Enable mandatory messages. spring.rabbitmq.template.receive-timeout=0 # Timeout for receive() methods. spring.rabbitmq.template.reply-timeout=5000 # Timeout for sendAndReceive() methods. spring.rabbitmq.template.retry.enabled=false # Set to true to enable retries in the RabbitTemplate. spring.rabbitmq.template.retry.initial-interval=1000 # Interval between the first and second attempt to publish a message. spring.rabbitmq.template.retry.max-attempts=3 # Maximum number of attempts to publish a message. spring.rabbitmq.template.retry.max-interval=10000 # Maximum number of attempts to publish a message. spring.rabbitmq.template.retry.multiplier=1.0 # A multiplier to apply to the previous publishing retry interval. spring.rabbitmq.username= # Login user to authenticate to the broker. spring.rabbitmq.virtual-host= # Virtual host to use when connecting to the broker. ENDPOINTS (AbstractEndpoint subclasses) endpoints.enabled=true # Enable endpoints. endpoints.sensitive= # Default endpoint sensitive setting. endpoints.actuator.enabled=true # Enable the endpoint. endpoints.actuator.path= # Endpoint URL path. endpoints.actuator.sensitive=false # Enable security on the endpoint. endpoints.auditevents.enabled= # Enable the endpoint. endpoints.auditevents.path= # Endpoint path. endpoints.auditevents.sensitive=false # Enable security on the endpoint. endpoints.autoconfig.enabled= # Enable the endpoint. endpoints.autoconfig.id= # Endpoint identifier. endpoints.autoconfig.path= # Endpoint path. endpoints.autoconfig.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.beans.enabled= # Enable the endpoint. endpoints.beans.id= # Endpoint identifier. endpoints.beans.path= # Endpoint path. endpoints.beans.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.configprops.enabled= # Enable the endpoint. endpoints.configprops.id= # Endpoint identifier. endpoints.configprops.keys-to-sanitize=password,secret,key,token,.credentials.,vcap_services # Keys that should be sanitized. Keys can be simple strings that the property ends with or regex expressions. endpoints.configprops.path= # Endpoint path. endpoints.configprops.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.docs.curies.enabled=false # Enable the curie generation. endpoints.docs.enabled=true # Enable actuator docs endpoint. endpoints.docs.path=/docs # endpoints.docs.sensitive=false # endpoints.dump.enabled= # Enable the endpoint. endpoints.dump.id= # Endpoint identifier. endpoints.dump.path= # Endpoint path. endpoints.dump.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.env.enabled= # Enable the endpoint. endpoints.env.id= # Endpoint identifier. endpoints.env.keys-to-sanitize=password,secret,key,token,.credentials.,vcap_services # Keys that should be sanitized. Keys can be simple strings that the property ends with or regex expressions. endpoints.env.path= # Endpoint path. endpoints.env.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.flyway.enabled= # Enable the endpoint. endpoints.flyway.id= # Endpoint identifier. endpoints.flyway.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.health.enabled= # Enable the endpoint. endpoints.health.id= # Endpoint identifier. endpoints.health.mapping.*= # Mapping of health statuses to HttpStatus codes. By default, registered health statuses map to sensible defaults (i.e. UP maps to 200). endpoints.health.path= # Endpoint path. endpoints.health.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.health.time-to-live=1000 # Time to live for cached result, in milliseconds. endpoints.heapdump.enabled= # Enable the endpoint. endpoints.heapdump.path= # Endpoint path. endpoints.heapdump.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.hypermedia.enabled=false # Enable hypermedia support for endpoints. endpoints.info.enabled= # Enable the endpoint. endpoints.info.id= # Endpoint identifier. endpoints.info.path= # Endpoint path. endpoints.info.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.jolokia.enabled=true # Enable Jolokia endpoint. endpoints.jolokia.path=/jolokia # Endpoint URL path. endpoints.jolokia.sensitive=true # Enable security on the endpoint. endpoints.liquibase.enabled= # Enable the endpoint. endpoints.liquibase.id= # Endpoint identifier. endpoints.liquibase.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.logfile.enabled=true # Enable the endpoint. endpoints.logfile.external-file= # External Logfile to be accessed. endpoints.logfile.path=/logfile # Endpoint URL path. endpoints.logfile.sensitive=true # Enable security on the endpoint. endpoints.loggers.enabled=true # Enable the endpoint. endpoints.loggers.id= # Endpoint identifier. endpoints.loggers.path=/logfile # Endpoint path. endpoints.loggers.sensitive=true # Mark if the endpoint exposes sensitive information. endpoints.mappings.enabled= # Enable the endpoint. endpoints.mappings.id= # Endpoint identifier. endpoints.mappings.path= # Endpoint path. endpoints.mappings.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.metrics.enabled= # Enable the endpoint. endpoints.metrics.filter.enabled=true # Enable the metrics servlet filter. endpoints.metrics.filter.gauge-submissions=merged # Http filter gauge submissions (merged, per-http-method) endpoints.metrics.filter.counter-submissions=merged # Http filter counter submissions (merged, per-http-method) endpoints.metrics.id= # Endpoint identifier. endpoints.metrics.path= # Endpoint path. endpoints.metrics.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.shutdown.enabled= # Enable the endpoint. endpoints.shutdown.id= # Endpoint identifier. endpoints.shutdown.path= # Endpoint path. endpoints.shutdown.sensitive= # Mark if the endpoint exposes sensitive information. endpoints.trace.enabled= # Enable the endpoint. endpoints.trace.filter.enabled=true # Enable the trace servlet filter. endpoints.trace.id= # Endpoint identifier. endpoints.trace.path= # Endpoint path. endpoints.trace.sensitive= # Mark if the endpoint exposes sensitive information. ENDPOINTS CORS CONFIGURATION (EndpointCorsProperties) endpoints.cors.allow-credentials= # Set whether credentials are supported. When not set, credentials are not supported. endpoints.cors.allowed-headers= # Comma-separated list of headers to allow in a request. ‘’ allows all headers. endpoints.cors.allowed-methods=GET # Comma-separated list of methods to allow. '’ allows all methods. endpoints.cors.allowed-origins= # Comma-separated list of origins to allow. ‘*’ allows all origins. When not set, CORS support is disabled. endpoints.cors.exposed-headers= # Comma-separated list of headers to include in a response. endpoints.cors.max-age=1800 # How long, in seconds, the response from a pre-flight request can be cached by clients. JMX ENDPOINT (EndpointMBeanExportProperties) endpoints.jmx.domain= # JMX domain name. Initialized with the value of ‘spring.jmx.default-domain’ if set. endpoints.jmx.enabled=true # Enable JMX export of all endpoints. endpoints.jmx.static-names= # Additional static properties to append to all ObjectNames of MBeans representing Endpoints. endpoints.jmx.unique-names=false # Ensure that ObjectNames are modified in case of conflict. JOLOKIA (JolokiaProperties) jolokia.config.*= # See Jolokia manual MANAGEMENT HTTP SERVER (ManagementServerProperties) management.add-application-context-header=false # Add the “X-Application-Context” HTTP header in each response. management.address= # Network address that the management endpoints should bind to. management.context-path= # Management endpoint context-path. For instance /actuator management.cloudfoundry.enabled= # Enable extended Cloud Foundry actuator endpoints management.cloudfoundry.skip-ssl-validation= # Skip SSL verification for Cloud Foundry actuator endpoint security calls management.port= # Management endpoint HTTP port. Uses the same port as the application by default. Configure a different port to use management-specific SSL. management.security.enabled=true # Enable security. management.security.roles=ACTUATOR # Comma-separated list of roles that can access the management endpoint. management.security.sessions=stateless # Session creating policy to use (always, never, if_required, stateless). management.ssl.ciphers= # Supported SSL ciphers. Requires a custom management.port. management.ssl.client-auth= # Whether client authentication is wanted (“want”) or needed (“need”). Requires a trust store. Requires a custom management.port. management.ssl.enabled= # Enable SSL support. Requires a custom management.port. management.ssl.enabled-protocols= # Enabled SSL protocols. Requires a custom management.port. management.ssl.key-alias= # Alias that identifies the key in the key store. Requires a custom management.port. management.ssl.key-password= # Password used to access the key in the key store. Requires a custom management.port. management.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file). Requires a custom management.port. management.ssl.key-store-password= # Password used to access the key store. Requires a custom management.port. management.ssl.key-store-provider= # Provider for the key store. Requires a custom management.port. management.ssl.key-store-type= # Type of the key store. Requires a custom management.port. management.ssl.protocol=TLS # SSL protocol to use. Requires a custom management.port. management.ssl.trust-store= # Trust store that holds SSL certificates. Requires a custom management.port. management.ssl.trust-store-password= # Password used to access the trust store. Requires a custom management.port. management.ssl.trust-store-provider= # Provider for the trust store. Requires a custom management.port. management.ssl.trust-store-type= # Type of the trust store. Requires a custom management.port. HEALTH INDICATORS management.health.db.enabled=true # Enable database health check. management.health.cassandra.enabled=true # Enable cassandra health check. management.health.couchbase.enabled=true # Enable couchbase health check. management.health.defaults.enabled=true # Enable default health indicators. management.health.diskspace.enabled=true # Enable disk space health check. management.health.diskspace.path= # Path used to compute the available disk space. management.health.diskspace.threshold=0 # Minimum disk space that should be available, in bytes. management.health.elasticsearch.enabled=true # Enable elasticsearch health check. management.health.elasticsearch.indices= # Comma-separated index names. management.health.elasticsearch.response-timeout=100 # The time, in milliseconds, to wait for a response from the cluster. management.health.jms.enabled=true # Enable JMS health check. management.health.ldap.enabled=true # Enable LDAP health check. management.health.mail.enabled=true # Enable Mail health check. management.health.mongo.enabled=true # Enable MongoDB health check. management.health.rabbit.enabled=true # Enable RabbitMQ health check. management.health.redis.enabled=true # Enable Redis health check. management.health.solr.enabled=true # Enable Solr health check. management.health.status.order=DOWN, OUT_OF_SERVICE, UP, UNKNOWN # Comma-separated list of health statuses in order of severity. INFO CONTRIBUTORS (InfoContributorProperties) management.info.build.enabled=true # Enable build info. management.info.defaults.enabled=true # Enable default info contributors. management.info.env.enabled=true # Enable environment info. management.info.git.enabled=true # Enable git info. management.info.git.mode=simple # Mode to use to expose git information. TRACING (TraceProperties) management.trace.include=request-headers,response-headers,cookies,errors # Items to be included in the trace. METRICS EXPORT (MetricExportProperties) spring.metrics.export.aggregate.key-pattern= # Pattern that tells the aggregator what to do with the keys from the source repository. spring.metrics.export.aggregate.prefix= # Prefix for global repository if active. spring.metrics.export.delay-millis=5000 # Delay in milliseconds between export ticks. Metrics are exported to external sources on a schedule with this delay. spring.metrics.export.enabled=true # Flag to enable metric export (assuming a MetricWriter is available). spring.metrics.export.excludes= # List of patterns for metric names to exclude. Applied after the includes. spring.metrics.export.includes= # List of patterns for metric names to include. spring.metrics.export.redis.key=keys.spring.metrics # Key for redis repository export (if active). spring.metrics.export.redis.prefix=spring.metrics # Prefix for redis repository if active. spring.metrics.export.send-latest= # Flag to switch off any available optimizations based on not exporting unchanged metric values. spring.metrics.export.statsd.host= # Host of a statsd server to receive exported metrics. spring.metrics.export.statsd.port=8125 # Port of a statsd server to receive exported metrics. spring.metrics.export.statsd.prefix= # Prefix for statsd exported metrics. spring.metrics.export.triggers.*= # Specific trigger properties per MetricWriter bean name. DEVTOOLS (DevToolsProperties) spring.devtools.livereload.enabled=true # Enable a livereload.com compatible server. spring.devtools.livereload.port=35729 # Server port. spring.devtools.restart.additional-exclude= # Additional patterns that should be excluded from triggering a full restart. spring.devtools.restart.additional-paths= # Additional paths to watch for changes. spring.devtools.restart.enabled=true # Enable automatic restart. spring.devtools.restart.exclude=META-INF/maven/,META-INF/resources/,resources/,static/,public/,templates/,/*Test.class,/*Tests.class,git.properties # Patterns that should be excluded from triggering a full restart. spring.devtools.restart.poll-interval=1000 # Amount of time (in milliseconds) to wait between polling for classpath changes. spring.devtools.restart.quiet-period=400 # Amount of quiet time (in milliseconds) required without any classpath changes before a restart is triggered. spring.devtools.restart.trigger-file= # Name of a specific file that when changed will trigger the restart check. If not specified any classpath file change will trigger the restart. REMOTE DEVTOOLS (RemoteDevToolsProperties) spring.devtools.remote.context-path=/.~~spring-boot!~ # Context path used to handle the remote connection. spring.devtools.remote.debug.enabled=true # Enable remote debug support. spring.devtools.remote.debug.local-port=8000 # Local remote debug server port. spring.devtools.remote.proxy.host= # The host of the proxy to use to connect to the remote application. spring.devtools.remote.proxy.port= # The port of the proxy to use to connect to the remote application. spring.devtools.remote.restart.enabled=true # Enable remote restart. spring.devtools.remote.secret= # A shared secret required to establish a connection (required to enable remote support). spring.devtools.remote.secret-header-name=X-AUTH-TOKEN # HTTP header used to transfer the shared secret. TEST spring.test.database.replace=any # Type of existing DataSource to replace. spring.test.mockmvc.print=default # MVC Print option.","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://luxiaowan.github.io/categories/SpringBoot/"}],"tags":[]},{"title":"ThreadLocal是怎么实现线程隔离的","slug":"ThreadLocal是怎么实现线程隔离的","date":"2019-11-20T15:21:56.000Z","updated":"2019-11-25T17:08:11.991Z","comments":true,"path":"2019/11/20/ThreadLocal是怎么实现线程隔离的/","link":"","permalink":"http://luxiaowan.github.io/2019/11/20/ThreadLocal是怎么实现线程隔离的/","excerpt":"","text":"ThreadLocal大家应该都不陌生，见过最多的使用场景应该是和SimpleDateFormat一起使用吧，因为这个SDF非线程安全的，所以需要使用ThreadLocal将它在线程之间隔离开，避免造成脏数据的🐞。那么ThreadLocal是怎么保证线程安全，又是如何操作的呢？ 案例 123456789101112131415161718192021public static void main(String[] args) &#123; ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;(); new Thread(new Runnable() &#123; @Override public void run() &#123; threadLocal.set(1); threadLocal.set(2); System.out.println(\"cc1: \" + threadLocal.get()); &#125; &#125;, \"cc1\").start(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"cc2: \" + threadLocal.get()); &#125; &#125;, \"cc2\").start();&#125; 输出: 12cc1: 2cc2: null 哦哟~cc2打印出来null，也就是在cc1线程中设置的值在线程cc2中获取不到，这也就是所谓的线程隔离，我们来看下ThreadLocal具体的代码实现吧： ThreadLocal的set(T t)方法源码 123456789101112public void set(T value) &#123; // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程的threadLocals属性，这个属性在Thread类中定义的，为Thread的实例变量 ThreadLocalMap map = getMap(t); // 若线程的ThreadLocalMap已经存在，则调用ThreadLocalMap的set(ThreadLocal&lt;T&gt; key, Object value)方法 // 否则创建新的ThreadLocalMap实例，并set对应的value if (map != null) map.set(this, value); else createMap(t, value);&#125; ThreadLocalMap的set(ThreadLocal key, Object value)方法源码 12345678910111213141516171819202122232425262728private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; // 简单计算key所在的位置 int i = key.threadLocalHashCode &amp; (len-1); // 从key所在位置开始遍历table数组，找到具体key所在的位置 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; // 获取Entry实例的key值，这里调用的是超类java.lang.ref.Reference中的get(T t)方法 ThreadLocal&lt;?&gt; k = e.get(); // 若k与传入的参数key是同一个，则用参数value替换Entry实例的value，然后结束方法 if (k == key) &#123; e.value = value; return; &#125; // 若获取的k为null，则表示这个变量已经被删除了，则去清理一下table数组，并对数组中元素进行清理并设置新的Entry实例 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; // 代码走到这一步，说明该线程第一次设置数据，创建新的Entry实例放在table的第i个位置上 tab[i] = new Entry(key, value); int sz = ++size; // 清理table中的元素，若长度达到了扩容阈值，则对table进行扩容，扩容为原数组长度的2倍 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; ThreadLocal的createMap(Thread t, T firstValue)方法源码 12345void createMap(Thread t, T firstValue) &#123; // 创建一个ThreadLocalMap实例，并赋值给当前线程的实例变量threadLocals // 这里就是线程隔离的关键所在，每一个线程中的数据都是由线程独有的threadLocals变量存储的 t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; ThreadLocalMap的构造器源码 123456789101112ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; // 实例化Entry数组，长度为初始长度16 table = new Entry[INITIAL_CAPACITY]; // 计算key在数组中的位置 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 创建Entry实例，并放在table的i下标位置 table[i] = new Entry(firstKey, firstValue); // 实际长度设置为1 size = 1; // 设置数组扩容阈值（len * 2 / 3） setThreshold(INITIAL_CAPACITY);&#125; 以上便是ThreadLocal达到线程隔离的基本解析，讲解的比较基础，其实就是JDK源码鉴赏，还有什么不懂的地方就自己去看源码吧。 延伸下 ThreadLocal的get()方法源码 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 这段代码比较简单，这里就不在进行解释了，我们着重看一下最后一句setInitialValue()这个方法 1234567891011121314private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;protected T initialValue() &#123; return null;&#125; 会发现和set方法类似，只不过是将一个null当做value而已，所以我们在没给ThreadLocal设置值的情况下调用get方法，则会为其创建一个默认的null值并返回null。 留一个思考题 因为我们每个线程的ThreadLocal的key的hash值都是固定的，那么Thread的threadLocals变量的table中会有多少个非null元素呢？","categories":[{"name":"Java","slug":"Java","permalink":"http://luxiaowan.github.io/categories/Java/"}],"tags":[]},{"title":"慎用ArrayList中的SubList","slug":"慎用ArrayList中的SubList","date":"2019-11-10T17:11:00.000Z","updated":"2019-11-24T16:18:53.293Z","comments":true,"path":"2019/11/11/慎用ArrayList中的SubList/","link":"","permalink":"http://luxiaowan.github.io/2019/11/11/慎用ArrayList中的SubList/","excerpt":"","text":"双十一了，大家都省了多少钱啊？ 题外话：此处交给大家一个查看商品历史价格的小方法： 在商品链接的域名后加上三个v就能查看到该商品的历史价格啦 🌰 http://shop.taobao.com/xxxx ↓ http://shop.taobaovvv.com/xxx 步入正题，为什么说我们在实际开发过程中要慎用ArrayList的subList呢？其实这也是阿里军规中的一条，原因其实很简单：不稳定！也许看到这里会觉得&quot;就是创建一个独立的新的SubList的实例，怎么会不稳定！&quot;，如果你是这么想的，那么恭喜你，这篇文章真的能够帮助到你，且往下看： 1. 客观您上上眼，看看SubList的set方法： 1234567891011121314151617public static void main(String[] args) &#123; List&lt;String&gt; sourceList = new ArrayList&lt;String&gt;() &#123; &#123; add(\"H\"); add(\"E\"); add(\"L\"); add(\"L\"); add(\"O\"); add(\"W\"); add(\"O\"); add(\"R\"); add(\"L\"); add(\"D\"); &#125; &#125;; List&lt;String&gt; subList = sourceList.subList(2, 5); System.out.println(\"sourceList: \" + sourceList); System.out.println(\"sourceList.subList(2, 5)得到: \" + subList); subList.set(1, \"cc\"); System.out.println(\"sourceList: \" + sourceList); System.out.println(\"subList: \" + subList); &#125;&#125; 上面代码的执行结果是什么？先不要看下面的答案，自己想一想。 答案 1234sourceList: [H, E, L, L, O, W, O, R, L, D]subList: [L, L, O]sourceList: [H, E, L, cc, O, W, O, R, L, D]subList: [L, cc, O] 哦吼~！答案和你自己想的有没有出入？奇妙吧，为什么修改了subList中的元素，会影响到sourceList？我们来看下ArrayList的subList方法都做了些什么： JDK源码 12345678/** * Returns a view of the portion of this list between the specified * &#123;@code fromIndex&#125;, inclusive, and &#123;@code toIndex&#125;, exclusive. */public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex);&#125; 首先是检查我们的fromIndex和toIndex是否合法，然后调用ArrayList的内部类SubList创建一个SubList的实例。好像还真如我们之前想的一样，创建了一个独立的SubList的对象，没什么不对的，那我们来看一下SubList的构造器中都做了些什么吧。 1234567SubList(AbstractList&lt;E&gt; parent, int offset, int fromIndex, int toIndex) &#123; this.parent = parent; this.parentOffset = fromIndex; this.offset = offset + fromIndex; this.size = toIndex - fromIndex; this.modCount = ArrayList.this.modCount;&#125; 这是个什么鬼？ArrayList的实例对象(也就是parent)竟然作为参数传到了SubList中，SubList的偏移量为0+fromIndex，大小size为toIndex - fromIndex（也就是和String的substring方法一样，fromIndex到(toIndex -1)的数据集），修改次数modCount和ArrayList的modCount相等，那么我们猜测一下：SubList实例的变动，是否和ArrayList有关呢？ 我们看到subList方法的注释中有这么一句话：Returns a view of the portion of this list。难道SubList仅仅是ArrayList的一个被fromIndex和toIndex的区间视图？ 上面的例子中，subList调用了它的set方法，我们来看一下这个set方法内部逻辑是什么： 12345678910public E set(int index, E e) &#123; rangeCheck(index);// 下标校验 checkForComodification();// 校验合法性 // ***重点 // 根据偏移量和下标，获取ArrayList对象的elementData数组中下标为(offset + index)的元素 // offset是什么？从构造器中我们可以看到offset就是0 + fromIndex，也就是我们截取的起始下标，也就是SubList的set方法是直接在原ArrayList实例的内部数组上进行的操作 E oldValue = ArrayList.this.elementData(offset + index); ArrayList.this.elementData[offset + index] = e; return oldValue;&#125; 看到这里就一目了然了，怪不得我们修改了SubList的元素会影响到创建它的对象的值。所以在使用SubList的时候，如果需要修改SubList里面的值，一定要注意一下是否会影响到原List中的数据所涉及的业务，否则这个坑一旦踩上了，不太容易排查啊。 2. 客观再上眼，看看SubList的add方法 1234567891011121314151617public static void main(String[] args) &#123; List&lt;String&gt; sourceList = new ArrayList&lt;String&gt;() &#123; &#123; add(\"H\"); add(\"E\"); add(\"L\"); add(\"L\"); add(\"O\"); add(\"W\"); add(\"O\"); add(\"R\"); add(\"L\"); add(\"D\"); &#125; &#125;; List&lt;String&gt; subList = sourceList.subList(2, 5); System.out.println(\"sourceList: \" + sourceList); System.out.println(\"sourceList.subList(2, 5)得到: \" + subList); subList.add(\"cc\"); System.out.println(\"sourceList: \" + sourceList); System.out.println(\"subList: \" + subList); &#125;&#125; 上面代码的执行结果又是什么呢？如果我们稍微思考一下，大致能正确的分析出结果： 答案 1234sourceList: [H, E, L, L, O, W, O, R, L, D]subList: [L, L, O]sourceList: [H, E, L, L, O, cc, W, O, R, L, D]subList: [L, L, O, cc] 我们向subList中添加一个元素，原列表sourceList在toIndex的位置插入了subList中add的元素，也就是我们在SubList中新增一个元素，同时会将这个元素添加到原List中。 JDK源码 我们查看SubList的源码，发现并没有add(E e)方法，那我们调用的add(“cc”)是调用到哪里去了呢？我们查看SubList类的声明，可以看到它是继承了AbstractList抽象类，所以这里应该是调用了超类里的add(E e)方法， 12345/** AbstractList.java */public boolean add(E e) &#123; add(size(), e); return true;&#125; 这里可以看到是调用了add(int index, E element)方法进行数据新增的，然而SubList里面实现了这个方法，那么我们来看下SubList中的这个方法实现： 123456789101112public void add(int index, E e) &#123; // 校验下标是否越界 rangeCheckForAdd(index); // 校验原List是否有过修改 checkForComodification(); // parent即是在构造器中注入的原List parent.add(parentOffset + index, e); // 同步列表修改次数 this.modCount = parent.modCount; // 本列表的长度+1 this.size++;&#125; 由SubList的源码可以看出，SubList实例的add方法实际上就是在修改原List，包括SubList中所有的方法均是在parent列表上进行操作。 3. 奇葩操作，最坑的坑 仔细分析如下代码： 12345678910111213141516public static void main(String[] args) &#123; List&lt;String&gt; sourceList = new ArrayList&lt;String&gt;() &#123; &#123; add(\"H\"); add(\"E\"); add(\"L\"); add(\"L\"); add(\"O\"); add(\"W\"); add(\"O\"); add(\"R\"); add(\"L\"); add(\"D\"); &#125; &#125;; List&lt;String&gt; subList = sourceList.subList(2, 5); System.out.println(\"sourceList: \" + sourceList); System.out.println(\"subList: \" + subList); sourceList.add(\"cc\"); System.out.println(\"sourceList: \" + sourceList); System.out.println(\"subList: \" + subList);&#125; 这段代码的执行结果是什么？在不执行这段代码的情况下，是不是以为是下面的结果？ 1234sourceList: [H, E, L, L, O, W, O, R, L, D]subList: [L, L, O]sourceList: [H, E, L, L, O, W, O, R, L, D, cc]subList: [L, L, O] 如果你说对，就是这个，那你可就说错咯，实际上在执行到System.out.println(&quot;sourceList: &quot; + sourceList);这一句代码的时候整个程序的输出都是正常的，但在执行最后一句代码的时候，就会报错了，错误信息是： 123456789Exception in thread \"main\" java.util.ConcurrentModificationException at java.util.ArrayList$SubList.checkForComodification(ArrayList.java:1239) at java.util.ArrayList$SubList.listIterator(ArrayList.java:1099) at java.util.AbstractList.listIterator(AbstractList.java:299) at java.util.ArrayList$SubList.iterator(ArrayList.java:1095) at java.util.AbstractCollection.toString(AbstractCollection.java:454) at java.lang.String.valueOf(String.java:2994) at java.lang.StringBuilder.append(StringBuilder.java:131) at cc.kevinlu.sublist.SubListTest.main(SubListTest.java:31) 哦吼~！竟然报错了，我们可以看到是在ArrayList$SubList.checkForComodificatio方法中报的错，我们来看一下这个方法： 12345private void checkForComodification() &#123; // 比较原列表修改次数和SubList的修改次数是否相等 if (ArrayList.this.modCount != this.modCount) throw new ConcurrentModificationException();&#125; 这里抛出异常，说明这两个数是不相等的，那为什么会不相等呢？我们看SubList的add方法中有同步主、'子’列表的语句this.modCount = parent.modCount;，也就是说我们在修改subList的时候，会同步更新主列表的modCount，以保证主、'子’列表始终是一致的。 但是我们在修改主List的时候是不会去同步SubList的modCount的，我们输出SubList的实例实际上就是调用iterator方法，最终是调用了SubList的public ListIterator&lt;E&gt; listIterator(final int index)方法，该方法第一句就是调用checkForComodification方法检查modCount，这里自然就会报错咯！ 4. 填坑 既然有坑，就有填坑的办法，不可能一直把坑放在那，是吧。 如果既想修改subList，又不想影响到原list。那么可以创建一个机遇subList的拷贝: 123451.创建新的List： subList = Lists.newArrayList(subList);2.lambda表达式： sourceList.stream().skip(fromIndex).limit(size).collect(Collectors.toList()); 5. 总结 并不是说使用SubList一定不妥，文章开头我们也说的是慎用，所以，根据具体业务进行选择吧。","categories":[{"name":"Java","slug":"Java","permalink":"http://luxiaowan.github.io/categories/Java/"}],"tags":[]},{"title":"Redis基本命令使用::zset篇","slug":"Redis基本命令使用—zset篇","date":"2019-11-08T04:55:00.000Z","updated":"2019-11-21T16:05:02.245Z","comments":true,"path":"2019/11/08/Redis基本命令使用—zset篇/","link":"","permalink":"http://luxiaowan.github.io/2019/11/08/Redis基本命令使用—zset篇/","excerpt":"","text":"Redis有6大基本类型，分别是字符串(String)、列表(List)、集合(set)、哈希结构(hash)、有序集合(zset)和基数(HyperLogLog) redis在线体验地址：http://try.redis.io/ 有序集合(ZSet) 介绍: Redis的有序集合和集合一样是一个简单的字符串集合，但该集合是有序的，且集合内的元素都是唯一的，也就是集合内不会出现重复元素，与集合唯一不同的是，有序集合中每一个元素都有一个double类型的score属性，Redis通过score的大小对元素进行排序的。有序集合中元素不能重复，但是元素的score值可以重复。 常用于做排行榜功能。 Redis中的集合是通过哈希表来实现的，所以获取集合中元素的时间复杂度为O(1)。 创建缓存 创建一个集合缓存，为集合新增元素 命令格式：zadd key score member [score member ...] 🌰 12345678zadd zk1 1 c 1 cc 1 ccc 2 cccc---创建有序集合zk1，元素为：key: c, score: 1key: cc, score: 1key: ccc, score: 1key: cccc, score: 2 创建一个元素或修改元素的score值（一次只能修改一个元素） 命令格式：zincrby key increment member 🌰 123456zincrby zk1 1 cc---1. 为集合zk1的元素cc的score进行+1操作2. 若集合zk1不存在，则创建3. 若元素cc不存在，则创建，且cc的score为1 查询缓存 查询缓存中元素个数 命令格式：zcard key 🌰 1234zcard zk1---查询集合zk1内的元素总个数 查询集合指定范围的元素 命令格式：zrange key start stop [withscores] 🌰 12345678910111213141. 返回元素名称zrange zk1 0 1---返回集合zk1中从下标0到下标1的元素名称，start和stop都是从0开始2. 返回元素和元素scorezrange zk1 0 -1 withscores---返回集合zk1中全部元素的名称和分数member1score1member2score2★常用于查询排行榜及分数 查询集合中某元素的下标（下标从0开始） 命令格式：zrank key member 🌰 1234zrank zk1 c---返回元素c在集合zk1中的下标 查询集合中某元素的分数 命令格式：zscore key member 🌰 12345zscore zk1 c---查询集合zk1中元素c的分数★常用于点赞数类别查询等 查询集合中指定范围的元素，按照score从大到小排序 命令格式：zrevrange key start stop [withscores] 🌰 1234zrevrange zk1 0 3 withscore---返回集合zk1中从1~4位元素，按照score从大到小 查询集合中某元素的排名 命令格式：zrevrank key member 🌰 12345zrevrank zk1 c---返回元素c在集合zk1中的排名★常用于名次查询 查询指定分数范围内的元素，可分页 命令格式：zrevrangebyscore key maxScore minScore [withscores] [limit offset count] 🌰 1234zrevrangebyscore zk1 3 2 withscores limit 0 1---分页返回集合zk1中分数从2~3的元素 查询指定成员区间内的成员 命令格式：zrangebylex key minChar maxChar [limit offset count] 🌰 1234zrangebylex zk1 - (c1 limit 0 12---返回从第一个元素到元素c1之间的位置 指令 是否必须 说明 ZRANGEBYLEX 是 指令 key 是 有序集合键名称 minChar 是 字典中排序位置较小的成员,必须以”[“(包含)开头,或者以”(“(不包含)开头,可使用”-“代替，&quot;-&quot;表示取最小值 maxChar 是 字典中排序位置较大的成员,必须以”[“(包含)开头,或者以”(“(不包含)开头,可使用”+”代替，&quot;+&quot;表示取最大值 limit 否 返回结果是否分页,指令中包含LIMIT后offset、count必须输入 offset 否 返回结果起始位置 count 否 返回结果数量 查询指定分数区间内的元素数 命令格式：zcount key min max 🌰 12345zcount zk1 1 2---返回score值为1~2的所有元素总数★计算排行榜中某一分数区间的数量 查询指定元素区间内的元素总数 命令格式：zlexcount key min max 🌰 1234zlexcount zk1 (c [cccc---查询c~cccc之间的元素总数，不包括c，但包括cccc 移除缓存元素 移除集合中指定的元素 命令格式：zrem key member [member ...] 🌰 1234zrem zk1 cc c1---移除集合zk1中的元素cc、c1 移除指定元素区间的所有成员 命令格式：zremrangebylex key min max 🌰 1234zremrangebylex zk1 [c (ccc---移除集合zk1中元素c到元素ccc之间的所有成员，包括c，但不包括ccc 移除指定排名区间所有成员 命令格式：zremrangebyrank key start stop 🌰 1234zremrangebyrank zk1 0 1---移除集合zk1中0~1下标的所有元素 移除指定分数区间所有成员 命令格式：zremrangebyscore key min max 🌰 1234zremrangebyscore zk1 0 1---移除集合zk1中score值为0~1的所有元素 特殊操作 计算多个集合的并集，并存入新的集合 命令格式：zunionstore destinationKey numkeys key[key ...] 🌰 1234zunionstore zku 2 zk1 zk2---合并集合zk1和zk2，将并集存入zku，集合zku中元素的score为所有参与计算的集合中相同的元素的score之和","categories":[{"name":"Redis","slug":"Redis","permalink":"http://luxiaowan.github.io/categories/Redis/"}],"tags":[]},{"title":"Java命令::jstat","slug":"Java命令—jstat","date":"2019-11-08T04:00:00.000Z","updated":"2019-11-10T15:57:22.417Z","comments":true,"path":"2019/11/08/Java命令—jstat/","link":"","permalink":"http://luxiaowan.github.io/2019/11/08/Java命令—jstat/","excerpt":"","text":"jstat是用于监控虚拟机运行状态信息的命令，可以显示虚拟机进程中的类装载、内存使用、GC情况、JIT编译等运行状态数据，能够在Linux上快速定位虚拟机性能问题。 jstat命令在jdk的bin目录下，目录中还有很多实用的命令 *以下分析是基于jdk1.8+ jstat命令格式： 123456789jstat -&lt;option&gt; &lt;pid&gt; [&lt;interval&gt; [&lt;count&gt;]]--- option: 需要查看的虚拟机信息 pid: Java程序进程号 本地虚拟机: pid 远程虚拟机: [protocol:][//] lvmid [@hostname[:port]/servername] interval: 监控间隔时间，可选，默认立刻执行一次 count: 监控次数，可选，默认无限次 option 说明 class 查看类装载、卸载数量、总空间及类装载所耗时间 gc 查看Java堆状况，包括Eden、survivor、老年代、永久代的容量 gcutil 类似于gc，主要输出各区域空间使用占比 gccause 同gc，会多输出每次gc的原因 gccapacity 同gc，但输出的主要是Java堆各个区域使用到的最大、最小空间 gcnew 查看新生代的使用情况 gcnewcapacity 同gcnew，输出内容主要关注新生代的最大、最小空间 gcold 查看老年代的使用情况 gcoldcapacity 同gcold，输出内容主要关注老年代的最大、最小空间 gcpermcapacity 输出永久代使用到的最大、最小空间 compiler 输出JIT编译器编译过的方法、耗时等信息 printcompilation 输出已经被JIT编译的方法 🌰 jstat -class : 显示加载class的数量及所占空间等信息 12345678910[root@master0 ~]# jstat -class 19080Loaded Bytes Unloaded Bytes Time 11512 22276.9 268 421.6 18.41 ---Loaded: 装载类的数量Bytes: 装载类所占用的字节数Unloaded: 卸载类的数量Bytes: 卸载类所占用的字节数Time: 装载和卸载类所花费的时间 jstat -gc : 显示gc的信息，查看gc的次数和时间 1234567891011121314151617181920212223，等于YGCT + FGCT[root@master0 ~]# jstat -gc 19080 1000 1 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 6656.0 6656.0 0.0 3761.4 94208.0 51469.2 73728.0 50832.0 - - - - 20207 92.896 37 7.833 100.729---[容量为字节]S0C: 年轻代第一个survivor区的总容量（survivor 0 capacity）S1C: 年轻代第二个survivor区的总容量（survivor 1 capacity）S0U: 年轻代第一个survivor区的已使用容量（survivor 0 using）S1U: 年轻代第二个survivor区的已使用容量（survivor 1 using）EC: 年轻代Eden区的总容量（Eden capacity）EU: 年轻代Eden区的已使用容量（Eden using）OC: 老年代的总容量（Old capacity）OU: 老年代已使用的容量（Old using）MC: Metaspace的总容量, jdk1.8+MU: Metaspace已使用的容量, jdk1.8+CCSC:压缩类空间容量, jdk1.8+CCSU:压缩类空间已使用的容量, jdk1.8+YGC: 服务启动至今年轻代gc的次数（young gc）YGCT: 服务启动至今年轻代gc使用的时间，秒（young gc time）FGC: 服务启动至今fullgc的次数FGCT: 服务启动至今fullgc使用的时间，秒GCT: 服务启动至今gc用的总时间，秒，等于YGCT + FGCT jstat -gcutil : 统计gc信息 123456789101112131415161718[root@master0 ~]# jstat -gcutil 19080 1000 3 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 48.90 20.83 69.35 - - 20221 93.006 37 7.833 100.838 0.00 48.90 20.83 69.35 - - 20221 93.006 37 7.833 100.838 0.00 48.90 20.83 69.35 - - 20221 93.006 37 7.833 100.838---S0: 年轻代第一个survivor已使用容量比例S1: 年轻代第二个survivor已使用容量比例E: 年轻代Eden区已使用容量比例O: 老年代已使用容量比例M: 元空间已使用容量比例CCS: 压缩类空间已使用容量比例YGC: 服务启动至今年轻代gc次数YGCT: 服务启动至今年轻代gc所占用时间，秒FGC: 服务启动至今fullgc次数FGCT: 服务启动至今fullgc所占用时间，秒GCT: 服务启动至今gc总占用时间，秒，等于YGCT + FGCT jstat -gccause : 查看gc原因 12345678[root@master0 ~]# jstat -gccause 19080 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT LGCC GCC 57.32 0.00 13.35 69.36 - - 20222 93.015 37 7.833 100.848 Allocation Failure No GC ---上述可以看到比-gcutil多处了一个LGCC和GCCLGCC: 最近一次gc发生的原因（last gc cause）GCC: 当前gc发生的原因 jstat -gccapacity : 查看虚拟机中对象的使用和容量大小 12345678910[root@master0 ~]# jstat -gccapacity 19080 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 20480.0 323584.0 112640.0 7680.0 6656.0 96768.0 40448.0 647168.0 73728.0 73728.0 - - - - - - 20223 37---[容量单位为字节]NGC开头的表示：新生代空间容量OGC开头的表示：老年代空间容量MC开头的表示：元空间容量（Metaspace capacity）CCS开头的表示：类压缩空间 jstat -gcnew : 查看新生代gc情况 123456789[root@master0 ~]# jstat -gcnew 19080 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT 7680.0 6656.0 0.0 6354.4 15 15 7680.0 96768.0 95634.9 20223 93.023---[容量单位为字节]TT: 老年化阈值，也可以理解为对象持有次数，就是在被移动到老年代之前，在新生代中存活的次数MTT: 最大老年化阈值DSS: Survivor区所需空间大小 jstat -gcnewcapacity : 查看新生代空间容量 123456789101112[root@master0 ~]# jstat -gcnewcapacity 19080 NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 20480.0 323584.0 112128.0 107520.0 7168.0 107520.0 7168.0 322560.0 97280.0 20225 37---[容量单位为字节]MN表示：最小MX表示：最大NGC开头表示：新生代空间总容量S0C开头：新生代第一个survivor区容量S1C开头：新生代第二个survivor区容量EC开头：新生代Eden区容量 jstat -gcold : 查看老年代gc情况 1234567[root@master0 ~]# jstat -gcold 19080 1000 MC MU CCSC CCSU OC OU YGC FGC FGCT GCT - - - - 73728.0 51144.0 20234 37 7.833 100.943 - - - - 73728.0 51144.0 20234 37 7.833 100.943---[容量单位为字节] jstat -gcoldcapacity : 查看老年代容量 1234[root@master0 ~]# jstat -gcoldcapacity 19080 100 2 OGCMN OGCMX OGC OC YGC FGC FGCT GCT 40448.0 647168.0 73728.0 73728.0 20235 37 7.833 100.949 40448.0 647168.0 73728.0 73728.0 20235 37 7.833 100.949 jstat -gcpermcapacity : 查看perm中对象的信息和容量 1jdk1.8+以上去除了该命令，如果你当前使用的是jdk1.7-，那么自行谷歌吧 jstat -compiler : 查看虚拟机实时编译的信息 1234567891011[root@master0 ~]# jstat -compiler 19080Compiled Failed Invalid Time FailedType FailedMethod 2737 0 0 41.90 0 ---Compiled: 编译任务执行数量Failed: 编译任务执行失败数量Invalid: 编译任务执行失效数量Time: 编译任务消耗的时间FailedType: 最后一个编译失败任务的类型FailedMethod: 最后一个编译失败的任务所在类及方法 jstat -printcompilation : 查看虚拟机已经编译过的方法 123456789[root@master0 ~]# jstat -printcompilation 19080Compiled Size Type Method 2737 1562 1 sun/misc/FloatingDecimal dtoa---Compiled: 编译任务的数量Size: 方法生成字节码的大小（单位：字节）Type: 编译类型Method: 类名和方法名用来标识编译的方法","categories":[{"name":"Java","slug":"Java","permalink":"http://luxiaowan.github.io/categories/Java/"}],"tags":[]},{"title":"Redis基本命令使用::list篇","slug":"Redis基本命令使用—list篇","date":"2019-10-31T04:55:00.000Z","updated":"2019-10-31T17:23:56.890Z","comments":true,"path":"2019/10/31/Redis基本命令使用—list篇/","link":"","permalink":"http://luxiaowan.github.io/2019/10/31/Redis基本命令使用—list篇/","excerpt":"","text":"Redis有6大基本类型，分别是字符串(String)、列表(List)、集合(set)、哈希结构(hash)、有序集合(zset)和基数(HyperLogLog) redis在线体验地址：http://try.redis.io/ 列表(List) 介绍: Redis的列表就是一个简单的字符串列表，我们可以往列表的头部和尾部添加新数据，要可以根据下标修改下标对应的值，列表是按照插入顺序有序的（按插入顺序倒序，类似于栈），并且列表可以出现重复数据。可以做消息队列，不过需要注意的是可能需要消息去重(后面有更牛的)。 创建缓存 创建一个列表缓存 命令格式：lpush key value [value ...] 🌰 1234lpush c1 1 2 3 4 5 6 7 8 9---将1~9放入c1列表中，此时列表中存储顺序为9 8 7 6 5 4 3 2 1 向列表左侧新增值 命令格式：lpush key value [value ...] 🌰 1234lpush c1 10---将10放入到c1列表头部，此时列表中存储顺序为10 9 8 7 6 5 4 3 2 1 向列表右侧新增值 命令格式：rpush key value [value ...] 🌰 1234rpush c1 0---将0放入到c1列表尾部，此时列表中存储顺序为10 9 8 7 6 5 4 3 2 1 0 以上两个命令很容易理解，lpush—&gt;left push, rpush—&gt;right push 在列表指定元素前/后插入数据 命令格式：linsert key BEFORE|AFTER pivot value 🌰 123456789101112131415161718192021221) linsert c1 after 0 -1---将-1插入到元素值0之前，此时列表中存储顺序为10 9 8 7 6 5 4 3 2 1 0 -12)linsert c1 before 0 1---将1插入到元素值0之前，此时列表中存储顺序为10 9 8 7 6 5 4 3 2 1 1 0 -13)linsert c1 before 1 3---将3插入到元素值1之前，此时列表中存储顺序为10 9 8 7 6 5 4 3 2 3 1 1 0 -14)linsert c1 after 1 4---将4插入到元素值1之后，此时列表中存储顺序为10 9 8 7 6 5 4 3 2 3 1 4 1 0 -15)linsert c1 after 99 100---失败** 由3、4操作可以得出结论，当执行linsert指令时，列表是从头部开始进行遍历，直到查询到与pivot元素相同的值时停止，根据AFTER、BEFORE选择是插入到元素后还是元素前，所以划重点：若列表中存在pivot的重复元素，linsert只会以第一个遍历到的元素为准** 由5可以得出结论，若指定的pivot元素不存在于列表中，则不进行任何设置 通过索引下标设置值 命令格式：lset key index value 🌰 12345671)lset c1 0 21---将下标为0的元素修改为21，此时列表中存储顺序为21 9 8 7 6 5 4 3 2 3 1 4 1 0 -12)lset c1 99 99---ERR index out of range,说明通过lset命令，不能越界修改元素 向已存在的列表头部添加元素 命令格式：lpushx key value [value ...] 🌰 12345671)lpushx c1 22 23 24---将22、23、24添加到列表c1头部，列表变为：24 23 22 21 9 8 7 6 5 4 3 2 3 1 4 1 0 -12)lpushx c2 1 2 3---因为列表c2不存在，所以设置失败，此时使用lrange查看c2会返回空 向已存在的列表尾部添加元素 命令格式：rpushx key value [value ...] 🌰 12345671)rpushx c1 -2 -3---将-2、-3添加到列表c1尾部，列表变为：24 23 22 21 9 8 7 6 5 4 3 2 3 1 4 1 0 -1 -2 -32)rpushx c2 1 2 3---因为列表c2不存在，所以设置失败，此时使用lrange查看c2会返回空 截取列表 命令格式：ltrim key start end 🌰 123ltrim c1 4 16---列表下标从0开始，截取5~17位的元素，列表c1变为：9 8 7 6 5 4 3 2 3 1 4 1 0 查看缓存 查看列表内所有元素 命令格式：lrange key 0 -1 🌰 1234lrange c1 0 -1---获取列表c1的所有元素 查看列表某一范围内的元素 命令格式：lrange key start end 🌰 1234lrange c1 1 3---查看列表c1中弟2~4位上的元素 弹出列表头部元素 命令格式：lpop key 🌰 1234lpop c1---弹出列表c1的头部元素9，此时列表c1变为：8 7 6 5 4 3 2 3 1 4 1 0，头部的9已经没有了，是不是很适合做消息队列 弹出列表尾部元素 命令格式：rpop key 🌰 1234rpop c1---弹出c1的尾部元素0，此时列表c1变为：8 7 6 5 4 3 2 3 1 4 1，尾部的0已经没有了，是不是很适合做消息队列👀 弹出列表头部元素，若当前列表内无元素，则阻塞，直到获取到或达到超时时间 命令格式：blpop key [key ...] timeout timeout单位为***秒*** 🌰 12345blpop c1 c2 c3 10---弹出列表c1或列表c2/c3的头部元素，只要c1、c2、c3有一个列表中有元素被弹出，则结束阻塞若c1、c2、c3均有元素，则返回第一个满足弹出条件的列表，然后结束阻塞 弹出列表尾部元素，若当前列表内无元素，则阻塞，直到获取到或达到超时时间 命令格式：brpop key [key ...] timeout timeout单位为***秒*** 🌰 12345blpop c1 c2 c3 10---弹出列表c1或列表c2/c3的尾部元素，只要c1、c2、c3有一个列表中有元素被弹出，则结束阻塞若c1、c2、c3均有元素，则返回第一个满足弹出条件的列表，然后结束阻塞 获取列表指定位置的元素 命令格式：lindex key index 🌰 12345671)lindex c1 2---返回列表c1中下标为2的元素，仅仅返回数据，不弹出，时间复杂度O(1)2)lindex c1 -1---返回列表最后一个元素。列表元素下标-1代表列表中最后一个元素，所以列表是可以通过负数下标从后往前遍历 弹出一个列表中的最后一个元素到另外一个列表头部，并返回这个元素——无阻塞 命令格式：rpoplpush source_key destination_key 🌰 1234rpoplpush c1 c2---弹出列表c1的尾部元素插入到列表c2的头部，若c1为空，则返回nil，但不插入到c2中，是不是更适合做队列 弹出一个列表中的最后一个元素到另外一个列表头部，并返回这个元素——阻塞 命令格式：brpoplpush source_key destination_key timeout timeout单位为***秒*** 🌰 1234brpoplpush c3 c2 10---弹出列表c3的尾部元素插入到列表c2的头部，若c3为空，则阻塞等到列表c3中有值，否则等到了10秒后结束阻塞返回nil，是不是更适合做阻塞队列 其他命令 删除指定范围内等于某个值的所有元素 命令格式：lrem key index element 🌰 1234567891011121314151)lrem c1 -2 3---移除列表c1中，从倒数第二个元素到列表头部范围内所有的32)lrem c1 3 2---移除列表c1中，从第四位元素到尾部范围内所有的23)lrem c1 0 1---移除列表c1中所有的14)lrem c1 -1 4---移除列表c1中所有的4 查看列表长度 命令格式：llen key 🌰 1234llen c1---查看列表c1的总长度，若c1不存在，则返回0，不会报错，记住，若列表不存在也不会报错","categories":[{"name":"Redis","slug":"Redis","permalink":"http://luxiaowan.github.io/categories/Redis/"}],"tags":[]},{"title":"Redis基本命令使用::set篇","slug":"Redis基本命令使用—set篇","date":"2019-10-31T04:55:00.000Z","updated":"2019-11-10T15:57:22.418Z","comments":true,"path":"2019/10/31/Redis基本命令使用—set篇/","link":"","permalink":"http://luxiaowan.github.io/2019/10/31/Redis基本命令使用—set篇/","excerpt":"","text":"Redis有6大基本类型，分别是字符串(String)、列表(List)、集合(set)、哈希结构(hash)、有序集合(zset)和基数(HyperLogLog) redis在线体验地址：http://try.redis.io/ 集合(Set) 介绍: Redis的集合就是一个简单的字符串集合，该集合是无序的，且集合内的元素都是唯一的，也就是集合内不会出现重复元素。Redis中的集合是通过哈希表来实现的，所以获取集合中元素的时间复杂度为O(1)。 创建缓存 创建一个集合缓存，为集合新增元素 命令格式：sadd key member [member ...] 🌰 1234sadd s1 1 2 3 0 -1 redis mongodb zookeeper---创建集合s1,元素为：1 2 3 0 -1 redis mongodb zookeeper 移除元素 随机移除集合中的一个元素并返回这个元素 命令格式：spop key 🌰 1234spop s1---移除之后，集合s1中就没有这个元素了 指定移除集合中一个或多个元素 命令格式：srem key member [member ...] 🌰 1234srem s1 -1 0 99---将元素-1、0、99从集合s1中移除，仅移除集合中存在的元素 查询集合 查询集合中元素个数 命令格式：scard key 🌰 1234scard s1---返回集合s1中元素总个数 返回集合中所有元素 命令格式：smembers key 🌰 1234smembers s1---返回集合s1中所有的元素 随机返回集合中的一个或多个元素 命令格式：srandmember key [count] 🌰 1234srandmember s1 10---随机返回集合s1中的10个元素，若不指定数量，则默认返回一个元素 迭代集合中的元素 命令格式：sscan key cursor [MATCH pattern] [COUNT count] 🌰 1234sscan s1 0 match re* count 1---迭代集合中re开头的所有元素，每次返回1个 判断元素是否存在于集合中 命令格式：sismember key member 🌰 1234sismember s1 99---若99存在于s1中，则返回1，不存在则返回0 多集合之间操作 查看多个集合的差集 命令格式：sdiff key [key ...] 🌰 1234sdiff s1 s2 s3---返回集合s1相对于s2、s3的差集，也就是只返回s1中所有不存在于s2、s3中的所有元素 多个集合的差集存储到指定集合中 命令格式：sdiffstore destination key [key ...] 🌰 1234sdiffstore ds1 s1 s2 s3---将s1中不存在于s2、s3中的元素存储到集合ds1中 查看多个集合的并集，去重 命令格式：sunion key [key ...] 🌰 1234sunion s1 s2 s3---将集合s1、s2、s3的元素合并去重后返回，所有元素均唯一 多个集合的并集存储到指定集合中 命令格式：sunionstore destination key [key ...] 🌰 1234sunionstore us1 s1 s2 s3---集合s1、s2、s3的并集存储到集合us1中，并返回集合us1中的元素个数 将一个集合中的某元素移动到另一个集合中 命令格式：smove source destination member 🌰 1234smove s1 s2 -2---将s1中的元素-2移动到集合s2中，若s2不存在，则自动创建 查看多个集合的交集 命令格式：sinter key [key ...]（intersection） 🌰 123456sinter s1 s3---返回集合s1和集合s3的交集，也就是两个集合中都存在的数据实际应用：查看两个人的共同好友；微信里查看和好友的共同群 多个集合的交集存储到指定集合中 命令格式：sinterstore destination key [key ...] 🌰 1234sinterstore is1 s1 s3---将s1和s3的交集元素存储到集合is1中","categories":[{"name":"Redis","slug":"Redis","permalink":"http://luxiaowan.github.io/categories/Redis/"}],"tags":[]},{"title":"Redis基本命令使用::hash篇","slug":"Redis基本命令使用—hash篇","date":"2019-10-30T15:55:00.000Z","updated":"2019-10-31T16:05:56.510Z","comments":true,"path":"2019/10/30/Redis基本命令使用—hash篇/","link":"","permalink":"http://luxiaowan.github.io/2019/10/30/Redis基本命令使用—hash篇/","excerpt":"","text":"Redis有6大基本类型，分别是字符串(String)、列表(List)、集合(set)、哈希结构(hash)、有序集合(zset)和基数(HyperLogLog) redis在线体验地址：http://try.redis.io/ 哈希(Hash) 介绍: Redis hash 是一个存储多个键值对的映射表，适用于存储对象的属性，比如存储用户信息、用户Session信息等。在实际项目中使用的频率比较多，之前主要用于存储用户基本信息、用户临时订单信息、产品信息等。 创建缓存 创建一个缓存 命令格式：hset key field value 🌰 1234hset cc name 'cc'---将cc的name属性的值设置为cc 批量创建缓存 命令格式：hmset key filed value [field value ...] 🌰 1234hmset cc name 'cc' age 19 avatar 'a.png' status 1---设置cc对象的name、age、avatar、status属性的值 设置一个key不存在field的value，若field已存在则不设置 命令格式：hsetnx key field value 🌰 1234hsetnx cc name 'yy'---若对象cc的name属性不存在，则设置cc的name属性值为yy 查看缓存 查看key下所有属性+值 命令格式：hgetall key 🌰 12345678hgetall cc---获取对象cc的所有属性，返回数据格式： field1 value1 field2 value2 查看key下所有的值 命令格式：hvals key 🌰 12345hvals cc---返回cc对象的所有属性的值，仅返回值，不返回属性名称等同于 ”hmget key 所有field“ 命令 查看key下所有的field名称 命令格式：hkeys key 🌰 1234hkeys cc---返回对象cc的所有属性名 查看key的某一field的值 命令格式：hget key field 🌰 1234hget cc name---返回对象cc的name属性的值，若对象无此属性，则返回nil 查看key的多个field的值 命令格式：hmget key field [field ...] 🌰 1234hmget cc name age status---返回对象cc的name、age、status属性 迭代对象的所有属性(适用于大对象) 命令格式：hscan key course [MATCH pattern] [COUNT num] 🌰 1hscan cc 0 MATCH *e COUNT 1 查看对象的属性数 命令格式：hlen key 🌰 1234hlen cc---返回对象cc的属性数量 其他命令 删除一个/多个属性 命令格式：hdel key field [field ...] 🌰 1234hdel cc name age---删除对象cc的name、age属性 查看对象属性是否存在 命令格式：hexists key field 🌰 1234hexists cc name---对象cc若存在属性name，则返回1，不存在则返回0","categories":[{"name":"Redis","slug":"Redis","permalink":"http://luxiaowan.github.io/categories/Redis/"}],"tags":[]},{"title":"Redis基本命令使用::string篇","slug":"Redis基本命令使用—string篇","date":"2019-10-29T15:55:00.000Z","updated":"2019-10-30T16:43:50.550Z","comments":true,"path":"2019/10/29/Redis基本命令使用—string篇/","link":"","permalink":"http://luxiaowan.github.io/2019/10/29/Redis基本命令使用—string篇/","excerpt":"","text":"Redis有6大基本类型，分别是字符串(String)、列表(List)、集合(set)、哈希结构(hash)、有序集合(zset)和基数(HyperLogLog) redis在线体验地址：http://try.redis.io/ 字符串(String) 介绍: 字符串是Redis中最基本的数据类型，数据以二进制的形式存储于内存中，所以Redis的字符串可以是任何形式的数据，比如JPEG图像、序列化的Ruby对象等。 字符串最大可存储512MB的数据，但一般一个字符串容量过大，会直接影响存储和查询的效率。字符串有两种编码方式：raw和embstr，根据字符串长度自动选择使用哪一种编码，目前最新版的长度是44个字节，字符串长度小于等于44个字节，则使用embstr编码，大于44个字节则使用raw编码，两种编码方式这里就不作详解，有兴趣的可以谷歌一下。 创建缓存 创建一个缓存 命令格式：set key value 🌰 1234set cc 'niubility'---创建一个key为cc，值为niubility的缓存 批量创建缓存 命令格式：mset key value [key value ...] 🌰 1234mset cc1 1 cc2 2 cc3 3---创建三个缓存，key:value分别为cc1:1, cc2:2, cc3:3 命令格式：msetnx key value [key value ...] 🌰 12345msetnx cc1 11 cc2 22 cc5 5 cc6 6---此命令只会将尚不存在的key值创建到缓存中，已经存在的key则忽略* cc1、cc2已存在于缓存中，所以不会创建/更新成功，cc5、cc6不存在于缓存中，会创建 创建一个带过期时间的缓存 命令格式：setex key time value 🌰 1234setex cc1 10 234---设置key:value为cc1:234且过期时间为10秒的缓存 设置一个不存在key的value，若key已存在则不设置 命令格式：setnx key value 🌰 1234setnx cc5 12---若cc5的key不存在于缓存中，则创建key:value为cc5:12的缓存，否则不执行创建 组合创建一个缓存(缓存过期时间、是否覆盖) 命令格式：set key value [EX|PX time] [NX|XX] 解析： 1234567 EX：表明过期时间为秒 PX：表明过期时间为毫秒 NX：若key不存在则执行，否则不执行，与XX相反 XX：若key存在则执行，否则不执行，与NX相反 🌰 1234 set cc1 123 EX 20 XX --- 若cc1已存在则创建过期时间为20秒的key:value = cc1:123 将key设置为新值的同时返回原值 命令格式：getset key value 🌰 1234getset cc1 1---若key不存在，则返回nil 读取缓存 读取一个key的缓存值 命令格式：get key 🌰 1234get cc1---读取key=cc1的值 批量读取一批数据 命令格式：mget key [key ...] 🌰 1mget cc1 cc2 cc3 截取字符串并返回 命令格式：getrange key start end 🌰 1234getrange cc1 1 12---字符串下标以0开始，若start超出字符串长度或key不存在，则返回空字符串 其他操作 将value加1( value必须为整数 )[ 可用于阅读量、点赞数等简单统计类的功能应用 ] 命令格式：incr key 🌰 1234incr cc1---每次调用均对value进行+1操作 给value加上某个数( num必须为整数 ) 命令格式：incrby key num 🌰 1234incrby cc1 100---给cc1的值加上100 给value加上某个浮点数 命令格式：incrbyfloat key num 🌰 1incrbyfloat cc1 0.2 给value减1 命令格式：decr key 🌰 1234decr cc1---每次调用均对value进行-1操作 给value减去某个数( num必须为整数 ) 命令格式：descby key num 🌰 1234decrby cc1 100---给cc1的值减去100 查看value的长度 命令格式：strlen key 🌰 1strlen cc1 目前先整理这些，都是一些基础的命令，随后再写一篇Java中使用Jedis操作字符串的随笔。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://luxiaowan.github.io/categories/Redis/"}],"tags":[]},{"title":"Redis数据在内存中是如何存储的","slug":"Redis数据在内存中是如何存储的","date":"2019-10-29T08:50:00.000Z","updated":"2019-10-29T15:02:17.269Z","comments":true,"path":"2019/10/29/Redis数据在内存中是如何存储的/","link":"","permalink":"http://luxiaowan.github.io/2019/10/29/Redis数据在内存中是如何存储的/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://luxiaowan.github.io/categories/Redis/"}],"tags":[]},{"title":"MySQL索引什么时候用hash","slug":"MySQL索引什么时候用hash","date":"2019-10-28T11:06:00.000Z","updated":"2019-10-29T14:10:04.447Z","comments":true,"path":"2019/10/28/MySQL索引什么时候用hash/","link":"","permalink":"http://luxiaowan.github.io/2019/10/28/MySQL索引什么时候用hash/","excerpt":"","text":"MySQL索引是在面试中常被问到的知识点，常用的两种索引方法有Hash和B+Tree，树的结构我们改天再扯，今天说收Hash。 为什么使用hash Hash索引可以根据数据的hash值直接定位到索引数据的存储位置，就相当于我知道了数组的下标，然后根据下标去取数据，这个效率可以说是最高的了，使用hash就是为了如此。 支持hash的存储引擎 目前支持hash的引擎有MEMORY(这里需要谷歌)，其他的引擎都通过各自的方式去支持hash方法。如InnoDB有一套自适应hash算法，内部实现还是采用了BT的方式，可以理解为BT索引的索引 InnoDB中hash索引支持的开启/关闭 hash索引虽然非常快速，但是在InnoDB中确实支持的不是很好，并且索引的具体创建是由引擎决定的(创建后存在于内存中)，非DBA可控，所以一般情况下建议关闭hash支持，使用BT也能够满足性能要求。 ​ set global innodb_adaptive_hash_index=off/on hash的使用场景 hash使用场景比较局限 hash索引仅适用于‘=’、‘&lt;=&gt;’和‘in’操作，所以hash仅仅适用于精确查找。 不适用于查询排序，因为hash后的数据并不会像原数据一样保持有序。 不适用于模糊查询，也就是不能使用like关键字。 既然不支持排序，也肯定不支持范围查询咯 解决hash冲突 不论hash的算法多么精确，当数据量大的时候都有可能发生hash碰撞，解决hash碰撞的方法有很多，比如再hash、链表叠加等，MySQL采用的是链表叠加的方式，也就是类似于HashMap解决hash碰撞的方法。所以在发生hash碰撞过多的情况下，使用hash索引会影响查询性能。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://luxiaowan.github.io/categories/MySQL/"}],"tags":[]},{"title":"Spring-Session和Redis实现Session共享","slug":"Spring-Session和Redis实现Session共享","date":"2019-10-24T11:30:00.000Z","updated":"2019-10-24T15:18:45.220Z","comments":true,"path":"2019/10/24/Spring-Session和Redis实现Session共享/","link":"","permalink":"http://luxiaowan.github.io/2019/10/24/Spring-Session和Redis实现Session共享/","excerpt":"","text":"需求 现在大部分服务都以集群负载均衡的方式部署，几乎很难再遇到单点部署的项目，因为大家都要保证最基本的HA，说到HA，第一要考虑的就是各系统之间的Session共享的问题，如何解决呢？负载均衡当前使用Nginx 分析 不同的POD之间如果需要达到数据共享的目的，那么则需要使用同一个存储媒介，一开始想到使用MySQL来存储登录session，但是每次请求都去MySQL中查询数据，开销还是非常大的；然后最近使用MongoDB比较嗨，想着用MongoDB，但是MongoDB查询起来也不方便，况且我们这个Session也不是量级很大的数据集，最终采用了内存级的Redis来解决这个问题。 使用Redis的基本操作是将jsessionId为key，用户信息为value，使用jedis或者redisTemplate来操作Redis的读写行为。但是这种方式侵入了业务代码，并不是最优解，查了部分资料之后，发现spring-session.jar包中有一个非常有特色的注解@EnableRedisHttpSession，可以不需要侵入业务代码就能使用redis实现session共享的问题。 我们看一下@EnableRedisHttpSession的源码是怎么说的： 将此注释添加到一个单独的类上，该类必须加上@Configuration注解。使用方式在注释里也给出了demo代码。 实现 修改pom.xml文件，引入我们需要的jar包 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 修改application.yml文件，配置redis信息 1234spring.redis.database=0spring.redis.host=localhostspring.redis.port=6379spring.redis.password=123456 创建配置类 1234567import org.springframework.context.annotation.Configuration;import org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSession;@Configuration@EnableRedisHttpSessionpublic class RedisHttpSessionConfig &#123;&#125; 到此，我们使用Redis实现Session共享的所有配置和代码都已经写完了，可以看到我们没有侵入到任何业务代码中，从头到尾也很简单。 扩展 1234@EnableGemFireHttpSession@EnableSpringHttpSession@EnableMongoHttpSession@EnableJdbcHttpSession","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://luxiaowan.github.io/categories/SpringBoot/"}],"tags":[]},{"title":"Java简单操作MongoDB","slug":"Java简单操作MongoDB","date":"2019-10-24T02:16:00.000Z","updated":"2019-10-24T13:20:12.762Z","comments":true,"path":"2019/10/24/Java简单操作MongoDB/","link":"","permalink":"http://luxiaowan.github.io/2019/10/24/Java简单操作MongoDB/","excerpt":"","text":"前面已经掌握了mongo最基本的一些命令，对各个命令也都实操过，理解各命令的意思，也对mongo有了最基本的理解，但大部分猿还是想使用Java去连接mongo，串串也不例外 在pom.xml中加入mongodb-java-driver.jar的依赖 Maven项目依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.mongodb&lt;/groupId&gt; &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt; &lt;version&gt;3.0.4&lt;/version&gt;&lt;/dependency&gt; SpringBoot项目依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 连接mongo 认证连接 12345678// 创建验证信息，根据加密方式选择MongoCredential内对应的加密方式List&lt;MongoCredential&gt; credentials = new ArrayList&lt;&gt;();MongoCredential credential = MongoCredential.createCredential(\"admin\", \"test1\", \"admin\".toCharArray());credentials.add(credential);// 创建mongo服务地址ServerAddress serverAddress = new ServerAddress(\"localhost\", 27017);MongoClient mongoClient = new MongoClient(serverAddress, credentials); 无需认证连接 1MongoClient client = new MongoClient(\"localhost\", 27017); 然后就可以通过MongoClient的实例方法对mongo进行相关操作了 创建数据库连接 1MongoDatabase db = client.getDatabase(\"test1\"); mongo特性是不管数据库事先是否存在，都可以正常创建数据库连接，不会像MySQL一样报错，连接成功后，在mongo服务器上执行show dbs，会发现仍然查不到我们连接的这个数据库，这是正常情况，只有在数据库中有数据的时候，才会查得出来，client.getDatabase(&quot;test&quot;) === use test命令 创建集合 使用数据库连接实例方法创建一个空的集合 1234db.createCollection(\"base_info\");--- 命令：db.createCollection(\"base_info\") 直接向创建的集合中插入数据 12345MongoCollection&lt;Document&gt; collection = db.getCollection(\"base_info\");collection.insertOne(new Document(\"name\", \"lxl\"));--- 命令：db.base_info.insert(&#123;\"name\": \"lxl\"&#125;) 以上两种方式均可创建一个集合，区别在于第一种方式创建的是空集合， 删除集合 1234collection.drop();--- 命令：db.base_info.drop() 对集合的CRUD 新增数据 单条新增 12Document document = new Document().append(\"name\",\"cc\").append(\"age\",30).append(\"location\",\"SZ\");collection.insertOne(document); 批量新增 123456List&lt;Document&gt; documentList = new ArrayList&lt;&gt;();for (int i = 0; i &lt; 1000; i++) &#123; Document doc = new Document().append(\"name\", \"cc\" + i).append(\"age\", new Random().nextInt(100)).append(\"location\", \"SZ\"); documentList.add(doc);&#125;collection.insertMany(documentList); insertOne(Document)方法每次插入一条数据 insertMany(List)方法批量插入数据，并且可以通过参数InsertManyOptions设置是否排序 删除数据 删除第一条匹配的数据 12345Bson condition = Filters.eq(\"age\", 99);collection.deleteOne(condition);--- 命令：db.base_info.deleteOne(&#123;\"age\": 99&#125;) 删除所有匹配数据 12345Bson condition = Filters.eq(\"age\", 99);collection.deleteMany(condition);--- 命令：db.base_info.deleteMany(&#123;\"ag\": 99&#125;) 查询数据 查询返回第一条匹配的数据 1234Bson condition = Filters.eq(\"age\", 16);FindIterable&lt;Document&gt; vals = collection.find(condition);Document document = vals.first();System.out.println(document.toJson()); 通过调用FindIterable的实例方法first()取第一条数据 查询返回所有匹配数据 12345Bson condition = Filters.eq(\"age\", 16);FindIterable&lt;Document&gt; vals = collection.find(condition);for (Document val : vals) &#123; System.out.println(val.toJson());&#125; find()方法返回所有匹配数据 分页查询 分页查询是我们日常开发中经常用到的功能，尤其是mongo这种量级较大的存储，分页使用limit()和skip()两个方法来实现，limit指定查询的条数，skip进行分页，参数为从第几条开始，需要使用当前页码和分页条数进行计算(pageNo - 1) * pageSize 12345Bson condition = Filters.lt(\"age\", 2);FindIterable&lt;Document&gt; vals = collection.find(condition).limit(10).skip(10).sort(Sorts.descending(\"age\"));for (Document val : vals) &#123; System.out.println(val.toJson());&#125; limit(10): 每页取10条数据 skip(10): 从第11条开始查询，起始位置为0 sort(Sorts.descending(“age”)): 以列age倒序 对应MySQL：select * from base_info where age &lt; 2 order by age desc limit 7, 7 更新数据 更新第一条匹配数据中的某些字段 123Bson condition = Filters.eq(\"age\", 15);Document document = new Document(\"$set\", new Document(\"location\", \"XZ\"));collection.updateOne(condition, document); 注意这里有一个$set，这个指令是必须的，相对应的指令还有$inc 替换第一条匹配数据全部内容 123Bson condition = Filters.eq(\"age\", 15);Document document = new Document(\"location\", \"XZ\");collection.updateOne(condition, document); 没有$set指令,则表示使用参数document替换掉第一条匹配到的数据 第一条匹配的数据中指定字段数量+1 123Bson condition = Filters.eq(\"location\", \"XZ\");Document document = new Document(\"$inc\", new Document(\"age\", 1));collection.updateOne(condition, document); 更新所有匹配数据 123Bson condition = Filters.eq(\"age\", 15);Document document = new Document(\"$set\", new Document(\"location\", \"XZ\"));collection.updateMany(condition, document); 全部代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import org.bson.Document;import org.bson.conversions.Bson;import com.mongodb.MongoClient;import com.mongodb.client.FindIterable;import com.mongodb.client.MongoCollection;import com.mongodb.client.MongoDatabase;import com.mongodb.client.model.Filters;import com.mongodb.client.model.Sorts;/** * @author: cc */public class MongoConnectTest &#123; public static void main(String[] args) &#123; MongoClient client = new MongoClient(\"localhost\", 27017); try &#123; /* // 创建验证信息，根据加密方式选择MongoCredential内对应的加密方式 List&lt;MongoCredential&gt; credentials = new ArrayList&lt;&gt;(); MongoCredential credential = MongoCredential.createCredential(\"admin\", \"test\", \"\".toCharArray()); credentials.add(credential); // 创建mongo服务地址 ServerAddress serverAddress = new ServerAddress(\"localhost\", 27017); MongoClient mongoClient = new MongoClient(serverAddress, credentials);*/ MongoDatabase db = client.getDatabase(\"test1\"); // 创建集合 // 方式1 // db.createCollection(\"base_info2\"); // 方式2 MongoCollection&lt;Document&gt; collection = db.getCollection(\"base_info\"); // collection.insertOne(new Document(\"name\", \"lxl\")); // 删除集合 // collection.drop(); // 新增数据 // 单条新增 /*Document document = new Document().append(\"name\", \"cc\").append(\"age\", 30).append(\"location\", \"SZ\"); collection.insertOne(document); // 批量新增 List&lt;Document&gt; documentList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 1000; i++) &#123; Document doc = new Document().append(\"name\", \"cc\" + i).append(\"age\", new Random().nextInt(100)) .append(\"location\", \"SZ\"); documentList.add(doc); &#125; collection.insertMany(documentList);*/ // 删除数据 // 删除第一条匹配数据 /*Bson condition = Filters.eq(\"age\", 99); collection.deleteOne(condition); // 删除所有匹配数据 collection.deleteMany(condition);*/ // 修改数据 // 修改第一条匹配数据 /*Bson condition = Filters.eq(\"age\", 15); Document document = new Document(\"$set\", new Document(\"location\", \"XZ\")); collection.updateOne(condition, document); collection.updateMany(condition, document);*/ // 年龄+1 /*Bson condition = Filters.eq(\"location\", \"XZ\"); Document document = new Document(\"$inc\", new Document(\"age\", 1)); collection.updateOne(condition, document);*/ // 查询返回第一条匹配数据 Bson condition = Filters.lt(\"age\", 2); FindIterable&lt;Document&gt; vals = collection.find(condition).sort(Sorts.descending(\"age\")).limit(7).skip(7); // Document document = vals.first(); // System.out.println(document.toJson()); for (Document val : vals) &#123; System.out.println(val.toJson()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://luxiaowan.github.io/categories/MongoDB/"}],"tags":[{"name":"Java与MongoDB","slug":"Java与MongoDB","permalink":"http://luxiaowan.github.io/tags/Java与MongoDB/"}]},{"title":"MongoDB监控、分片及备份恢复","slug":"MongoDB监控、分片及备份恢复","date":"2019-10-23T16:00:00.000Z","updated":"2019-10-24T13:20:12.764Z","comments":true,"path":"2019/10/24/MongoDB监控、分片及备份恢复/","link":"","permalink":"http://luxiaowan.github.io/2019/10/24/MongoDB监控、分片及备份恢复/","excerpt":"","text":"","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://luxiaowan.github.io/categories/MongoDB/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://luxiaowan.github.io/tags/监控/"}]},{"title":"MongoDB连接报错java.lang.NoSuchFieldError ACKNOWLEDGED","slug":"MongoDB连接报错java.lang.NoSuchFieldError-ACKNOWLEDGED","date":"2019-10-22T16:00:00.000Z","updated":"2019-10-24T13:20:12.764Z","comments":true,"path":"2019/10/23/MongoDB连接报错java.lang.NoSuchFieldError-ACKNOWLEDGED/","link":"","permalink":"http://luxiaowan.github.io/2019/10/23/MongoDB连接报错java.lang.NoSuchFieldError-ACKNOWLEDGED/","excerpt":"","text":"BUG描述 使用SpringBoot整合MongoDB时，正要运行代码连接mongo，就赤红赤红的报了个错： 12345Exception in thread \"main\" java.lang.NoSuchFieldError: ACKNOWLEDGED at com.mongodb.MongoClientOptions$Builder.&lt;init&gt;(MongoClientOptions.java:960) at com.mongodb.MongoClient.&lt;init&gt;(MongoClient.java:155) at com.mongodb.MongoClient.&lt;init&gt;(MongoClient.java:145) at com.example.demo.mongo.MongoConnectTest.main(MongoConnectTest.java:15) 这一下就傻眼了，对于刚接触mongo的人来说，是很懵圈的，大脑知识库中没有这个异常信息的解决办法，只能谷歌了，没想到有那么多人遇到过这个问题 BUG解决 在Stack Overflow上找到一个帖子： https://stackoverflow.com/questions/13593614/mongodb-java-lang-nosuchfielderror 其中jyemin的回答可以说是直击要害了，顺利的解决了这个问题，我把截图贴上，以防帖子被删 其实就是在工程中引入了多个版本不同的mongo-java-driver，所以导致程序混乱，只要保留自己真正使用的那个版本，其他的都删除即可 我的配置： 将2.7.1版本的依赖删除就可以正常运行了","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://luxiaowan.github.io/categories/MongoDB/"}],"tags":[{"name":"MongoDB错误记录","slug":"MongoDB错误记录","permalink":"http://luxiaowan.github.io/tags/MongoDB错误记录/"}]},{"title":"MongoDB基础应用","slug":"MongoDB基础应用","date":"2019-10-22T16:00:00.000Z","updated":"2019-10-24T13:20:12.764Z","comments":true,"path":"2019/10/23/MongoDB基础应用/","link":"","permalink":"http://luxiaowan.github.io/2019/10/23/MongoDB基础应用/","excerpt":"","text":"索引 说明：索引是为了加快查询速度，可以对集合中的一列或多列设置索引。 – 无索引：扫描整个集合的文档，查找符合条件的文档 – 有索引：查找索引，根据索引取出文档数据 创建索引 db.&lt;collection_name&gt;.createIndex(keys, option) 栗子： 123456789101. 单索引db.user.createIndex(&#123;age:-1&#125;)---age:索引列名-1:倒序索引1:正序索引2. 多索引(复合索引)db.user.createIndex(&#123;age:1, gender:-1&#125;) 可选参数 参数 类型 说明 background Boolean 指定创建索引时是否阻塞集合的其他操作。true:后台执行，不阻塞；false:阻塞，默认 unique Boolean 指定索引是否为唯一索引。true:唯一索引；false:不唯一，默认 name String 索引名称，默认为字段名+索引顺序 v indexversion 索引版本号，默认为当前mongo的版本号 weights Integer 1~99999之间，值越大权重越大 expireAfterSeconds Integer 指定集合生存时间。秒级，TTL sparse Boolean 指定是否忽略不存在的字段。true:不查出不包含查询字段的文档；false:查询所有文档，默认 栗子： 12345&gt; db.user.createIndex(&#123;name:1&#125;, &#123;background: true, unique: true, name: \"idx_user_name\", v: 1, weights: 99, sparse: true&#125;)&gt; &gt; ---&gt; 后台不阻塞集合的方式创建一个name列正序,版本号为1,权重99,忽略无name字段的文档的唯一索引idx_user_name&gt; 查看所有索引 db.&lt;collection_name&gt;.getIndexes() 栗子： db.user.getIndexes() 重建索引 方法1：db.&lt;collection_name&gt;.reIndex() 方法2：先删除原索引，然后再创建 12db.&lt;collection_name&gt;.dropIndex(&lt;idx_name&gt;)db.&lt;collection_name&gt;.createIndex(...) 删除索引 删除指定名称的索引： db.user.dropIndex(&lt;idx_name&gt;) 删除集合中所有索引 db.user.dropIndexes() 说明：只会删除自建的索引，集合中_id列的索引不会被删除 聚合查询 12345678910111213141516171819202122232425创建集合并插入数据：db.agg.save([&#123; title: 'MongoDB Overview', description: 'MongoDB is no sql database', by_user: 'runoob.com', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100&#125;,&#123; title: 'NoSQL Overview', description: 'No sql database is very fast', by_user: 'runoob.com', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 10&#125;,&#123; title: 'Neo4j Overview', description: 'Neo4j is no sql database', by_user: 'Neo4j', url: 'http://www.neo4j.com', tags: ['neo4j', 'database', 'NoSQL'], likes: 750&#125;]) 格式： 12345678910&gt; db.&lt;collection_name&gt;.aggregate(condition)&gt; ---&gt; condition:&gt; [&#123;$group:&#123;_id:\"$&lt;key&gt;\", num_tutorial:&#123;$&lt;fun_expression&gt;:\"$&lt;key&gt;\"&#125;&#125;&#125;]&gt; $group:一个组&gt; _id:组合列，类同于MySQL的group by后面的字段，默认_id的列会在查询结果中显示&gt; num_tutorial:输出的列名&gt; $&lt;fun_expression&gt;:聚合表达式&gt; $&lt;key&gt;:运算的列名&gt; 关键字：aggregate 说明：聚合查询就是求和、最大、最小、最前、最后、平均数的统称，类似于MySQL的count()、sum()、avg() 栗子： 12345&gt; db.user.aggregate([&#123;$group: $&#123;_id:\"$gender\", num_tutorial:&#123;$sum:1&#125;&#125;&#125;])&gt; &gt; ---&gt; 等同于MySQL：select gender, count(1) from user group by gender&gt; 聚合表达式 表达式 描述 案例 $sum 计算总和 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$sum:&quot;$likes&quot;}}}])—等同于MySQL：select by_user, sum(likes) from agg group by by_user $avg 计算平均值 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$avg:&quot;$likes&quot;}}}])—等同于MySQL：select by_user, avg(likes) from agg group by by_user $min 获取集合中指定列的最小值记录 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$min:&quot;$like&quot;}}}])—等同于MySQL：select by_user, min(likes) from agg group by by_user $max 获取集合中指定列的最大值记录 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$max:&quot;$likes&quot;}}}])—等同于MySQL：select by_user, max(likes) from agg group by by_user $push 在结果文档中插入值到数组 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$push:&quot;$url&quot;}}}])—等同于MySQL：查出所有数据，然后取字段url写入同一个列表中，url不去重，然后输出 $addToSet 在结果文档中插入值到一个数组中，但不创建副本 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$addToSet:&quot;$url&quot;}}}])—等同于MySQL：查出所有数据，然后取字段url写入同一个列表中，url去重，然后输出 $first 根据资源文档的排序获取第一个文档数据 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$first:&quot;$title&quot;}}}]) $last 根据资源文档的排序获取最后一个文档数据 db.agg.aggregate([{$group:{_id:&quot;$by_user&quot;, num_tutorial:{$last:&quot;$title&quot;}}}]) 管道函数 说明：管道函数类似于Linux系统中的管道操作，将上一步的运算结果作为下一步的输入值，最终达到理想计算结果的运算方式 函数 说明 $project 指定需要输出的列，默认显示_id，格式：{$project:{by_user:1, title:1, url:1, _id:0不显示id}}, $limit 限制查询返回的文档数，格式：{$limit: 1},只返回一个文档 $skip 跳过指定数量的文档，返回之后的所有文档，格式：{$skip: 1},从第二个文档开始输出 $match 条件筛选，格式：{match: {likes: {gte: 10}}} $group 聚合条件，格式：{group: {_id: &quot;by_user&quot;, count: {$sum: -1}}} $sort 排序，格式：{$sort: {likes: -1}}，-1:倒序; 1:正序 $unwind 将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值 $geoNear 输出接近某一地理位置的有序文档。 栗子： 123456&gt; db.agg.aggregate(&#123;$match: &#123;likes: &#123;$gte: 10&#125;&#125;&#125;, &#123; $project: &#123;_id: 0, title: 1, by_user: 1, likes: 1&#125;&#125;, &#123;$limit: 5&#125;, &#123;$skip: 1&#125;, &#123;$sort: &#123;likes: -1&#125;&#125;)&gt; &gt; ---&gt; 等同于MySQL: &gt; select title, by_user, likes from agg where likes &gt;= 10 order by likes desc limit 1,5&gt;","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://luxiaowan.github.io/categories/MongoDB/"}],"tags":[{"name":"基础应用","slug":"基础应用","permalink":"http://luxiaowan.github.io/tags/基础应用/"}]},{"title":"MongoDB基本指令","slug":"MongoDB基本指令","date":"2019-10-22T16:00:00.000Z","updated":"2019-10-24T13:20:12.763Z","comments":true,"path":"2019/10/23/MongoDB基本指令/","link":"","permalink":"http://luxiaowan.github.io/2019/10/23/MongoDB基本指令/","excerpt":"","text":"查看所有的db show dbs 切换db user &lt;db_name&gt; 查看当前所在db名称 db 删除db**(必须在要删除的db中操作)** db.dropDatabase() 查看db下所有的集合 show tables show collections 创建集合 db.createCollection(&quot;abc&quot;) db.createCollection(&quot;def&quot;, {capped: true, autoIndexId: true, size: 1024, max: 100}) 往一张不存在的集合中插入一条数据，会自动创建集合 db.test.insert({title: 123}) 删除集合 db.&lt;collection_name&gt;.drop() 例：db.abc.drop() 插入文档 db.&lt;collection_name&gt;.insert({title: 1234}) doc=({title: 12345, name: &quot;MongoDB指南&quot;}) db.&lt;collection_name&gt;.insert(doc) db.&lt;collection_name&gt;.save({name: &quot;MongoDB简单指令&quot;}}) doc2=({name: &quot;MongoDB从入门到放弃&quot;}) db.&lt;collection_name&gt;.save(doc2) doc3=({_id: &quot;edrftgyhjkgjhfgv2ryuoio&quot;, name: &quot;MongoDB从入门到放弃&quot;}) db.&lt;collection_name&gt;.save(doc3)// 若_id对应值的数据已经存在，则更新这条数据，否则新增一条数据 更新文档 db.&lt;collection_name&gt;.update({title: 1234}, {$set:{title: &quot;4321&quot;}}) 格式： 123456789db.&lt;collection_name&gt;.update( &lt;where&gt;,// 相当于MySQL的where &lt;update&gt;,// 相当于MySQL的update语句的set，需要跟一些指令：$,$inc,$set &#123; upsert: true,// true：如果不存在记录，则新增；false相反，默认 multi: true,// true：只更新第一条匹配的记录；false相反，全部更新， 默认 writeConcern: &lt;document&gt;// 异常级别 &#125;) 案例 12345678910111213&gt; 1. 只更新第一条记录：&gt; db.col.update( &#123; \"count\" : &#123; $gt : 1 &#125; &#125; , &#123; $set : &#123; \"test2\" : \"OK\"&#125; &#125; );&gt; 2. 全部更新：&gt; db.col.update( &#123; \"count\" : &#123; $gt : 3 &#125; &#125; , &#123; $set : &#123; \"test2\" : \"OK\"&#125; &#125;,false,true );&gt; 3. 只添加第一条：&gt; db.col.update( &#123; \"count\" : &#123; $gt : 4 &#125; &#125; , &#123; $set : &#123; \"test5\" : \"OK\"&#125; &#125;,true,false );&gt; 4. 全部添加进去:&gt; db.col.update( &#123; \"count\" : &#123; $gt : 5 &#125; &#125; , &#123; $set : &#123; \"test5\" : \"OK\"&#125; &#125;,true,true );&gt; 5. 全部更新：&gt; db.col.update( &#123; \"count\" : &#123; $gt : 15 &#125; &#125; , &#123; $inc : &#123; \"count\" : 1&#125; &#125;,false,true );&gt; 6. 只更新第一条记录：&gt; db.col.update( &#123; \"count\" : &#123; $gt : 10 &#125; &#125; , &#123; $inc : &#123; \"count\" : 1&#125; &#125;,false,false );&gt; db.&lt;collection_name&gt;.save() 调用save指令一般需要指定_id 删除文档 db.&lt;collection_name&gt;.remove({title: &quot;4321&quot;}, true) 格式 1234db.&lt;collection_name&gt;.remove( &lt;where&gt;,// 相当于MySQL的where &lt;justOne&gt;// true：只删除一条匹配条件的数据；false：匹配条件的数据全部删除，默认) 删除集合中所有数据 db.&lt;collection_name&gt;.remove({}) 新函数： db.&lt;collection_name&gt;.deleteMany({}) db.&lt;collection_name&gt;.deleteOne({title: &quot;12345&quot;}) 查询文档 普通查询 格式： 12345&gt; db.&lt;collection_name&gt;.find(&gt; &lt;where&gt;, // 查询条件&gt; &lt;colName&gt;// 返回字段名称&gt; )&gt; 创建一个集合，插入三条数据 1db.user.insert([&#123;name: \"cc\", age: \"29\", gender: 1&#125;, &#123;name: \"ccc\", age: \"30\", gender: 2&#125;, &#123;name: \"c\", age: \"28\", gender: 1&#125;]) 查询集合中全部数据 普通显示：db.user.find() 格式化显示：db.user.find().pretty() 查询name=&quot;c&quot;的信息 db.user.find({name: &quot;c&quot;}).pretty() 查询只返回第一个匹配到的数据 db.user.findOne({name: &quot;c&quot;}) AND查询 db.user.find({key: value, key: value}) And查询即是在where条件里面用逗号&quot;,&quot;分隔 栗子： 123456&gt; db.user.find(&#123;name:\"cc\", gender:1&#125;)&gt; &gt; ---&gt; 等同于MySQL：&gt; select * from user where name = \"c\" AND gender = 1&gt; OR查询 db.user.find({$or:[{key:value}, {key:value}]}) 栗子： 12345678&gt; db.user.find(&#123;&gt; $or:[&#123;name:\"c\"&#125;, &#123;gender:2&#125;]&gt; &#125;)&gt; &gt; ---&gt; 等同于MySQL：&gt; select * from user where name = \"c\" OR gender = 2&gt; AND和OR组合查询 db.user.find({key:value, $or:[{key:value}, {key:value}]}) 栗子： 123456&gt; db.user.find(&#123;gender:1, $or:[&#123;name: \"c\"&#125;, &#123;age: \"28\"&#125;]&#125;)&gt; &gt; ---&gt; 等同于MySQL：&gt; select * from user where gender = 1 AND (name = \"c\" OR age = \"28\")&gt; 运算符 运算符 格式 案例 MySQL对应语句 等于 {key:value}{key:{$eq:value}} db.user.find({age:“29”})db.user.find({age:{$eq:“29”}}) where age = “29” 大于 {key:{$gt: value}} db.user.find({age:{$gt:“30”}}) where age &gt; “30” 小于 {key:{$lt: value}} db.user.find({age:{$lt: “30”}}) where age &lt; “30” 大于等于 {key:{$gte: value}} db.user.find({age:{$gte:“30”}}) where age &gt;= “30” 小于等于 {key:{$lte: value}} db.user.find({age:{$lte:“30”}}) where age &lt;= “30” 不等于 {key:{ne: value}} db.user.find({age:{$ne:“29”}}) where age != “30” 模糊查询 查询age包含0的：db.user.find({age:/0/}) 查询age以2开头的：db.user.find({age:/^2/}) 查询age以8结束的：db.user.find({age:/8$/}) 分页查询 格式： 123456&gt; db.&lt;collection_name&gt;.find().limit(Number).skip(Number)&gt; &gt; ---&gt; limit(Number)表示查询多少条数据&gt; skip(Number)表示从第几条开始查询&gt; 查询一条数据 第一种方法：db.user.findOne({}) 第二种方法：db.user.find({}).limit(1) 从第二条数据开始查询一条数据 db.user.find().limit(1).skip(2) 查询排序 格式： 1234567&gt; db.&lt;collection_name&gt;.find().sort(&#123;&lt;key_name&gt;:-1/1&#125;)&gt; &gt; ---&gt; &lt;key_name&gt;：排序字段&gt; -1：倒序&gt; 1：正序&gt; 按照年龄倒序 db.user.find().sort({age:-1}) 按照年龄倒序、性别正序 db.user.find().sort({age:-1, gender:1})","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://luxiaowan.github.io/categories/MongoDB/"}],"tags":[{"name":"基本指令","slug":"基本指令","permalink":"http://luxiaowan.github.io/tags/基本指令/"}]},{"title":"Git Stash用法","slug":"git stash命令","date":"2019-10-21T16:00:00.000Z","updated":"2019-10-24T13:20:12.765Z","comments":true,"path":"2019/10/22/git stash命令/","link":"","permalink":"http://luxiaowan.github.io/2019/10/22/git stash命令/","excerpt":"","text":"创建仓库 git init echo 123 &gt; test.txt git add . git commit -m “add test file” git remote add origin git@git.xx.xx.xx:xxx/xxx.git git push origin master 以上内容比较简单，就不作详细讲述，如果上面的内容看不懂，下面的请放弃 使用git stash暂存 随意修改test.txt文件的内容，比如：画个心形，你正热火朝天修改中…… 这时领导走过来拍了拍你的肩膀说到：”小伙子啊，创建个朕.txt文件提交上来，内容就写我还想再活五百年，test.txt文件这一版不作修改“。 你面露笑容的回答：“好的，没问题！”，内心却是：“MMP,MMP,MMP……” 辛辛苦苦修改的test.txt文件怎么办？眼瞅着就要完成了，难道复制出去，然后等解决领导需求后再粘贴回来？low不low？肯定不low啊，一个文件而已，这种方法很简单，*但是当你实际项目中修改了几十个文件的时候呢？*挨个儿复制出去？累傻小子呐？！！！！！ git stash命令帮你解决问题，stash是存储的意思，也就是将当前工作区内的所有东西都存储起来，然后工作区所有文件恢复到修改之前的状态(并不是最新状态，不会和仓库中进行自动同步，需要你自己去pull)，然后你就可以继续完成任务了。(在执行git stash之前需要先执行git add命令) stash可以进行多次操作，每次操作都会将当前工作区的文件情况暂存起来，stash是类栈存储，每次stash的序号都为0，此次之前stash的序号会自动+1 使用git stash pop取出 git stash pop取出栈顶元素，也就是序号为0的那个，即最近一次执行git stash保存的内容。pop之后，暂存列表中就会自动将其清除掉，这个时候你再执行git stash list会发现毛都没有 这个时候可能就会纳闷了，我保存了好几次，但是我这次是想使用最开始stash的那份内容，怎么办？一直pop，直到最后一次？当然不行，上面刚讲过pop之后暂存列表中就没有stash的信息了，已经被pop出去的就找不回来了，等于是自杀式攻击，那咋整呢？ git stash apply stash@{序号}可以将指定序号的stash内容弹出到工作区，此时工作区里文件的状态就和stash@{序号}里的一致了，但是这个命令无法将stash记录从暂存列表中删除，仅仅只是将文件恢复而已 git stash drop stash@{序号}来丢弃暂存列表中的记录，可以配合apply使用 查看暂存记录中的信息 查看暂存列表：git stash list查看当前stash的列表 查看暂存内容：git stash show stash@{序号}查看指定序号的stash的内容 git stash save ‘msg’ 等于是在stash的时候打了个标签，妖娆！！！！","categories":[{"name":"Git","slug":"Git","permalink":"http://luxiaowan.github.io/categories/Git/"}],"tags":[]},{"title":"Hash索引相关","slug":"Hash索引相关","date":"2019-10-12T15:42:43.000Z","updated":"2019-10-21T15:48:05.043Z","comments":true,"path":"2019/10/12/Hash索引相关/","link":"","permalink":"http://luxiaowan.github.io/2019/10/12/Hash索引相关/","excerpt":"","text":"hash索引结构使用方式较为局限，仅适用于=、IN和&lt;=&gt;三种，但是由于通过hash可以直接查找到具体的值，而不用像BT那样每次都从root节点开始遍历，所以在通常情况下，hash的查找效率要比BT高。 hash的缺陷： 1. hash不能进行范围查找 值在计算hash后，并不能保证计算后的hash值和计算前的大小排列一样，所以hash不适用于范围查找 2. hash不能进行排序查询 值计算后的hash值无法保证与原值大小顺序一样，所以无法进行排序 3. 组合索引不能使用部分字段查询 组合索引的hash值是所有索引字段的值组合在一起进行计算的，若仅使用部分字段进行查询的话，计算出的hash值基本不会与索引的hash值相同 4. hash在出现大量值碰撞的时候，性能会降低 hash出现大量的值相等的时候，需要进行表扫描以进行精确匹配，效率较低","categories":[{"name":"Java","slug":"Java","permalink":"http://luxiaowan.github.io/categories/Java/"}],"tags":[{"name":"Java基础知识","slug":"Java基础知识","permalink":"http://luxiaowan.github.io/tags/Java基础知识/"}]},{"title":"Char和varchar简单介绍","slug":"char与varchar简单介绍","date":"2019-10-12T04:10:43.000Z","updated":"2019-10-21T16:19:50.476Z","comments":true,"path":"2019/10/12/char与varchar简单介绍/","link":"","permalink":"http://luxiaowan.github.io/2019/10/12/char与varchar简单介绍/","excerpt":"","text":"1. 数据长度 1) char(最大长度255个字节) 长度固定（字段存入数据长度始终等于字段长度） 2) varchar(最大长度65535个字节) 可变长度，存入数据长度为N个字节，则实际使用了N+1(255以上长度则+2)个字节的空间，多出来的1字节是用来存储数据实际长度。 存入数据对比 存入&quot;ab&quot; char查询出&quot;ab&quot; varchar查询出&quot;ab&quot; 存入&quot;ab &quot;，ab后面有两个空格， char查询出&quot;ab&quot; varchar查询出&quot;ab &quot; 解析： ​ 在入库时，数据库会自动在ab后面添加两位空格，让入库的数据长度保证等于4 char(4) ，这种操作很容易理解，但是如果你去数据表里面去查这条数据，会发现表中数据并没有空格，所以可以推断出这里是逻辑追加，所以在查询数据的时候会并不会出现引擎自动添加的空格。 2. 实操(技术一定要**实操**) 1）无空格数据 先创建一张表 1create table cv(c char(4), v varchar(4)); 插入数据 1insert into cv values(&quot;ab&quot;, &quot;ab&quot;); 查询数据 1select concat(&apos;(&apos;, c, &apos;)&apos;) AS c, concat(&apos;(&apos;, v, &apos;)&apos;) AS v from cv; 结果 结果中char和varchar均查出来为无空格的ab ####2）有空格数据 插入数据 1insert into cv values(&quot;ab &quot;, &quot;ab &quot;); 查询数据 1select concat(&apos;(&apos;, c, &apos;)&apos;) AS c, concat(&apos;(&apos;, v, &apos;)&apos;) AS v from cv; 结果 结果中可以看出，char类型将数据后面的空格自动去掉了，varchar则保留了所有的空格","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://luxiaowan.github.io/categories/MySQL/"}],"tags":[]},{"title":"MySQL使用查询缓存","slug":"MySQL使用查询缓存","date":"2019-10-11T05:01:23.000Z","updated":"2019-10-21T15:48:59.282Z","comments":true,"path":"2019/10/11/MySQL使用查询缓存/","link":"","permalink":"http://luxiaowan.github.io/2019/10/11/MySQL使用查询缓存/","excerpt":"","text":"查询服务是否已开启缓存 执行show variables like '%query_cache%';查看缓存状态 Variable_name: query_cache_type为缓存状态，ON表示开启，OFF表示关闭 开启/关闭使用查询缓存 修改my.cnf文件进行开启和关闭 [mysqld]中添加/修改： query_cache_size = 20M query_cache_type = ON/OFF **修改完成后重启MySQL服务：service mysql restart/systemctl mysql restart ** 查询缓存使用情况 执行show status like 'qcache%';查询缓存使用情况 因为本机MySQL未开启查询缓存，所以此处和使用相关的属性均为0 属性解释: 属性 释义 Qcache_free_blocks 缓存中相邻内存块的个数。数目大说明可能有碎片。FLUSH QUERY CACHE会对缓存中的碎片进行整理，从而得到一个空闲块。 Qcache_free_memory 缓存中空闲内存大小 Qcache_hits 缓存命中次数，命中一次就+1 Qcache_inserts 查询次数，命中次数/查询次数=缓存命中率 Qcache_lowmem_prunes 缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数，如果数字不断增长，就可能碎片非常严重，或者内存很少，通过Qcache_free_blocks、Qcache_free_memory来分析具体情况 Qcache_not_cached 不适合进行缓存的查询的数量 Qcache_queries_in_cache 当前缓存的查询(和响应)的数量 Qcache_total_blocks 缓存中块的数量","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://luxiaowan.github.io/categories/MySQL/"}],"tags":[]},{"title":"Java基础面试题","slug":"蚂蚁Java基础面试题","date":"2019-10-10T15:21:56.000Z","updated":"2019-10-21T15:49:27.313Z","comments":true,"path":"2019/10/10/蚂蚁Java基础面试题/","link":"","permalink":"http://luxiaowan.github.io/2019/10/10/蚂蚁Java基础面试题/","excerpt":"","text":"一 map怎么实现hashcode和equals,为什么重写equals必须重写hashcode 使用过concurrent包下的哪些类，使用场景等等。 concurrentHashMap怎么实现？concurrenthashmap在1.8和1.7里面有什么区别 CountDownLatch、LinkedHashMap、AQS实现原理 线程池有哪些RejectedExecutionHandler,分别对应的使用场景 多线程的锁？怎么优化的？偏向锁、轻量级锁、重量级锁？ 组合索引？B+树如何存储的？ 为什么缓存更新策略是先更新数据库后删除缓存 OOM说一下？怎么排查？哪些会导致OOM? OSI七层结构，每层结构都是干什么的？ java的线程安全queue需要注意的点 死锁的原因，如何避免 二 jvm虚拟机老年代什么情况下会发生gc，给你一个场景，一台4核8G的服务器，每隔两个小时就要出现一次老年代gc，现在有日志，怎么分析是哪里出了问题 数据库索引有哪些？底层怎么实现的？数据库怎么优化？ 数据库的事务，四个性质说一下，分别有什么用，怎么实现的？ 服务器如何负载均衡，有哪些算法，哪个比较好，一致性哈希原理，怎么避免DDOS攻击请求打到少数机器 volatile讲讲 哪些设计模式？装饰器、代理讲讲？ redis集群会吗？ mysql存储引擎 事务隔离级别 不可重复度和幻读，怎么避免，底层怎么实现（行锁表锁） 三 项目介绍 分布式锁是怎么实现的 MySQL有哪几种join方式，底层原理是什么 Redis有哪些数据结构？底层的编码有哪些？有序链表采用了哪些不同的编码？ Redis扩容，失效key清理策略 Redis的持久化怎么做，aof和rdb，有什么区别，有什么优缺点。 MySQL数据库怎么实现分库分表，以及数据同步？ 单点登录如何是实现？ 谈谈SpringBoot和SpringCloud的理解 未来的技术职业怎么规划？ 为什么选择我们公司？","categories":[{"name":"Java","slug":"Java","permalink":"http://luxiaowan.github.io/categories/Java/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://luxiaowan.github.io/tags/面试/"},{"name":"阿里","slug":"阿里","permalink":"http://luxiaowan.github.io/tags/阿里/"}]}]}