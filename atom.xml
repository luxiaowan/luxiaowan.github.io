<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>串一串</title>
  
  <subtitle>断舍离</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://luxiaowan.github.io/"/>
  <updated>2020-04-16T20:18:28.216Z</updated>
  <id>http://luxiaowan.github.io/</id>
  
  <author>
    <name>cc</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka生产者</title>
    <link href="http://luxiaowan.github.io/2020/04/17/Kafka%E7%94%9F%E4%BA%A7%E8%80%85/"/>
    <id>http://luxiaowan.github.io/2020/04/17/Kafka生产者/</id>
    <published>2020-04-16T16:46:00.000Z</published>
    <updated>2020-04-16T20:18:28.216Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简"><a class="markdownIt-Anchor" href="#简"></a> 简</h3><p>在kafka中把产生消息的一方称为生产者（Producer），尽管消息的产生非常简单，但是消息的发送过程比较复杂</p><p><img src="/images/kafka-p-send.png" alt="img"></p><p>发送消息从创建一个ProducerRecord对象开始，此类是kafka中的一个核心类，表示kafka需要发送的K-V键值对，记录了要发送的topic、partition、key、value、timestamp等</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在发送ProducerRecord的时候需要将对象序列化为字节数组，便于在网络上传输，之后消息达到分区器，若发送过程中指定了分区号，也就是partition，则在发送消息的时候将使用指定的分区，若发送过程中未制定分区，则根据topic和cluster中的partition数量顺序选择一个分区进行发送，分区选择器由接接口<code>org.apache.kafka.clients.producer.Partitioner</code>的实现类指定。</p><blockquote><p>org.apache.kafka.clients.producer.KafkaProducer</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="keyword">byte</span>[] serializedKey, <span class="keyword">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;</span><br><span class="line">  Integer partition = record.partition();</span><br><span class="line">  <span class="keyword">return</span> partition != <span class="keyword">null</span> ?</span><br><span class="line">    partition :</span><br><span class="line">  partitioner.partition(</span><br><span class="line">    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>org.apache.kafka.clients.producer.internals.DefaultPartitioner</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 选取分区</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">  List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">  <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">  <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 顺序index</span></span><br><span class="line">    <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line">    List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 取模</span></span><br><span class="line">      <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">      <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">      <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">    <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ProducerRecord内关联的时间戳timestamp，如果用户未指定，则使用KafkaProducer内的time的时间作为时间戳，但是kafka最终使用的时间戳取决于topic配置的时间戳类型：</p><ul><li>topic为CreateTime，则消息记录中的时间戳由broker使用</li><li>topic为LogAppendTime，则消息记录中的时间戳会在追加到日志中时由broker重写</li></ul><p><img src="/images/kafka_log.png" alt="img"></p><p>消息被放在一个记录批次里<code>ProducerBatch</code>，这个批次的所有消息都会被发送到相同的topic和partition上，由一个FutureRecordMetadata负责发送。</p><p>broker收到消息后会返回一个响应，如果发送正常的话，会返回一个<code>RecordAppendResult</code>对象，包含了topic、partition、offset、时间戳等信息，发送失败则会将失败的消息记录下来，然后后续重试发送。</p><blockquote><p>org.apache.kafka.clients.producer.KafkaProducer</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">  TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    throwIfProducerClosed();</span><br><span class="line">    <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">    ClusterAndWaitTime clusterAndWaitTime;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (metadata.isClosed())</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>, e);</span><br><span class="line">      <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">    Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line">    <span class="comment">// 序列化key</span></span><br><span class="line">    <span class="keyword">byte</span>[] serializedKey;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert key of class "</span> + record.key().getClass().getName() +</span><br><span class="line">                                       <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                                       <span class="string">" specified in key.serializer"</span>, cce);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 序列化value</span></span><br><span class="line">    <span class="keyword">byte</span>[] serializedValue;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert value of class "</span> + record.value().getClass().getName() +</span><br><span class="line">                                       <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                                       <span class="string">" specified in value.serializer"</span>, cce);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 决定要发送的partition</span></span><br><span class="line">    <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">    tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置header</span></span><br><span class="line">    setReadOnly(record.headers());</span><br><span class="line">    Header[] headers = record.headers().toArray();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),</span><br><span class="line">                                                                       compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">    ensureValidRecordSize(serializedSize);</span><br><span class="line">    <span class="comment">// 设置消息时间戳</span></span><br><span class="line">    <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">    log.trace(<span class="string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);</span><br><span class="line">    <span class="comment">// producer callback will make sure to call both 'callback' and interceptor callback</span></span><br><span class="line">    Callback interceptCallback = <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 事务</span></span><br><span class="line">    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">      transactionManager.maybeAddPartitionToTransaction(tp);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 发送消息，见下方代码</span></span><br><span class="line">    RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,</span><br><span class="line">                                                                     serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line">    <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">      log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</span><br><span class="line">      <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result.future;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (ApiException e) &#123;</span><br><span class="line">    log.debug(<span class="string">"Exception occurred during message send:"</span>, e);</span><br><span class="line">    <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</span><br><span class="line">      callback.onCompletion(<span class="keyword">null</span>, e);</span><br><span class="line">    <span class="comment">// 记录错误信息</span></span><br><span class="line">    <span class="keyword">this</span>.errors.record();</span><br><span class="line">    <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> FutureFailure(e);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">this</span>.errors.record();</span><br><span class="line">    <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> InterruptException(e);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (BufferExhaustedException e) &#123;</span><br><span class="line">    <span class="keyword">this</span>.errors.record();</span><br><span class="line">    <span class="keyword">this</span>.metrics.sensor(<span class="string">"buffer-exhausted-records"</span>).record();</span><br><span class="line">    <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">    <span class="keyword">this</span>.errors.record();</span><br><span class="line">    <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>org.apache.kafka.clients.producer.internals.RecordAccumulator</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">byte</span>[] key,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">byte</span>[] value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Header[] headers,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Callback callback,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  appendsInProgress.incrementAndGet();</span><br><span class="line">  ByteBuffer buffer = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (headers == <span class="keyword">null</span>) headers = Record.EMPTY_HEADERS;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">    <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">      <span class="keyword">if</span> (closed)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line">      RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">      <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> appendResult;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">byte</span> maxUsableMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">    <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">    log.trace(<span class="string">"Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;"</span>, size, tp.topic(), tp.partition());</span><br><span class="line">    <span class="comment">// 申请一个缓冲区，将消息数据写入到缓冲区中</span></span><br><span class="line">    buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">    <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">      <span class="keyword">if</span> (closed)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Producer closed while send in progress"</span>);</span><br><span class="line"></span><br><span class="line">      RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">      <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> appendResult;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">      <span class="comment">// 将消息分批处理</span></span><br><span class="line">      ProducerBatch batch = <span class="keyword">new</span> ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">      FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">      dq.addLast(batch);</span><br><span class="line">      incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 清空缓冲区</span></span><br><span class="line">      buffer = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (buffer != <span class="keyword">null</span>)</span><br><span class="line">      free.deallocate(buffer);</span><br><span class="line">    appendsInProgress.decrementAndGet();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="消息发送类型"><a class="markdownIt-Anchor" href="#消息发送类型"></a> 消息发送类型</h3><ol><li><p>简单发送</p><p>kafka最简单的消息发送是只指定topic和key及value，分区及时间戳均使用默认值，send()方法会返回一个<code>Future&lt;RecordMetadata&gt;</code>对象，如果不需要关心返回值，则可以忽略这个返回值，否则必须关注此值，方法返回的异常信息可能有<code>InterruptedException(发送线程中断异常)</code>，<code>BufferExhaustedException(缓冲区已满)</code>，<code>SerializationException(序列化异常)</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;String,String&gt; record =</span><br><span class="line">                <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"cc_test"</span>,<span class="string">"cc"</span>,<span class="string">"chuanchuan"</span>);</span><br><span class="line">producer.send(record);</span><br></pre></td></tr></table></figure></li><li><p>同步发送</p><p>第一种简单发送方式的前提是我们不在意发送的结果，但是我们在正常的情况下都会等待broker的反馈。我们从发送的源码中看到send()方法返回的<code>Future&lt;RecordMetadata&gt;</code>对象，我们可以调用Future的get()方法阻塞主线程等待broker的响应，如果返回错误，则我们调用get()方法的时候会抛出异常，如果没发生异常，则顺利获取到<code>RecordMetadata</code>对象，使用该对象查看消息的详细信息：topic、key和value的序列化后的大小、offset、partition。</p><p>生产者发送过程中一般会出现两类错误：一类可以通过重试解决，一类无法通过重试解决。比如连接错误、无Leader错误等都可以通过重试来实现，而消息过大这类错误KafkaProducer会直接抛出异常，不会重试，因为不管重试多少次都是消息过大。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"cc_test"</span>, <span class="string">"cc"</span>, <span class="string">"chuanchuan"</span>);</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  RecordMetadata rm = producer.send(record).get();</span><br><span class="line">  System.out.println(rm.offset());</span><br><span class="line">&#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">  log.error(<span class="string">"occur error"</span>, e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>异步发送</p><p>消息同步发送会造成同一时间只能有一条消息在发送中，在其有返回之前，其他的消息都需要一直等待，这样会造成消息堵塞滞后，无法让kafka发挥更大的效益，若一个消息发送需要20ms，发送五十条消息就需要1s，如果我们使用异步这种方式，那么发送五十条可能只需要30ms，甚至更少。异步发送的原理是在我们调用send()方法时传入一个接口<code>org.apache.kafka.clients.producer.Callback</code>的实现类的对象，由ProducerBatch的私有方法<code>completeFutureAndFireCallbacks</code>完成回调</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"cc_test"</span>, <span class="string">"cc"</span>, <span class="string">"chuanchuan"</span>);</span><br><span class="line">producer.send(record, );</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CcProducerCallback</span> <span class="keyword">implements</span> <span class="title">Callback</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata,Exception exception)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(exception != <span class="keyword">null</span>)&#123;</span><br><span class="line">      exception.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>org.apache.kafka.clients.producer.internals.ProducerBatch</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">completeFutureAndFireCallbacks</span><span class="params">(<span class="keyword">long</span> baseOffset, <span class="keyword">long</span> logAppendTime, RuntimeException exception)</span> </span>&#123;</span><br><span class="line">  produceFuture.set(baseOffset, logAppendTime, exception);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// execute callbacks</span></span><br><span class="line">  <span class="keyword">for</span> (Thunk thunk : thunks) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 发生异常</span></span><br><span class="line">      <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">        RecordMetadata metadata = thunk.future.value();</span><br><span class="line">        <span class="keyword">if</span> (thunk.callback != <span class="keyword">null</span>)</span><br><span class="line">          thunk.callback.onCompletion(metadata, <span class="keyword">null</span>);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 正常</span></span><br><span class="line">        <span class="keyword">if</span> (thunk.callback != <span class="keyword">null</span>)</span><br><span class="line">          thunk.callback.onCompletion(<span class="keyword">null</span>, exception);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      log.error(<span class="string">"Error executing user-provided callback on message for topic-partition '&#123;&#125;'"</span>, topicPartition, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  produceFuture.done();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="分区机制"><a class="markdownIt-Anchor" href="#分区机制"></a> 分区机制</h3><p>kafka对于数据的读写是以partition为粒度的，partition可以分布在不同的broker上，每个节点都可以独立的实现消息的读写，并且能够通过新增新的broker来提升kafka集群的吞吐量，partition部署在多个broker来实现负载均衡。</p><p>kafka的分区策略其实指的就是Producer将消息发送到哪个分区的算法，kafka提供了默认的分区策略，同时也支持我们自定义分区策略，所有的策略都实现于接口<code>org.apache.kafka.clients.producer.Partitioner</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Partitioner</span> <span class="keyword">extends</span> <span class="title">Configurable</span>, <span class="title">Closeable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 提供消息信息计算partition</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic topic名称</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key key名称</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> keyBytes key序列化字节数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value value值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> valueBytes value序列化字节数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cluster 集群</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关闭partitioner</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>消息发送到哪一个partition上涉及到分区选择机制，主要有顺序、随机、按key分配、自定义分配等方式，具体的实现方法就是<code>public int partition()</code>。</p><ol><li><p>顺序轮询</p><p>顺序分配就是消息均匀的发送给每一个partition，每个partition存储一次消息，kafka的默认策略。</p><img src="/images/image-20200417033430230.png" alt="image-20200417033430230" style="zoom: 67%;"></li><li><p>随机策略</p><p>随机策略可以先计算出topic的总的partition数，然后使用<code>ThreadLocalRandom.current().nextInt()</code>方法来获取一个小于分区总数的随机值，随机策略会导致消息分布不均匀。虽然是随机的，但是单个分区内也是有序的。</p><img src="/images/image-20200417035130292.png" alt="image-20200417035130292" style="zoom:67%;"><blockquote><p>策略代码</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line"><span class="keyword">return</span> ThreadLocalRandom.current().nextInt(partitions.size());</span><br></pre></td></tr></table></figure></li><li><p>key分配策略</p><p>这个策略也叫做 key-ordering策略，kafka中每条消息都会有自己的key，一旦消息被定义了 key，那么你就可以保证同一个key的所有消息都进入到相同的partition里面，因为每个partition下的消息处理都是有顺序的，所以这个策略也被称为按消息键保序策略</p><img src="/images/image-20200417035625713.png" alt="image-20200417035625713" style="zoom:60%;"><blockquote><p>策略代码</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line"><span class="comment">// Math.abs()的原因是hashCode可能是负数</span></span><br><span class="line"><span class="keyword">return</span> Math.abs(key.hashCode()) % partitions.size();</span><br></pre></td></tr></table></figure></li><li><p>自定义分配策略</p><p>自由发挥吧，只要实现Partitioner接口就成了</p><blockquote><p>application.properties</p></blockquote><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># org.apache.kafka.clients.producer.ProducerConfig类中定义了各类参数配置信息</span></span><br><span class="line"><span class="meta">spring.kafka.properties.partitioner.class</span>=<span class="string">cc.kevinlu.springboot.kafka.partitioners.CcPartitioner</span></span><br></pre></td></tr></table></figure><blockquote><p>CcPartitioner</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cc.kevinlu.springboot.kafka.partitioners;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CcPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">            log.debug(<span class="string">"&#123;&#125;------------&#123;&#125;"</span>, topic, cluster.availablePartitionsForTopic(topic).size());</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="comment">// 永远都打到partition 0上</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;简&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#简&quot;&gt;&lt;/a&gt; 简&lt;/h3&gt;
&lt;p&gt;在kafka中把产生消息的一方称为生产者（Producer），尽管消息的产生非常简单，但是消息的发送过程比较复杂&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://luxiaowan.github.io/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Git切换回某个commit</title>
    <link href="http://luxiaowan.github.io/2020/04/16/Git%E5%88%87%E6%8D%A2%E5%9B%9E%E6%9F%90%E4%B8%AAcommit/"/>
    <id>http://luxiaowan.github.io/2020/04/16/Git切换回某个commit/</id>
    <published>2020-04-16T15:45:00.000Z</published>
    <updated>2020-04-16T16:00:43.558Z</updated>
    
    <content type="html"><![CDATA[<h3 id="原由"><a class="markdownIt-Anchor" href="#原由"></a> 原由</h3><p>commit之后忘了push，然后就revert HEAD了，导致本地的代码丢失了刚修改的内容</p><h3 id="第一步"><a class="markdownIt-Anchor" href="#第一步"></a> 第一步</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure><p>使用该命令查看commit记录</p><img src="/images/image-20200416235542502.png" alt="git commit log" style="zoom:50%;"><p>格式<code>commit commit_id</code>，比如<code>commit bc208f03c3bb341dfc56533d9ea196b6d347ff34</code>中，bc208f03c3bb341dfc56533d9ea196b6d347ff34就是commit_id，每一次commit的id都是全局唯一的</p><h3 id="第二步"><a class="markdownIt-Anchor" href="#第二步"></a> 第二步</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard $&#123;commit_id&#125;</span><br></pre></td></tr></table></figure><p>若想切换回jmm这次的commit，则语句为<code>git reset --hard 81fc9404e8186d132c799ffaf62e652a4c8c98f0</code></p><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>git操作要慎重，不过即使出了问题也有恢复的小技巧</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;原由&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#原由&quot;&gt;&lt;/a&gt; 原由&lt;/h3&gt;
&lt;p&gt;commit之后忘了push，然后就revert HEAD了，导致本地的代码丢失了刚修改的内容&lt;/p&gt;
&lt;h3 id=&quot;第一步&quot;&gt;&lt;a clas
      
    
    </summary>
    
    
      <category term="Git" scheme="http://luxiaowan.github.io/categories/Git/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka初探</title>
    <link href="http://luxiaowan.github.io/2020/04/16/Kafka%E5%88%9D%E6%8E%A2/"/>
    <id>http://luxiaowan.github.io/2020/04/16/Kafka初探/</id>
    <published>2020-04-15T18:51:00.000Z</published>
    <updated>2020-04-16T16:00:26.695Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基本名词"><a class="markdownIt-Anchor" href="#基本名词"></a> 基本名词</h3><ul><li>消息：kafka中的数据单元称为消息，也可以叫记录，相当于MySQL表中的一条记录</li><li>批次：为了提高效率，kafka可以一次性写入一批数据(消息)，批次指的就是一组消息</li><li>主题：相当于MySQL的表，一个主题(Topic)代表着一类消息，kafka使用主题对消息分类</li><li>分区：分区(partition)归属于主题，一个主题可以划分为若干个分区，分区可以分布在不同的broker上，也可以在同一个broker上，使用分区来实现kafka的伸缩性。主题的单个分区上的消息是有序的，但是不同分区上的消息无法保证有序。</li><li>生产者：向主题发布消息的客户端称为生产者，生产者用于不断的向主题发送消息</li><li>消费者：订阅主题消息的客户端称为消费者，消费者用于处理生产者生产的消息</li><li>消费者群组：生产者与消费者的关系是一对多，比如一个客服对应多个咨询者，消费者群组就是由一批消费者组成的</li><li>偏移量：偏移量(Consumer Offset)是一种源数据，是一个单向递增的整数标识，用于记录消费者发生重平衡时的位置，以便用来恢复数据</li><li>broker：一个独立的服务器被称为broker，broker接收来自生产者的消息，并为消息设置偏移量，并提交消息持久化到磁盘</li><li>broker集群：多个broker组成一个集群，保证kafka的高可用，每个集群中都有一个broker充当集群Leader的角色</li><li>副本：kafka中消息的备份又称为副本(Replica)，副本的数量是可配置的，类型有Leader和Follower两种，Leader对外提供服务，Follower辅助</li><li>重(chong)平衡(ReBalance)：若消费者组内某个消费者宕了，其他存活的消费者自动重新分配订阅主题分区，kafka高可用的必备能力</li></ul><h3 id="关系介绍"><a class="markdownIt-Anchor" href="#关系介绍"></a> 关系介绍</h3><ul><li><p>Topic&amp;Partition</p><ol><li><p>Topic是kafka中给消息分类的标记，一个消息必定属于一个Topic，一个Topic可以包括一个或多个Partition，Partition又可以有多个副本，副本又可以分配在不同的broker上。</p></li><li><p>Partition内部是有序的，Partition之间是无序的</p><img src="/images/log_anatomy.png" alt="img" style="zoom: 130%;"></li><li><p>内部存储是以append-log的方式不断进行log文件尾部追加，文件读写是在磁盘上是顺序的，效率极高，媲美内存操作，每一条log对应一个offset，可以把offset理解为一个数组的下标，通过这个下标就可以读取对应的消息数据，Partition只负责为消息分配offset，消费者具体由哪个offset开始消费消息完全由消费者自己控制，也就是kafka服务端只负责提供数据，消费者自己控制消息消费进度。</p><img src="/images/log_consumer.png" alt="img" style="zoom: 25%;"></li><li><p>kafka虽然是可以持久化消息，并且不删除已经被消费过的消息，但消息也不是被永久存储在磁盘上的，为了防止磁盘长期被消息写入数据日积月累，kafka提供两种旧数据淘汰策略：</p></li></ol><ul><li><p>开启数据清理：<code>log.cleaner.enable=true</code>，默认关闭状态</p></li><li><p>基于时间：<code>log.retention.hours=168</code>，单位：小时；<code>log.retention.ms=100</code>，单位：毫秒；<code>log.retention.minutes</code>，单位：分钟</p></li><li><p>基于文件大小：<code>log.retention.bytes=1073741824</code>，单位：字节</p></li></ul></li><li><p>Consumer&amp;Consumer Group</p><ol><li><p>一个消费者组由一个或多个消费者组合而成，每一条消息只会被同一个group中的一个消费者消费，但是不同group中的消费者可以同时消费同一条消息，保证了 消息队列中的消息只被消费一次；kafka是发布订阅模式的消息队列，这里订阅的是消费者组，而不是特定的一个消费者实例。</p><p><img src="/images/consumer-groups.png" alt="img"></p><p>kafka支持离线处理和实时处理，所以我们可以使用Hadoop进行离线处理，也可以使用Storm这种实时流处理系统进行实时处理，还可以将数据实时的同步到其他的数据中心，前提是这些消费者处于不同的消费者组。</p><p>可以测试一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1. 创建一个topic</span></span><br><span class="line">kafka-topics --create --zookeeper localhost:2181 --replication-factor 3 --partition 1 --topic cc_topic</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2. 启动一个Producer</span></span><br><span class="line">kafka-console-producer --broker-list localhost:9092 --topic cc_topic</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3. 启动五个Consumer，1~3号放cc_group_1，4~5放cc_group_2</span></span><br><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --group cc_group_1 --from-beginning --topic cc_topic</span><br><span class="line"></span><br><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --group cc_group_1 --from-beginning --topic cc_topic</span><br><span class="line"></span><br><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --group cc_group_1 --from-beginning --topic cc_topic</span><br><span class="line"></span><br><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --group cc_group_2 --from-beginning --topic cc_topic</span><br><span class="line"></span><br><span class="line">kafka-console-consumer --bootstrap-server localhost:9092 --group cc_group_2 --from-beginning --topic cc_topic</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4. 发送一条消息</span></span><br><span class="line">123</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5. 查看消费者</span></span><br><span class="line">cc_group_1和cc_group_2各自收到123这条消息一次</span><br></pre></td></tr></table></figure></li></ol></li><li><p>Consumer ReBalance</p><p>Consumer ReBalance是通过Zookeeper实现，kafka保证了同一个消费者组中只能有一个消费者消费某条消息，其实kafka保证的是在稳定状态下每一个消费者都只会消费一个或多个Partition的消息，而某一Partition的消息仅会被一个消费者消费，这样设计的优势是每个消费者不用跟所有的broker进行通信，减少了通信开销，劣势是同一个消费组内的消费者不能均匀消费，而且单个Partition内部的数据是有序的，所以对于单个消费者来说，其消费的消息是有序的。</p><ol><li>Consumer &lt; Partition：会出现某些Consumer消费多个Partition的数据</li><li>Consumer &gt; Partition：会出现某些Consumer没有可消费的Partition</li><li>Consumer = Partition：一个Consumer消费一个Partition，均匀</li></ol></li></ul><h3 id="特性"><a class="markdownIt-Anchor" href="#特性"></a> 特性</h3><ul><li>高吞吐、低延迟：kafka处理消息的速度非常快，每秒几乎可以处理几十万条消息，并且最低延迟只有几毫秒</li><li>高伸缩性：每个topic都能有多个partition，每个partition又可以分布在不同的broker上</li><li>高并发：能够同时支持数千个客户端进行读写</li><li>容错性：允许集群中的某些节点失败，某个节点宕机，kafka仍然可用继续提供服务</li><li>持久性、可靠性：kafka的消息存储是基于Zookeeper的，Zookeeper是可以将消息持久化到磁盘上，并且支持数据备份，所以kafka是一个非常可靠的可持久化消息中间件</li><li>速度快：kafka采用零拷贝的模式实现数据的快速移动，避免了内核空间和用户空间的频繁切换，kafka可以批量发送数据，从生产者到文件系统到消费者；数据压缩可以通过有效的数据压缩减少IO次数，并且采用顺序读写的方式避免寻址造成的消耗。总结起来就是零拷贝、顺序读写、数据压缩、分批发送。</li></ul><h3 id="消息队列"><a class="markdownIt-Anchor" href="#消息队列"></a> 消息队列</h3><ul><li><p>点对点（一对一）：一个生产者所生产的消息只会被一个消费者进行消费，不会同时被多个消费者消费</p><img src="/images/image-20200416173858298.png" alt="image-20200416173858298" style="zoom:50%;"></li><li><p>发布订阅（一对多、多对多）：一个或多个生产者所生产的消息会被多个消费者同时消费</p><img src="/images/image-20200416173919621.png" alt="image-20200416173919621" style="zoom:50%;"></li></ul><h3 id="架构体系"><a class="markdownIt-Anchor" href="#架构体系"></a> 架构体系</h3><img src="/images/image-20200416220029587.png" alt="image-20200416220029587" style="zoom:45%;"><p>一个kafka集群包含若干个Producer、若干Consumer group、若干broker和Zookeeper集群组成，kafka通过Zookeeper管理Partition，选举Leader，以及在Consumer发生变化时通过Zookeeper进行ReBalance。Producer将消息push到Partition，Consumer通过pull将消息从Partition拉取到本地。</p><h3 id="api"><a class="markdownIt-Anchor" href="#api"></a> API</h3><p>kafka目前提供五类常用的API，主要有Producer、Consumer、Stream、Connect、Admin API：</p><ul><li>Producer API：允许App作为Producer将消息发送到kafka集群的一个或多个topic上</li><li>Consumer API：允许App作为Consumer从kafka集群上的一个或多个topic拉取消息</li><li>Stream API：允许App作为流处理器，从一个或多个topic中消费输入流并转化为输出流</li><li>Connector API：允许将现有的应用程序或存储系统连接到kafka的topic，充当Producer或Consumer</li><li>Admin API：允许管理和检查topic、broker和kafka的其他内容</li></ul><img src="/images/kafka-apis.png" alt="img" style="zoom:50%;"><h3 id="重要配置参数"><a class="markdownIt-Anchor" href="#重要配置参数"></a> 重要配置参数</h3><p>kafka的参数配置文件是server.properties</p><ul><li><a href="http://broker.id" target="_blank" rel="noopener">broker.id</a>：每个broker都有一个唯一标识，就像是MySQL表中的主键ID，默认值是0，这个值在kafka集群中必须是唯一不可重复的，值随意设置。</li><li>port：kafka broker的默认端口是9092，若未指定port参数，则就是9092，修改port参数可以是任意端口，但是最好不要低于1024，不然就需要管理员权限启动了</li><li>zookeeper.connect：设置broker源数据的Zookeeper地址，参数的值可以设置一个或多个，多个zk通过逗号分隔，比如<code>zk1:port,zk2:port,zk3:port</code>，不同的kafka集群可以使用同一个zk集群，可以通过指定zk的具体path来区分每个kafka的使用，比如kafka cluster1使用<code>zk:port/path1</code>，kafka cluster2使用<code>zk:port/path2</code>。</li><li><a href="http://zookeeper.connection.timeout.ms" target="_blank" rel="noopener">zookeeper.connection.timeout.ms</a>：设置broker连接Zookeeper的超时时间，单位是毫秒</li><li>log.dirs：kafka把所有的消息都保存在本地磁盘上，保存的日志地址通过该参数指定，可以指定多个存储目录，通过逗号分隔，例如<code>/home/kafka/1,/home/kafka/2,/home/kafka/3</code></li><li>auto.create.topic.enable：默认为true，允许随意的创建topic，参数为true时，使用Producer往一个不存在的topic发送消息时会自动创建topic、使用Consumer从一个不存在的topic拉取消息时自动创建topic、主动创建topic、当任意一个客户端向topic发送元数据请求时。此值建议在生产上设置为false，topic由人工进行分配，防止生产环境出现各种乱七八糟的topic。</li><li>topic相关参数<ul><li>num.partitions：主题拥有的Partition数量，若在创建topic的时候未指定分区数量，则使用该参数的值，默认为1。在运行过程中，分区数量可以增加不能减少，在创建时可以通过<code>--partition</code>指定个数</li><li>default.replication.factor：kafka消息的默认副本数，默认为1，只有在自动创建topic的时候才有效，在创建时可以通过<code>--replication-factor</code>指定</li><li>log.cleaner.enable：是否开启日志清理功能，默认为true，清理方式有时间和日志文件大小两种方式</li><li>log.retention.hours：设置kafka消息保存的时间，默认为168个小时，还可以通过<code>log.retention.ms</code>和<code>log.retention.minutes</code>来设置清理时间的毫秒和分钟时间</li><li>log.retention.bytes：设置topic的每个Partition所能保存的数据量，比如若一个topic有10个Partition，此参数的值为1G，那么该topic的最大存储容量为8G，topic的容量随着Partition的增加而增加。</li><li>log.segment.bytes：设置日志文件的最大的容量大小。当消息到达broker时，会被追加到日志文件中，但是如果日志片段的当前大小加上新接收消息的打小后超过了该参数设置的值，则将新消息和后续的消息写入到一个新的日志文件中。该参数的值越小，分割的文件就越多，磁盘的写入效率就越低。</li><li><a href="http://log.segment.ms" target="_blank" rel="noopener">log.segment.ms</a>：除了待日志文件大小超值后重新分配新文件之外，还可以通过日志创建时间来控制消息日志文件的生命周期，可以和<code>log.segment.bytes</code>同时设置，哪一个先达标使用哪一个策略，比如bytes设置为1G，ms设置为1小时，若30分钟内文件容量已达1G，则后续消息写入到新的日志文件中，若1小时内日志文件尚未达到1G，则也分配新的日志文件记录后续的消息。</li><li><a href="http://log.retention.check.interval.ms" target="_blank" rel="noopener">log.retention.check.interval.ms</a>：检查日志段以查看是否可以根据保留策略删除它们的时间间隔，单位：毫秒</li><li>message.max.bytes：该参数限定broker可接收的单个消息的大小，默认是1MB，如果Producer发送的消息大于此值，则broker会直接拒绝并返回错误。该参数指定的是压缩后的消息大小，消息的实际大小可能大于此值。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;基本名词&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#基本名词&quot;&gt;&lt;/a&gt; 基本名词&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;消息：kafka中的数据单元称为消息，也可以叫记录，相当于MySQL表中的一条记录&lt;/li&gt;
&lt;li&gt;批次：为了提高效率
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://luxiaowan.github.io/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis的穿透、击穿和雪崩</title>
    <link href="http://luxiaowan.github.io/2020/04/13/Redis%E7%9A%84%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF%E5%92%8C%E9%9B%AA%E5%B4%A9/"/>
    <id>http://luxiaowan.github.io/2020/04/13/Redis的穿透、击穿和雪崩/</id>
    <published>2020-04-13T14:23:00.000Z</published>
    <updated>2020-04-16T15:41:38.711Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>不论是我们在使用Redis还是准备面试，都逃不掉一块我们必须要考虑到的内容，也是使用Redis不精细的话必定会遇到的问题，就是缓存穿透、击穿和雪崩，这三个问题严重情况下，会使服务无法继续正常使用。从名字上来看，好像雪崩最严重，眼前突然浮现出电影《攀登者》里面的画面=。=</p><h3 id="缓存穿透"><a class="markdownIt-Anchor" href="#缓存穿透"></a> 缓存穿透</h3><p>缓存穿透是指访问一个DB和Redis中必定不存在的key，如果不对这类请求进行过滤拦截的话，请求每次都会穿过Redis直接打到DB上，并且我们一般是缓存中没数据的时候去DB中取，取出来之后再放到缓存中，但这类请求所需要的数据在DB中也不存在，所以即使请求打到DB上，最终缓存中还是没有数据，在这类请求特别多的情况下，DB很快就会被拖垮，引起服务异常。</p><blockquote><p>解决方案</p></blockquote><ol><li>布隆过滤器：我们可以在做事务型处理之后，将需要缓存的key放到布隆过滤器中，但是由于布隆过滤器只能保证可能存在，所以在使用过程中还是会有穿透的可能性存在，但概率极小，所以不用过多担心</li><li>短期null：此方案是在DB中查询不到数据的时候，就往Redis中设置一个短时间内就会过期的null值，比如30秒，1分钟等，不过时间还是要根据自己的业务性质来定。为什么要给不存在的key在缓存中设置一个null值？其实不一定是null，只要团队约定一个特殊字符即可，因为我们到数据库里取不出来数据，缓存里取个null（或者nil），也就代表了这个key不存在与数据库中</li></ol><h3 id="缓存雪崩"><a class="markdownIt-Anchor" href="#缓存雪崩"></a> 缓存雪崩</h3><p>大量的key在同一时刻同时失效，这些key并不一定是设置了相同的时间，也可能是凑巧时间累计在一起了，恰巧大量的针对这些失效的key的请求在同一时间大量的打了进来，这时缓存全部未命中，所有的请求都透传到DB上，引起DB压力瞬间扩大数倍，极易导致DB因负载过高而崩溃，危害极大。</p><blockquote><p>解决方案</p></blockquote><ol><li>加锁：对访问的key进行加锁，同时只放一个请求透传到DB，从一定程度上缓解了DB的压力，这也是缓存击穿的一种解决方案</li><li>队列：所有的请求全部塞入到队列中，依次打到DB上，这种方式能解决DB的压力，但是会给请求处理效率带来一些延迟</li><li>随机过期时间：给key设置过期时间时，在原过期时间的基础上加一个随机时间，比如3000毫秒以内的随机数，这样过期时间重复或者累计重复的可能性降低了很多，不太容易引起大量的key同时失效，并且成本较低。</li></ol><h3 id="缓存击穿"><a class="markdownIt-Anchor" href="#缓存击穿"></a> 缓存击穿</h3><p>缓存雪崩是说的大量的key，缓存击穿说的是某一个热点key，也就是在某些时间点会被超高的并发访问。key在某个时间点过期的时候，恰好在对这个Key有大量的并发请求过来，缓存中无法命中则会把请求全部打到DB端，如此大量的请求可能会瞬间把DB压爆。</p><blockquote><p>解决方案</p></blockquote><ol><li><p>临时加锁：对key加上互斥锁，若缓存中命中不了的时候，先给这个key设置一个锁（SETNX），锁的过期时间要非常简短，只有加锁成功的线程才透传到DB，加载完数据后set到缓存中，并释放锁</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">function get(key):</span><br><span class="line">  var v = redis.get(key)</span><br><span class="line">  <span class="keyword">if</span> v eq null:</span><br><span class="line">    <span class="keyword">if</span> setnx(key_lock, val, timeout):</span><br><span class="line">      var v = db.get(key)</span><br><span class="line">      redis.set(key, v, timeout)</span><br><span class="line">      release(key_lock)</span><br><span class="line">      <span class="keyword">return</span> v</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      sleep(<span class="number">30</span>)</span><br><span class="line">      <span class="keyword">return</span> get(key)</span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line">  <span class="keyword">return</span> v;</span><br></pre></td></tr></table></figure></li><li><p>同步锁：对于热点key，set缓存的时候同时set一个针对这个key的监视key，监视key的过期时间一定要小于被监视的key，每次获取缓存数据的时候都获取一下这个监视key，并判断监视key是否过期了，如果过期了，则重置一下key的过期时间，并重新设置这个监视key</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">function get(key):</span><br><span class="line">  var v = redis.get(key)</span><br><span class="line">  <span class="keyword">if</span> v eq null:</span><br><span class="line">    <span class="keyword">if</span> setnx(key_lock, val, timeout):</span><br><span class="line">      var v = db.get(key)</span><br><span class="line">      redis.set(key, v, timeout)</span><br><span class="line">      redis.set(key_monitor, now() + timeout - time, timeout - time)</span><br><span class="line">      release(key_lock)</span><br><span class="line">      <span class="keyword">return</span> v</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      sleep(<span class="number">30</span>)</span><br><span class="line">      <span class="keyword">return</span> get(key)</span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line">  var vm = redis.get(key_monitor)</span><br><span class="line">  <span class="keyword">if</span> now() - vm lt <span class="number">10</span>:</span><br><span class="line">    redis.expire(key ,timeout)</span><br><span class="line">    reids.expire(key_monitor, now() + timeout - time)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>若是想更好的使用Redis，那么穿透、击穿、雪崩必定是要慎重考虑的东西，解决方案有多种，应根据自己的实际业务做更优选择</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;不论是我们在使用Redis还是准备面试，都逃不掉一块我们必须要考虑到的内容，也是使用Redis不精细的话必定会遇到的问题，就是缓存穿透、击穿和雪
      
    
    </summary>
    
    
      <category term="Redis" scheme="http://luxiaowan.github.io/categories/Redis/"/>
    
    
  </entry>
  
  <entry>
    <title>Java内存模型JMM</title>
    <link href="http://luxiaowan.github.io/2020/04/13/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8BJMM/"/>
    <id>http://luxiaowan.github.io/2020/04/13/Java内存模型JMM/</id>
    <published>2020-04-12T17:11:00.000Z</published>
    <updated>2020-04-12T17:13:19.959Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/jmm.png" alt="JMM"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/jmm.png&quot; alt=&quot;JMM&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Java" scheme="http://luxiaowan.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>查看字节码Javap</title>
    <link href="http://luxiaowan.github.io/2020/04/13/%E6%9F%A5%E7%9C%8B%E5%AD%97%E8%8A%82%E7%A0%81javap/"/>
    <id>http://luxiaowan.github.io/2020/04/13/查看字节码javap/</id>
    <published>2020-04-12T16:45:00.000Z</published>
    <updated>2020-04-12T16:51:46.838Z</updated>
    
    <content type="html"><![CDATA[<h3 id="代码"><a class="markdownIt-Anchor" href="#代码"></a> 代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaP</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    String s1 = <span class="string">"Hello"</span>;</span><br><span class="line">    String s2 = <span class="string">"Hel"</span> + <span class="string">"lo"</span>;</span><br><span class="line">    String s3 = <span class="keyword">new</span> String(<span class="string">"Hello"</span>);</span><br><span class="line">    String s4 = <span class="string">"Hel"</span> + <span class="keyword">new</span> String(<span class="string">"lo"</span>);</span><br><span class="line">    String s5 = s3.intern();</span><br><span class="line">    <span class="keyword">int</span> i1 = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> i2 = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    System.out.println(s1 == s2);</span><br><span class="line">    System.out.println(s1 == s3);</span><br><span class="line">    System.out.println(s3 == s4);</span><br><span class="line">    System.out.println(s2 == s4);</span><br><span class="line">    System.out.println(s1 == s2);</span><br><span class="line">    System.out.println(s2 == s5);</span><br><span class="line">    System.out.println(i1 == i2);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查看字节码"><a class="markdownIt-Anchor" href="#查看字节码"></a> 查看字节码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javap -v JavaP.class</span><br></pre></td></tr></table></figure><h3 id="字节码"><a class="markdownIt-Anchor" href="#字节码"></a> 字节码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">Constant pool:（常量池）</span><br><span class="line"><span class="meta">#</span><span class="bash">2 = String <span class="comment">#36 // Hello</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">3 = Class <span class="comment">#37 // java/lang/String</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">5 = Class <span class="comment">#39 // java/lang/StringBuilder</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">7 = String <span class="comment">#40 // Hel</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">9 = String <span class="comment">#42 // lo</span></span></span><br><span class="line">&#123;</span><br><span class="line">stack=4, locals=8, args_size=1</span><br><span class="line">0: ldc #2 // String Hello （加载常量池的#2号字符串压入栈）</span><br><span class="line">2: astore_1 (将上一步加载的引用变量赋值给变量1，即s1【参照LocalVariableTable的slot数值】)</span><br><span class="line">3: ldc #2 // String Hello （加载常量池的#2号字符串压入栈）</span><br><span class="line">5: astore_2 (将上一步加载的引用变量赋值给变量2，即s2【参照LocalVariableTable的slot数值】)</span><br><span class="line">6: new #3 // class java/lang/String (创建#3号的实例：java/lang/String)</span><br><span class="line">9: dup （复制上一步创建的对象的引用压入栈）</span><br><span class="line">10: ldc #2 // String Hello （加载常量池的#2号字符串压入栈）</span><br><span class="line">12: invokespecial #4 // Method java/lang/String."&lt;init&gt;":(Ljava/lang/String;)V (调用String的init方法，将上一步加载入栈的引用作为参数传入init方法)</span><br><span class="line">15: astore_3 （将上一步返回的引用变量赋值给变量3，即s3【参照LocalVariableTable的slot数值】)</span><br><span class="line">16: new #5 // class java/lang/StringBuilder（创建#5号的实例：java/lang/StringBuilder）</span><br><span class="line">19: dup （复制上一步创建的对象引用压入栈）</span><br><span class="line">20: invokespecial #6 // Method java/lang/StringBuilder."&lt;init&gt;":()V （调用StringBuilder的init方法）</span><br><span class="line">23: ldc #7 // String Hel （加载常量池#7号字符串压入栈）</span><br><span class="line">25: invokevirtual #8 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;（调用StringBuilder的append方法，将上一步加载的引用作为参数传入append方法）</span><br><span class="line">28: new #3 // class java/lang/String （创建#3号的实例：java/lang/String）</span><br><span class="line">31: dup （复制上一步创建的对象的引用压入栈）</span><br><span class="line">32: ldc #9 // String lo （加载常量池#9号字符串压入栈）</span><br><span class="line">34: invokespecial #4 // Method java/lang/String."&lt;init&gt;":(Ljava/lang/String;)V （调用String的init方法，将上一步加载入栈的引用作为参数传入init方法）</span><br><span class="line">37: invokevirtual #8 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;（调用StringBuilder的append方法，将上一步加载的引用作为参数传入append方法）</span><br><span class="line">40: invokevirtual #10 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;（调用StringBuilder的toString方法）</span><br><span class="line">43: astore 4 （将上一步返回的引用赋值给变量4，即s4【参照LocalVariableTable的slot数值】）</span><br><span class="line">45: aload_3 （加载变量3压入栈）</span><br><span class="line">46: invokevirtual #11 // Method java/lang/String.intern:()Ljava/lang/String; （调用String的intern方法）</span><br><span class="line">49: astore 5 （将上一步返回的引用赋值给变量5，即s5【参照LocalVariableTable的slot数值】）</span><br><span class="line">51: iconst_0 （将数字0压入栈）</span><br><span class="line">52: istore 6 （将上一步加载的数字赋值给变量6，即i1【参照LocalVariableTable的slot数值】）</span><br><span class="line">54: iconst_1 （将数字1压入栈）</span><br><span class="line">55: istore 7 （将上一步加载的数字赋值给变量7，即i2【参照LocalVariableTable的slot数值】）</span><br><span class="line">57: getstatic #12 // Field java/lang/System.out:Ljava/io/PrintStream; （调用System的静态方法out）</span><br><span class="line">60: aload_1 （加载变量1，即s1）</span><br><span class="line">61: aload_2 （加载变量2，即s2）</span><br><span class="line">62: if_acmpne 69（比较s1和s2是否不相等，如果不相等，跳转到63行指令，如果相等则继续下一步，if_acmpne和if_icmpne，a表示对象引用比较，I表示数字比较；if_acmpeq和if_acmpne，eq【equal】表示相等，ne【not equal】）</span><br><span class="line">65: iconst_1 （将数字1压入栈）</span><br><span class="line">66: goto 70 （跳转到64行指令）</span><br><span class="line">69: iconst_0 （将数字0压入栈）</span><br><span class="line">70: invokevirtual #13 // Method java/io/PrintStream.println:(Z)V</span><br><span class="line">……</span><br><span class="line">156: getstatic #12 // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class="line">159: iload 6 （加载变量6，即i1）</span><br><span class="line">161: iload 7 （加载变量7，即i2）</span><br><span class="line">163: if_icmpne 170（比较i1和i2）</span><br><span class="line">166: iconst_1</span><br><span class="line">167: goto 171</span><br><span class="line">170: iconst_0</span><br><span class="line">171: invokevirtual #13 // Method java/io/PrintStream.println:(Z)V</span><br><span class="line">……</span><br><span class="line">150: return</span><br><span class="line">LocalVariableTable:</span><br><span class="line">Start Length Slot Name Signature</span><br><span class="line">0 151 0 args [Ljava/lang/String;</span><br><span class="line">3 148 1 s1 Ljava/lang/String;</span><br><span class="line">6 145 2 s2 Ljava/lang/String;</span><br><span class="line">16 135 3 s3 Ljava/lang/String;</span><br><span class="line">45 106 4 s4 Ljava/lang/String;</span><br><span class="line">51 100 5 s5 Ljava/lang/String;</span><br><span class="line">54 121 6 i1 I</span><br><span class="line">57 118 7 i2 I</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;代码&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#代码&quot;&gt;&lt;/a&gt; 代码&lt;/h3&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span cla
      
    
    </summary>
    
    
      <category term="Java" scheme="http://luxiaowan.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>GC日志分析</title>
    <link href="http://luxiaowan.github.io/2020/04/13/GC%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"/>
    <id>http://luxiaowan.github.io/2020/04/13/GC日志分析/</id>
    <published>2020-04-12T16:40:00.000Z</published>
    <updated>2020-04-12T16:46:14.671Z</updated>
    
    <content type="html"><![CDATA[<h3 id="vm参数"><a class="markdownIt-Anchor" href="#vm参数"></a> VM参数</h3><p>1、在控制台打印出每次GC信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+PrintGCDetails</span><br></pre></td></tr></table></figure><p>2、在发生OOM时打印出堆栈信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/Users/chuan/</span><br></pre></td></tr></table></figure><h3 id="oom代码"><a class="markdownIt-Anchor" href="#oom代码"></a> OOM代码</h3><p>发生OOM测试程序代码，也可以自行编写，运行VM参数（<code>-Xms1m -Xmx1m -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/Users/chuan/</code>）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OOMDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> K = <span class="number">1024</span>;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> M = K * K;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> G = K * M;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> ALIVE_OBJECT_SIZE = <span class="number">32</span> * M;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> length = ALIVE_OBJECT_SIZE / <span class="number">64</span>;</span><br><span class="line">    ObjectOf64Bytes[] array = <span class="keyword">new</span> ObjectOf64Bytes[length];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">long</span> i = <span class="number">0</span>; i &lt; G; i++) &#123;</span><br><span class="line">    array[(<span class="keyword">int</span>) (i % length)] = <span class="keyword">new</span> ObjectOf64Bytes();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ObjectOf64Bytes</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> placeholder0;</span><br><span class="line">  <span class="keyword">long</span> placeholder1;</span><br><span class="line">  <span class="keyword">long</span> placeholder2;</span><br><span class="line">  <span class="keyword">long</span> placeholder3;</span><br><span class="line">  <span class="keyword">long</span> placeholder4;</span><br><span class="line">  <span class="keyword">long</span> placeholder5;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="minor-gc日志"><a class="markdownIt-Anchor" href="#minor-gc日志"></a> Minor GC日志</h3><p><code>[GC --[PSYoungGen: 447K-&gt;447K(1024K)] 709K-&gt;956K(1536K), 0.0031459 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]</code></p><p>下面来解析这一段信息，其实很简单，不用硬记，按顺序从左到右：</p><ul><li><p>GC：表示这是发生了GC</p></li><li><p>PSYoungGen：GC类型，此处表示新生代内存发生了GC；</p></li><li><p>447K-&gt;447K：-&gt;前面的447K表示GC前新生代内存占用，-&gt;后面的447K表示GC后新生代内存占用（此处是分毫未被回收，那你执行个骡子，浪费 0.0031459秒）；</p></li><li><p>(1024K)：1024K表示新生代总共大小，看得出来是1M，可以回头看一下VM参数配置；</p></li><li><p>709K-&gt;956K：709K表示GC前JVM堆内存使用，956表示GC后JVM堆内存使用（硌老子的，GC后还变多了）；</p></li><li><p>(1536K):1536K表示JVM堆内存总大小；</p></li><li><p>0.0031459 secs：本次GC耗时（看得出还是很快的）；</p></li><li><p>user：GC用户耗时；</p></li><li><p>sys：GC系统耗时；</p></li><li><p>real：GC实际耗时。</p></li></ul><h3 id="full-gc日志"><a class="markdownIt-Anchor" href="#full-gc日志"></a> Full GC日志</h3><p><code>[Full GC [PSYoungGen: 447K-&gt;197K(1024K)] [ParOldGen: 508K-&gt;494K(512K)] 956K-&gt;692K(1536K), [Metaspace: 3179K-&gt;3179K(1056768K)], 0.0069504 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]</code></p><ul><li><p>Full GC：GC类型；</p></li><li><p>[PSYoungGen: 447K-&gt;197K(1024K)] ：Young区，447K表示GC前Young区内存占用，197K表示GC后Young区内存占用，1024K表示Young区总大小；</p></li><li><p>[ParOldGen: 508K-&gt;494K(512K)] ：Old区，508K表示GC前Old区内存占用，494K表示GC后Old区内存占用，512K表示Old区总大小；</p></li><li><p>956K-&gt;692K(1536K)：956K表示GC前JVM堆内存使用，692K表示GC后JVM堆内存使用，1536K表示JVM堆内存总大小；</p></li><li><p>[Metaspace: 3179K-&gt;3179K(1056768K)]：元空间，3179K表示GC前后元空间的使用，1056768K表示元空间的总大小（使用VM参数 -XX:-UseCompressedClassPointers -XX:MetaspaceSize=50M指定元空间的总大小）；</p></li><li><p>0.0069504 secs：本次GC耗时（看得出还是很快的）；</p></li><li><p>user：GC用户耗时；</p></li><li><p>sys：GC系统耗时；</p></li><li><p>real：GC实际耗时。</p></li></ul><blockquote><p>规律</p><p>[名称:GC前内存-&gt;GC后内存(总内存)]</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Heap</span><br><span class="line">PSYoungGen total 2560K, used 60K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000)</span><br><span class="line">eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0f038,0x00000000fff00000)</span><br><span class="line">from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000)</span><br><span class="line">to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000)</span><br><span class="line">ParOldGen total 7168K, used 736K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000)</span><br><span class="line">object space 7168K, 10% used [0x00000000ff600000,0x00000000ff6b8128,0x00000000ffd00000)</span><br><span class="line">Metaspace used 3328K, capacity 4112K, committed 4352K, reserved 8192K</span><br></pre></td></tr></table></figure><p>解析上述：</p><p>PSYoungGen total = eden space + from space，内存地址eden+from+to</p><p>ParOldGen GC前后老年代的内存变化</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;vm参数&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#vm参数&quot;&gt;&lt;/a&gt; VM参数&lt;/h3&gt;
&lt;p&gt;1、在控制台打印出每次GC信息：&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;t
      
    
    </summary>
    
    
      <category term="Java" scheme="http://luxiaowan.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>MySQL连接查询</title>
    <link href="http://luxiaowan.github.io/2020/04/12/MySQL%E8%BF%9E%E6%8E%A5%E6%9F%A5%E8%AF%A2/"/>
    <id>http://luxiaowan.github.io/2020/04/12/MySQL连接查询/</id>
    <published>2020-04-12T15:36:00.000Z</published>
    <updated>2020-04-12T17:08:48.838Z</updated>
    
    <content type="html"><![CDATA[<h3 id="左连接"><a class="markdownIt-Anchor" href="#左连接"></a> 左连接</h3><p>左连接基本格式为<code>A left join B on A.key=B.key</code>，比如以下语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from A left join B on A.id=B.id;</span><br></pre></td></tr></table></figure><p>如果A、B表的数据结构为：</p><table><thead><tr><th><code>table A</code></th><th><code>table B</code></th></tr></thead><tbody><tr><td>id, name</td><td>id, name</td></tr><tr><td>1, xiaolu</td><td>1, xiaolu</td></tr><tr><td>2, chuanchuan</td><td>3, chuanchuan</td></tr></tbody></table><p>这时执行上述语句会得出如下结果：</p><table><thead><tr><th><code>A.id</code></th><th><code>A.name</code></th><th><code>B.id</code></th><th><code>B.name</code></th></tr></thead><tbody><tr><td>1</td><td>Xiaolu</td><td>1</td><td>Xiaolu</td></tr><tr><td>2</td><td>chuanchuan</td><td>null</td><td>null</td></tr></tbody></table><p>由上述结果可以看出，左连接是以左表为坐标，首先将A表中所有的数据列出来，然后根据on的匹配条件查出B表中的数据并将数据列在A表数据后面，如果在B表中没有与A表中匹配的数据，则显示为null，查询出的总数据数为A表中的数据条目个数。</p><h3 id="右连接"><a class="markdownIt-Anchor" href="#右连接"></a> 右连接</h3><p>右连接基本格式为<code>A right join B on A.key=B.key</code>，比如以下语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from A right join B on A.id=B.id;</span><br></pre></td></tr></table></figure><p>如果A、B表的数据结构为：</p><table><thead><tr><th><code>table A</code></th><th><code>table B</code></th></tr></thead><tbody><tr><td>id, name</td><td>id, name</td></tr><tr><td>1, xiaolu</td><td>1, xiaolu</td></tr><tr><td>2, chuanchuan</td><td>3, chuanchuan</td></tr></tbody></table><p>这时执行上述语句会得出如下结果：</p><table><thead><tr><th><code>B.id</code></th><th><code>B.name</code></th><th><code>A.id</code></th><th><code>A.name</code></th></tr></thead><tbody><tr><td>1</td><td>xiaolu</td><td>1</td><td>xiaolu</td></tr><tr><td>null</td><td>null</td><td>3</td><td>chuanchuan</td></tr></tbody></table><p>由上述结果可以看出，左连接是以左表为坐标，首先将B表中所有的数据列出来，然后根据on的匹配条件查出A表中的数据并将A表的数据列在B表的前面，如果在A表中没有与B表中匹配的数据，则显示为null，查询出的总数据数为B表中的数据条目个数。</p><h3 id="内链接"><a class="markdownIt-Anchor" href="#内链接"></a> 内链接</h3><p>内连接基本格式为<code>A inner join B on A.key=B.key</code>，比如以下语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from A inner join B on A.id=B.id;</span><br></pre></td></tr></table></figure><p>如果A、B表的数据结构为：</p><table><thead><tr><th><code>table A</code></th><th><code>table B</code></th></tr></thead><tbody><tr><td>id, name</td><td>id, name</td></tr><tr><td>1, xiaolu</td><td>1, xiaolu</td></tr><tr><td>2, chuanchuan</td><td>3, chuanchuan</td></tr></tbody></table><p>这时执行上述语句会得出如下结果：</p><table><thead><tr><th><code>B.id</code></th><th><code>B.name</code></th><th><code>A.id</code></th><th><code>A.name</code></th></tr></thead><tbody><tr><td>1</td><td>xiaolu</td><td>1</td><td>xiaolu</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;左连接&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#左连接&quot;&gt;&lt;/a&gt; 左连接&lt;/h3&gt;
&lt;p&gt;左连接基本格式为&lt;code&gt;A left join B on A.key=B.key&lt;/code&gt;，比如以下语句：&lt;/p&gt;
&lt;figure
      
    
    </summary>
    
    
      <category term="MySQL" scheme="http://luxiaowan.github.io/categories/MySQL/"/>
    
    
  </entry>
  
  <entry>
    <title>MySQL联合索引底层数据结构</title>
    <link href="http://luxiaowan.github.io/2020/04/12/MySQL%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>http://luxiaowan.github.io/2020/04/12/MySQL联合索引底层数据结构/</id>
    <published>2020-04-12T07:36:00.000Z</published>
    <updated>2020-04-12T10:39:05.585Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>了解MySQL索引结构的基本都知道索引BTree类型是用B+树的数据结构，单列索引的结构我们很容易理解，二级索引的每个叶子节点只存储主键关键字外的一个数据，查询起来也很容易在非叶子节点进行大小值判断，最终找到叶子节点</p><p><img src="/images/image-20200409120534155.png" alt="单列索引"></p><p>对于多列组合索引，存储结构也是B+树，那么非叶子节点和叶子节点都存储的是什么内容？</p><h3 id="二级组合索引"><a class="markdownIt-Anchor" href="#二级组合索引"></a> 二级组合索引</h3><p>对于组合索引，需要遵循断桥原则(最左匹配原则)，例如(a, b,)可以满足a，a、b，我们根据这个原则反推一下二级组合索引的存储规则：</p><ol><li>叶子节点应该是线性排列，并且每个节点的数据排列顺序和创建索引字段的顺序一致</li><li>叶子节点排列顺序应该是先按照a进行排序，排序完成后再按照b进行排序，所以应该是a是全局有序，b是a中有序，如果列数更多的情况下，下一列都相对于前列有序。</li><li>非叶子节点存储完整的索引关键字信息，排列规则和叶子节点一致</li><li>整体查询使用二分法</li></ol><p>根据上述推断，我们基本可以判定二级组合索引的数据结构图了</p><p><img src="/images/image-20200412180233754.png" alt="image-20200412180233754"></p><p>上面我们进行了规则反推，也根据反推总结出了简单的组合索引数据结构图，那么我们来验证一下上述推论：</p><ol><li>因为索引遵循断桥原则，B+树是顺序且极限二分查找的方式进行遍历，所以在进行B+树遍历的时候从左到右进行匹配，并且我们创建索引的目的是为了提升查询效率，如果每个节点中数据和索引的字段顺序不一致，各执己见，那么在查询的时候还要判断当前节点的某位数据对应了索引的哪个字段，效率会更低，所以推论1是可信可靠的。</li><li>根据图中叶子节点的数据可以看出，所有的数据都是按照列A进行排序的1、2、3、4，B列的顺序为1、2、1、5、1、5，B列全局是无序的，这就尴尬了，如果我们仅按照列B去查询，在索引中匹配的时候岂不是很麻烦，或者说压根儿就无法匹配，这也就明白了为什么仅使用到列B的时候不会走索引了，那仅使用A的时候可以走索引是因为列A在索引树中相对于全局是有序的，所以可以根据列A进行二分查找和定位。由此可见推论2也是可靠的。</li><li>B+树的非叶子节点存储的是索引关键字的数据信息，并且根据推论2的结果可以验证推论3也是正确的。</li><li>B+树是使用二分法进行查找的，所以推论4是正确的。</li></ol><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>我们根据B+树的特性、索引的断桥原则和单列索引存储特性三个方面反推组合索引的数据存储结构，并验证了我们的推论，这仅仅是串一串的推论，可能不靠谱，哈哈~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;了解MySQL索引结构的基本都知道索引BTree类型是用B+树的数据结构，单列索引的结构我们很容易理解，二级索引的每个叶子节点只存储主键关键字外
      
    
    </summary>
    
    
      <category term="MySQL" scheme="http://luxiaowan.github.io/categories/MySQL/"/>
    
    
      <category term="索引" scheme="http://luxiaowan.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>Redis和MySQL分布式双写一致性</title>
    <link href="http://luxiaowan.github.io/2020/04/12/Redis%E5%92%8CMySQL%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <id>http://luxiaowan.github.io/2020/04/12/Redis和MySQL分布式双写一致性/</id>
    <published>2020-04-12T06:37:00.000Z</published>
    <updated>2020-04-12T14:50:23.244Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>一个MySQL服务和一个Redis服务，用户的数据存储持久化在MySQL中，缓存在Redis中，有请求的时候从Redis中获取缓存的用户数据，有修改则同时修改MySQL和Redis中的数据。现在问题是：不论是先保存到MySQL还是Redis，都面临着此成功彼失败的情况，那么如何保证MySQL与Redis中的数据一致？</p><h3 id="数据一致性"><a class="markdownIt-Anchor" href="#数据一致性"></a> 数据一致性</h3><p>数据一致性主要出现在使用不同存储组件的情况下，存储组件之间无法直接通信，所以不能相互之间实现数据交换，但是使用第三方来单独操作各存储组建时，有极大的可能造成各存储组件之间数据不一致。</p><p>数据一致性分为强一致性和最终一致性，强一致性的情况是不论何时访问哪一个存储组件，所得到的数据都是一样的，最终一致性的情况是可以在某短时间内访问不同存储组件所得到的数据允许不一样。我们实际的生产开发中，基本都是遵循最终一致性。</p><h3 id="mysql和redis一致性"><a class="markdownIt-Anchor" href="#mysql和redis一致性"></a> MySQL和Redis一致性</h3><p>Redis一般用于存储热点数据，MySQL存储所有数据。但是在更新缓存这方面有多种方案：</p><ul><li>先删除缓存，再更新数据库</li><li>先更新缓存，再更新数据库</li><li>先更新数据库，在更新缓存</li><li>先更新数据库，再删除缓存</li><li>先更新数据库，再给缓存设置过期时间</li><li>使用Canal中间件</li></ul><h4 id="先删除缓存再更新数据库不可取"><a class="markdownIt-Anchor" href="#先删除缓存再更新数据库不可取"></a> 先删除缓存，再更新数据库（不可取）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">()</span>:</span></span><br><span class="line">  deleteRedis()</span><br><span class="line">  updateDB()</span><br></pre></td></tr></table></figure><p>第一步先删除缓存，第二步再更新数据库，如果在第一步之后，其他线程发生了数据库读操作，然后读到的旧数据又set到了Redis中，然后第二步执行，最终Redis和MySQL中的数据出现了不一致</p><h4 id="先更新缓存再更新数据库不可取"><a class="markdownIt-Anchor" href="#先更新缓存再更新数据库不可取"></a> 先更新缓存，再更新数据库（不可取）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">()</span>:</span></span><br><span class="line">  updateRedis()</span><br><span class="line">  updateDB()</span><br></pre></td></tr></table></figure><p>第一步先更新缓存，第二步更新数据库，如果更新Redis成功，但是更新数据库失败，则两者的数据又出现了不一致</p><h4 id="先更新数据库在更新缓存不可取"><a class="markdownIt-Anchor" href="#先更新数据库在更新缓存不可取"></a> 先更新数据库，在更新缓存（不可取）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">()</span>:</span></span><br><span class="line">  updateDB()</span><br><span class="line">  updateRedis()</span><br></pre></td></tr></table></figure><p>两个线程同时对一条数据进行操作，在线程B先于线程A更新缓存成功，则造成了缓存中的数据低于MySQL一个版本</p><p>####先更新数据库，再删除缓存（可取）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">()</span>:</span></span><br><span class="line">  updateDB()</span><br><span class="line">  deleteRedis()</span><br></pre></td></tr></table></figure><p>两个线程同时操作一条数据，甭管哪一个先操作成功，最终都会删除掉缓存中的数据，然后由查询将最新数据set到缓存中，但是在并发量大的情况下，由于缓存被删除了两次，可能会造成缓存击穿</p><h4 id="先更新数据库再给缓存设置过期时间推荐"><a class="markdownIt-Anchor" href="#先更新数据库再给缓存设置过期时间推荐"></a> 先更新数据库，再给缓存设置过期时间（推荐）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">()</span>:</span></span><br><span class="line">  updateDB()</span><br><span class="line">  expireRedis()</span><br></pre></td></tr></table></figure><p>更新完数据库之后，并不立即删除缓存，而是给缓存设置一个过期时间，由缓存自行过期，使用这个方案的前提是能允许数据可以很短时间内的不一致，并且推荐</p><h4 id="使用canal中间件可取"><a class="markdownIt-Anchor" href="#使用canal中间件可取"></a> 使用Canal中间件（可取）</h4><p>Canal是阿里巴巴开源的一款数据库同步工具，他可以将自己伪装成一个MySQL Slave节点，将MySQL的binlog文件同步到Canal，然后由Canal进行下一步处理，比如存入MQ、Redis等，但是可能会存在些许延迟。后续讨论</p><h3 id="强一致性"><a class="markdownIt-Anchor" href="#强一致性"></a> 强一致性</h3><p>如果想要求数据强一致性，就只用MySQL，不要用Redis，以免出现不一致的情况</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;一个MySQL服务和一个Redis服务，用户的数据存储持久化在MySQL中，缓存在Redis中，有请求的时候从Redis中获取缓存的用户数据，有
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Consul心跳机制</title>
    <link href="http://luxiaowan.github.io/2020/04/12/Consul%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6/"/>
    <id>http://luxiaowan.github.io/2020/04/12/Consul心跳机制/</id>
    <published>2020-04-11T16:26:00.000Z</published>
    <updated>2020-04-11T18:25:09.519Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>我们知道Eureka是通过Client向Server发送renew通知来续命，属于是&quot;去中心化&quot;的设计，而Consul是&quot;中心化&quot;设计，Consul的心跳由Server端发起</p><h3 id="consul心跳"><a class="markdownIt-Anchor" href="#consul心跳"></a> Consul心跳</h3><p>Client在注册到Consul Server的时候(<code>ConsulServiceRegistry#register</code>)，会将客户端的注册信息全部发送给注册中心(接口：<code>/v1/agent/service/register</code>)，其中主要信息包括服务id、name、ip、port、health-check-url等，所以Consul Server才会知道向Client的哪个接口发送心跳。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    id='consul-demo-7702',</span><br><span class="line">    name='consul-demo',</span><br><span class="line">    tags=[</span><br><span class="line">        secure=false</span><br><span class="line">    ],</span><br><span class="line">    address='192.168.0.107',</span><br><span class="line">    meta=null,</span><br><span class="line">    port=7702,</span><br><span class="line">    enableTagOverride=null,</span><br><span class="line">    check=Check&#123;</span><br><span class="line">        script='null',</span><br><span class="line">        interval='10s',</span><br><span class="line">        ttl='null',</span><br><span class="line">        http='http://192.168.0.107:7702/health',</span><br><span class="line">        method='null',</span><br><span class="line">        header=&#123;</span><br><span class="line">        &#125;,</span><br><span class="line">        tcp='null',</span><br><span class="line">        timeout='null',</span><br><span class="line">        deregisterCriticalServiceAfter='null',</span><br><span class="line">        tlsSkipVerify=null,</span><br><span class="line">        status='null'</span><br><span class="line">    &#125;,</span><br><span class="line">    checks=null</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里check.http是值是我们在项目的properties文件中配置的：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.port</span>=<span class="string">7702</span></span><br><span class="line"><span class="meta">spring.application.name</span>=<span class="string">consul-demo</span></span><br><span class="line"><span class="meta">spring.cloud.consul.host</span>=<span class="string">127.0.0.1</span></span><br><span class="line"><span class="meta">spring.cloud.consul.port</span>=<span class="string">8500</span></span><br><span class="line"><span class="comment"># 心跳接口</span></span><br><span class="line"><span class="meta">spring.cloud.consul.discovery.health-check-path</span>=<span class="string">/health</span></span><br></pre></td></tr></table></figure><p>Spring Cloud Consul的心跳接口默认为actuator包中的/actuator/health，所以如果我们既没设置自定义的心跳接口，也没依赖actuator包，那么Consul Server就会在我们注册的Service上显示service checks fail</p><p><img src="/images/image-20200412013415372.png" alt="image-20200412013415372"></p><p>我们查看Consul Server控制台，发现会控制台健康检查语句<code>agent: Check is now critical: check=service:consul-demo-client-18090</code>，正常的健康检查语句是<code>agent: Check status updated: check=service:consul-demo-7702 status=passing</code></p><p>默认情况下Consul会每隔10秒，通过一个HTTP接口<code>/health</code>来检测节点的健康情况。 如果健康检测失败，那服务实例就会被标记成critical，可以通过在检查定义中指定超时字段来配置自定义HTTP检查超时值，检查的输出限制在大约4KB，大于此值的响应将被截断，会被认为健康检查未通过。</p><blockquote><p>spring.cloud.consul.discovery.prefer-ip-address参数决定上报给注册中心的健康接口是IP还是hostname</p></blockquote><ul><li><p>健康检查接口创建源码</p><p>ConsulAutoRegistration#createCheck</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> NewService.<span class="function">Check <span class="title">createCheck</span><span class="params">(Integer port,</span></span></span><br><span class="line"><span class="function"><span class="params">HeartbeatProperties ttlConfig, ConsulDiscoveryProperties properties)</span> </span>&#123;</span><br><span class="line">  NewService.Check check = <span class="keyword">new</span> NewService.Check();</span><br><span class="line">  <span class="keyword">if</span> (StringUtils.hasText(properties.getHealthCheckCriticalTimeout())) &#123;</span><br><span class="line">    check.setDeregisterCriticalServiceAfter(</span><br><span class="line">      properties.getHealthCheckCriticalTimeout());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (ttlConfig.isEnabled()) &#123;</span><br><span class="line">    check.setTtl(ttlConfig.getTtl());</span><br><span class="line">    <span class="keyword">return</span> check;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Assert.notNull(port, <span class="string">"createCheck port must not be null"</span>);</span><br><span class="line">  Assert.isTrue(port &gt; <span class="number">0</span>, <span class="string">"createCheck port must be greater than 0"</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 若自定义了spring.cloud.consul.discovery.health-check-url</span></span><br><span class="line">  <span class="keyword">if</span> (properties.getHealthCheckUrl() != <span class="keyword">null</span>) &#123;</span><br><span class="line">    check.setHttp(properties.getHealthCheckUrl());</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 自定义了spring.cloud.consul.discovery.health-check-path或默认</span></span><br><span class="line">    check.setHttp(String.format(<span class="string">"%s://%s:%s%s"</span>, properties.getScheme(),</span><br><span class="line">                                properties.getHostname(), port, properties.getHealthCheckPath()));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// spring.cloud.consul.discovery.health-check-headers</span></span><br><span class="line">  check.setHeader(properties.getHealthCheckHeaders());</span><br><span class="line">  <span class="comment">// 设置健康检查频率spring.cloud.consul.discovery.health-check-interval，字符串，要加上单位"5s"</span></span><br><span class="line">  check.setInterval(properties.getHealthCheckInterval());</span><br><span class="line">  <span class="comment">// 设置健康检查超时时间spring.cloud.consul.discovery.health-check-timeout，字符串，要加上单位"5s"</span></span><br><span class="line">  check.setTimeout(properties.getHealthCheckTimeout());</span><br><span class="line">  check.setTlsSkipVerify(properties.getHealthCheckTlsSkipVerify());</span><br><span class="line">  <span class="keyword">return</span> check;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/image-20200412020911482.png" alt="image-20200412020911482"></p><p>图中Tags一栏有一个<code>secure=false</code>，这个是由客户端返回给Server，这个标识是检测健康检查接口是否为https协议</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;String&gt; <span class="title">createTags</span><span class="params">(ConsulDiscoveryProperties properties)</span> </span>&#123;</span><br><span class="line">  List&lt;String&gt; tags = <span class="keyword">new</span> LinkedList&lt;&gt;(properties.getTags());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!StringUtils.isEmpty(properties.getInstanceZone())) &#123;</span><br><span class="line">    tags.add(properties.getDefaultZoneMetadataName() + <span class="string">"="</span></span><br><span class="line">             + properties.getInstanceZone());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!StringUtils.isEmpty(properties.getInstanceGroup())) &#123;</span><br><span class="line">    tags.add(<span class="string">"group="</span> + properties.getInstanceGroup());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 检查请求schema是否为https</span></span><br><span class="line">  tags.add(<span class="string">"secure="</span></span><br><span class="line">           + Boolean.toString(properties.getScheme().equalsIgnoreCase(<span class="string">"https"</span>)));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> tags;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;我们知道Eureka是通过Client向Server发送renew通知来续命，属于是&amp;quot;去中心化&amp;quot;的设计，而Consul是&amp;q
      
    
    </summary>
    
    
      <category term="SpringBoot" scheme="http://luxiaowan.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringCloud" scheme="http://luxiaowan.github.io/tags/SpringCloud/"/>
    
  </entry>
  
  <entry>
    <title>Consul是什么</title>
    <link href="http://luxiaowan.github.io/2020/04/11/Consul%E6%98%AF%E4%BB%80%E4%B9%88/"/>
    <id>http://luxiaowan.github.io/2020/04/11/Consul是什么/</id>
    <published>2020-04-11T07:32:00.000Z</published>
    <updated>2020-04-11T15:37:22.399Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>Consul是一个基于CP的轻量级分布式高可用的系统，提供服务发现、健康检查、K-V存储、多数据中心等功能，不需要再依赖其他组件(Zk、Eureka、Etcd等)。</p><ul><li>服务发现：Consul可以提供一个服务，比如api或者MySQL之类的，其他客户端可以使用Consul发现一个指定的服务提供者，并通过DNS和HTTP应用程序可以很容易的找到所依赖的服务。</li><li>健康检查：Consul客户端提供相应的健康检查接口，Consul服务端通过调用健康检查接口检测客户端是否正常</li><li>K-V存储：客户端可以使用Consul层级的Key/Value存储，比如动态配置,功能标记,协调,领袖选举等等</li><li>多数据中心：Consul支持开箱即用的多数据中心</li></ul><h3 id="架构介绍"><a class="markdownIt-Anchor" href="#架构介绍"></a> 架构介绍</h3><img src="/images/consul-arch-420ce04a.png" alt="Consul Architecture" style="zoom: 30%;"><p>看得出一个Consul集群是由N个Server和M个Client节点组成的。</p><ul><li>Client节点：使用的client模式，该模式下可以接收服务的注册请求，但是会把请求转发给Server节点，自身不做处理，并且不持久化在本地</li><li>Server节点：使用server模式，处理注册请求，将注册信息持久化到本地，用作故障恢复。<ul><li>Server节点分为Leader和Follower两个身份，Leader负责监控Follower，同步注册信息给所有的Follower，一个集群中只能有一个Leader</li><li>Server之间通过RPC消息通信，Follower不会主动发起RPC请求，只会有Leader或选举时的Candidate主动发起</li><li>Follower节点接收到RPC请求后，会将请求转发给Leader节点，由Leader节点处理后进行相应的ACK，请求分为事务型和非事务型，非事务型的请求由Leader节点直接响应，事务型的请求</li><li>集群一般推荐3或5个节点比较合适，因为Raft选举时，4和3、5和6的结果是一样的</li></ul></li></ul><h4 id="gossip是什么"><a class="markdownIt-Anchor" href="#gossip是什么"></a> Gossip是什么</h4><p>从架构图中发现有一个Gossip，一个DC中涵盖了两个Gossip池，LAN池和WAN池，为什么会有Gossip，因为Consul是建立在Serf基础之上的，Gossip由Serf提供，Gossip是一个去中心化的协议。Consul中用Gossip维护节点关系，告知当前节点集群中还有哪些节点，其他节点的身份，是Follower还是Leader。</p><ul><li>LAN Gossip：局域网内唯一，LAN池是用于局域网内的节点消息广播，Consul的Client和Server节点全部都在LAN池中，LAN池中的客户端可以自动发现服务器，不需要进行过多的配置，LAN池能保证快速可靠的消息传播，比如Leader选举。</li><li>WAN Gossip：WAN是全局唯一的，无论属于哪一个DC，所有Server应该加入到WAN中，由WAN提供信息让Server节点可以执行跨数据中心的请求。</li></ul><h3 id="工作原理"><a class="markdownIt-Anchor" href="#工作原理"></a> 工作原理</h3><img src="/images/consol_service.png" alt="consol_service" style="zoom:75%;"><ol><li>Producer启动之后，会向Consul注册中心发送一个POST请求，上报自己的id、name、ip、port、健康检查接口、心跳频率等信息</li><li>Consul接收到Producer上报的信息之后，根据上报的心跳频率和健康检查接口对Producer进行健康检查，检验Producer是否健康</li><li>Consumer启动之后，会从Consul拉取Producer的列表缓存在本地，后续的请求都会从本地选举发出，使用RestTemplate发出请求的时候，每次都会从Consul同步一下服务者信息。</li></ol><h3 id="leader选举"><a class="markdownIt-Anchor" href="#leader选举"></a> Leader选举</h3><p>一个DC可以有多个Server，但是只能有一个Leader，Leader基于Raft算法进行选举，在Leader选举过程中，整个集群都无法对外提供服务。</p><p>节点的身份有Follower、Candidate、Leader三种，所有的节点在初始化的时候都为Follower，节点加入到LAN Gossip池后，由Raft协议的Leader-Follower模式进行Leader选举。</p><p><img src="/images/raft-status.png" alt="Raft状态变更"></p><ul><li><p>概念</p><ul><li>Leader：集群中仅有一个，处理客户端所有的请求，遇到事务型的请求时会在本地处理后再生成同步日志，由Gossip通知到各个Follower节点进行同步</li><li>Follower：所有节点的初始状态，正常集群中可以有多个Follower，不处理任何请求也不发送任何请求，只响应来自Leader和Candidate的请求，当接收到客户端发来的请求时会自动将请求转发给Leader节点处理</li><li>Candidate：Follower超过选举器时都未收到来自Leader的心跳时，自动转换身份为Candidate，并根据Raft算法执行新一轮的Leader选举</li><li>Election Time(选举超时时间)：每一个节点都维护着自己的选举计时器，这个计时器的值需要大于心跳间隔，Follower收到Leader的心跳请求后会重置选举计时器，如果这个计时器归零了，则将节点身份转换为Candidate，并向其他节点发送投票。设置选举计时器主要是为了防止因为网络抖动等问题而引起心跳消息丢失，不然可能一旦心跳丢失了就立刻进入选举</li><li>Heart time(心跳超时时间)：Leader向Follower发送心跳的时间间隔</li><li>Term(任期)：任期是一个全局递增的数字，没进行一次选举，任期数就+1，每个节点都记录该值</li></ul></li><li><p>Raft算法</p><p>Raft是一个共识算法，也就是当大多数对某个事情都赞同的情况下执行该事情，主要为解决分布式一致性的问题。Raft算法是从Paxos的理论演变而来，Raft把问题分解成领导选举、日志复制、安全和成员变化</p><ul><li>领导选举：集群中必须存在一个Leader节点</li><li>日志复制：Leader节点接收并处理客户端的请求，然后将这些请求序列化成日志再同步到集群中的其他节点</li><li>安全性：已经被Raft状态机记录过的数据，就不能被再次输入到Raft状态机中</li></ul></li><li><p>Leader选举过程</p><ul><li><p>选举过程</p><p>在节点刚开始启动时，初始状态是Follower状态。一个Follower状态的节点，只要一直收到来自Leader或者Candidate的正确RPC消息的话，将一直保持在Follower状态。Leader节点通过周期性的发送心跳请求（一般使用带有空数据的AppendEntries RPC来进行心跳）来维持着Leader节点状态。每个Follower同时还有一个选举超时（Election timeout）定时器，如果在这个定时器超时之前都没有收到来自Leader的心跳请求，那么Follower将认为当前集群中没有Leader了，将发起一次新的选举。</p><p>发起选举时，Follower将递增它的任期号然后切换到Candidate状态。然后通过向集群中其它节点发送RequestVote RPC请求来发起一次新的选举，一个节点将保持在该任期内的Candidate状态下。</p></li><li><p>选举过程中可能遇到的问题</p><ul><li><p>该Candidate节点收到超过半数以上集群中其它节点的投票赢得选举</p><p>如果Candidate节点收到了集群中半数以上节点的投票，那么此Candidate节点将成为新的Leader。每个节点在一个任期中只能给一个节点投票，而且遵守“先来后到”的原则，这样就保证每个任期最多只有一个节点会赢得选举成为leader。</p></li><li><p>收到任期号比当前节点任期号不一致的请求</p><ul><li>比当前节点任期号小：说明当前集群已经进入了下一轮选举，则自动拒绝收到的请求，继续保持在Candidate状态</li><li>比当前节点任期号大：说明集群中已经存在了Leader，节点从Candidate切换到Follower</li></ul></li><li><p>选举后没有任何一个节点成为Leader</p><p>本次选举未选举出Leader，则将集群中的任期号+1，再次进行选举</p></li></ul></li></ul></li></ul><h3 id="springcloud使用consul"><a class="markdownIt-Anchor" href="#springcloud使用consul"></a> SpringCloud使用Consul</h3><ol><li><p>安装并启动Consul Server</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./consul agent -dev</span><br></pre></td></tr></table></figure></li><li><p>创建SpringCloud项目</p><ul><li>服务提供方</li></ul><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.port</span>=<span class="string">7702</span></span><br><span class="line"><span class="meta">spring.application.name</span>=<span class="string">consul-demo</span></span><br><span class="line"><span class="meta">spring.cloud.consul.host</span>=<span class="string">127.0.0.1</span></span><br><span class="line"><span class="meta">spring.cloud.consul.port</span>=<span class="string">8500</span></span><br><span class="line"><span class="meta">spring.cloud.consul.discovery.health-check-path</span>=<span class="string">/health</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/health"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">health</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  System.out.println(<span class="string">"----health check----"</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="string">"hello consul"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>服务调用方</li></ul><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.port</span>=<span class="string">18090</span></span><br><span class="line"><span class="meta">spring.application.name</span>=<span class="string">consul-demo-client</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@LoadBalanced</span></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RestTemplate <span class="title">restTemplate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> RestTemplate();</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Resource</span></span><br><span class="line"><span class="keyword">private</span> RestTemplate restTemplate;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/hello"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> restTemplate.getForObject(<span class="string">"http://consul-demo/health"</span>, String.class);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>两个项目启动后，查看服务注册情况：<a href="http://127.0.0.1:8500/" target="_blank" rel="noopener">http://127.0.0.1:8500/</a></li></ul><p><img src="/images/image-20200411225129805.png" alt="image-20200411225129805"></p><p>访问接口测试：<a href="http://127.0.0.1:18090/hello" target="_blank" rel="noopener">http://127.0.0.1:18090/hello</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;Consul是一个基于CP的轻量级分布式高可用的系统，提供服务发现、健康检查、K-V存储、多数据中心等功能，不需要再依赖其他组件(Zk、Eure
      
    
    </summary>
    
    
      <category term="SpringBoot" scheme="http://luxiaowan.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringCloud" scheme="http://luxiaowan.github.io/tags/SpringCloud/"/>
    
  </entry>
  
  <entry>
    <title>Eureka集群搭建</title>
    <link href="http://luxiaowan.github.io/2020/04/11/Eureka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://luxiaowan.github.io/2020/04/11/Eureka集群搭建/</id>
    <published>2020-04-11T05:16:00.000Z</published>
    <updated>2020-04-11T07:17:46.106Z</updated>
    
    <content type="html"><![CDATA[<h3 id="eureka集群"><a class="markdownIt-Anchor" href="#eureka集群"></a> Eureka集群</h3><p>Eureka是基于AP的分布式服务注册中心，集群中所有的Server节点都互为对方的备份，可以把所有的节点都看作是Master节点，也可以把所有的节点都看作是Slave节点，任一节点接收到新的服务注册请求后，都会在registry完成之后同步给其他的Server节点，续约操作renew和registry的逻辑一样。</p><img src="/images/image-20200411134658642.png" alt="image-20200411134658642" style="zoom:50%;"><p>当集群中一个Server节点宕机之后，Client会把自动切换到存活的节点，由于集群中的所有Server之间是相互同步的，所以各个Server节点之间的信息是相同的，除非是在一个Client刚注册到Server1还未同步给其他节点时宕机了，会造成信息不一致的情况，但当节点将续约请求发送给其他节点时，如果这个节点没有这个Client的信息，则会重新进行registry，并同步给集群中的其他节点。</p><img src="/images/image-20200411134915369.png" alt="image-20200411134915369" style="zoom:50%;"><p>因为Eureka集群是基于AP的，所以只要有一个Server节点可用，那么整个集群就是可用的，每一个Server节点都有一个server_id属性，当节点宕机后，会选择server_id值靠的最近的Server接收宕机节点的请求。</p><h3 id="搭建集群"><a class="markdownIt-Anchor" href="#搭建集群"></a> 搭建集群</h3><p>Eureka Server搭建很简单，最主要的就是节点配置文件的内容</p><ol><li>Eureka Server</li></ol><ul><li>peer1</li></ul><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9001</span> <span class="comment">#服务端口</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  instance:</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">peer1</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    register-with-eureka:</span> <span class="literal">false</span> <span class="comment">#是否将eureka自身作为应用注册到eureka注册中心</span></span><br><span class="line"><span class="attr">    fetch-registry:</span> <span class="literal">false</span> <span class="comment">#为true时，可以启动，但报异常：Cannot execute request on any known server</span></span><br><span class="line"><span class="attr">    serviceUrl:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://peer2:9002/eureka/,http://peer3:9003/eureka/</span></span><br><span class="line"><span class="attr">  server:</span></span><br><span class="line"><span class="attr">    enable-self-preservation:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><ul><li>peer2</li></ul><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9002</span> <span class="comment">#服务端口</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  instance:</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">peer2</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    register-with-eureka:</span> <span class="literal">false</span> <span class="comment">#是否将eureka自身作为应用注册到eureka注册中心</span></span><br><span class="line"><span class="attr">    fetch-registry:</span> <span class="literal">false</span> <span class="comment">#为true时，可以启动，但报异常：Cannot execute request on any known server</span></span><br><span class="line"><span class="attr">    serviceUrl:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://peer1:9001/eureka/,http://peer3:9003/eureka/</span></span><br><span class="line"><span class="attr">  server:</span></span><br><span class="line"><span class="attr">    enable-self-preservation:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><ul><li>peer3</li></ul><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line"><span class="attr">  port:</span> <span class="number">9003</span> <span class="comment">#服务端口</span></span><br><span class="line"><span class="attr">eureka:</span></span><br><span class="line"><span class="attr">  instance:</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">peer3</span></span><br><span class="line"><span class="attr">  client:</span></span><br><span class="line"><span class="attr">    register-with-eureka:</span> <span class="literal">false</span> <span class="comment">#是否将eureka自身作为应用注册到eureka注册中心</span></span><br><span class="line"><span class="attr">    fetch-registry:</span> <span class="literal">false</span> <span class="comment">#为true时，可以启动，但报异常：Cannot execute request on any known server</span></span><br><span class="line"><span class="attr">    serviceUrl:</span></span><br><span class="line"><span class="attr">      defaultZone:</span> <span class="attr">http://peer1:9001/eureka/,http://peer2:9002/eureka/</span></span><br><span class="line"><span class="attr">  server:</span></span><br><span class="line"><span class="attr">    enable-self-preservation:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><ol start="2"><li>Eureka Client</li></ol><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.port</span>=<span class="string">7080</span></span><br><span class="line"><span class="meta">spring.application.name</span>=<span class="string">eureka-health</span></span><br><span class="line"><span class="meta">eureka.client.service-url.defaultZone</span>=<span class="string">http://127.0.0.1:9001/eureka/</span></span><br><span class="line"><span class="meta">eureka.instance.health-check-url-path</span>=<span class="string">/cc/health</span></span><br><span class="line"><span class="meta">eureka.instance.lease-renewal-interval-in-seconds</span>=<span class="string">5</span></span><br><span class="line"><span class="meta">eureka.instance.lease-expiration-duration-in-seconds</span>=<span class="string">15</span></span><br></pre></td></tr></table></figure><p>在客户端的defaultZone不论设置集群中的哪一个节点或哪几个节点，整个集群的所有节点都会有这个Client的注册信息，这就是因为Server节点的replicate功能。</p><p><img src="/images/image-20200411143623870.png" alt="image-20200411143623870"></p><p>当我们关闭掉其他Server节点，只留一个可用节点的时候，注册中心仍然可以提供服务。但如果我们在Client的defaultZone只设置一个节点的信息的话，那么在这个节点宕机之后，Client就找不到可以继续renew的节点了，最终整个集群都收不到这个Client的续约，在<code>lease-expiration-duration-in-seconds</code>之后，集群会将这个Client从服务列表移除，这损失可就太大了。</p><p>所以应该把Server和Client节点的defaultZone要设置齐全。Client把所有Server节点都设置进来，Server节点也把所有的Server节点都设置进来。</p><h3 id="集群参数"><a class="markdownIt-Anchor" href="#集群参数"></a> 集群参数</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Eureka Server启动时，从远程Eureka Server读取不到注册信息时，多长时间不允许Client访问，默认5分钟</span></span><br><span class="line"><span class="attr">eureka.server.wait-time-in-ms-when-sync-empty</span></span><br><span class="line"><span class="comment"># Eureka Server 集群节点更新频率，单位：毫秒，默认10分钟</span></span><br><span class="line"><span class="attr">eureka.server.peer-eureka-nodes-update-interval-ms</span></span><br><span class="line"><span class="comment"># 初始化实例信息到Eureka服务端的间隔时间，单位为秒，默认40秒</span></span><br><span class="line"><span class="attr">eureka.client.initial-instance-info-replication-interval-seconds</span></span><br><span class="line"><span class="comment"># 更新实例信息的变化到Eureka服务端的间隔时间，单位为秒，默认30秒</span></span><br><span class="line"><span class="attr">eureka.client.instance-info-replication-interval-seconds</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;eureka集群&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#eureka集群&quot;&gt;&lt;/a&gt; Eureka集群&lt;/h3&gt;
&lt;p&gt;Eureka是基于AP的分布式服务注册中心，集群中所有的Server节点都互为对方的备份，可以把所有的节点都
      
    
    </summary>
    
    
      <category term="SpringBoot" scheme="http://luxiaowan.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringCloud" scheme="http://luxiaowan.github.io/tags/SpringCloud/"/>
    
  </entry>
  
  <entry>
    <title>Eureka心跳检测</title>
    <link href="http://luxiaowan.github.io/2020/04/10/Eureka%E5%BF%83%E8%B7%B3%E6%A3%80%E6%B5%8B/"/>
    <id>http://luxiaowan.github.io/2020/04/10/Eureka心跳检测/</id>
    <published>2020-04-10T13:18:00.000Z</published>
    <updated>2020-04-10T18:45:18.617Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>注册中心的心跳机制有两种形式：客户端主动上报和客户端被动响应。Eureka属于是主动上报类型的，Client通过renew机制频繁的向Server发送消息，通知Server它还活着，不要将其从服务列表中剔除，但是我们renew仅仅是监控Client是否存活，并不会去检测Client依赖的服务是否存活</p><img src="/images/image-20200410233537737.png" alt="image-20200410233537737" style="zoom: 40%;"><p>从图中我们发现Client123和Client456两个客户端均依赖了第三方组件，并且MySQL同时宕机了。</p><ul><li>Client123使用了Eureka自带的renew机制，renew最基础的就是调一下Server的<code>/apps/{appName}/{instanceId}?status=&amp;lastDirtyTimestamp=</code>接口，正常情况下Client启动后的status为UP，所以只要Client自身服务不出问题，永远都是UP，默认的指示器是<code>CompositeHealthIndicator</code>，默认的管理器为<code>EurekaHealthCheckHandler</code>；</li><li>Client456通过扩展<code>HealthIndicator</code>接口和<code>HealthCheckHandler</code>接口，然后来自定义需要监控的内容</li></ul><h3 id="默认健康监控组件"><a class="markdownIt-Anchor" href="#默认健康监控组件"></a> 默认健康监控组件</h3><p>在类<code>DiscoveryClient#getHealthCheckHandler</code>方法中选择需要使用的健康管理器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> HealthCheckHandler <span class="title">getHealthCheckHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  HealthCheckHandler healthCheckHandler = <span class="keyword">this</span>.healthCheckHandlerRef.get();</span><br><span class="line">  <span class="keyword">if</span> (healthCheckHandler == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> != healthCheckHandlerProvider) &#123;</span><br><span class="line">      healthCheckHandler = healthCheckHandlerProvider.get();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">null</span> != healthCheckCallbackProvider) &#123;</span><br><span class="line">      healthCheckHandler = <span class="keyword">new</span> HealthCheckCallbackToHandlerBridge(healthCheckCallbackProvider.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == healthCheckHandler) &#123;</span><br><span class="line">      healthCheckHandler = <span class="keyword">new</span> HealthCheckCallbackToHandlerBridge(<span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.healthCheckHandlerRef.compareAndSet(<span class="keyword">null</span>, healthCheckHandler);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">this</span>.healthCheckHandlerRef.get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>方法调用流程图</strong></p><p><img src="/images/image-20200411021953543.png" alt="image-20200411021953543"></p><h3 id="自定义健康监控"><a class="markdownIt-Anchor" href="#自定义健康监控"></a> 自定义健康监控</h3><ol><li><p>自定义监控组件</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HealthPolicyBean</span> <span class="keyword"><span class="keyword">implements</span> <span class="type">InitializingBean</span></span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    @Resource</span><br><span class="line">    <span class="keyword">private</span> RedisTemplate&lt;<span class="keyword">String</span>, Object&gt; redisTemplate;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 调度线程池</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> ScheduledExecutorService scheduled = Executors.<span class="keyword">new</span><span class="type">ScheduledThreadPool</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数据库健康情况</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> boolean                 dbHealth    = <span class="literal">true</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Redis健康情况</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> boolean                 redisHealth = <span class="literal">true</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * MongoDB健康情况</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> boolean                 mongoHealth = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    <span class="keyword">public</span> void afterPropertiesSet() throws Exception &#123;</span><br><span class="line">    <span class="comment">// 创建调度器</span></span><br><span class="line">        ThreadPoolExecutor heartbeatExecutor = <span class="keyword">new</span> <span class="type">ThreadPoolExecutor</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, TimeUnit.SECONDS,</span><br><span class="line">                <span class="keyword">new</span> <span class="type">SynchronousQueue</span>&lt;&gt;(),</span><br><span class="line">                <span class="keyword">new</span> <span class="type">ThreadFactoryBuilder</span>().setNameFormat(<span class="string">"redis-HeartbeatExecutor-%d"</span>).setDaemon(<span class="literal">true</span>).build());</span><br><span class="line"></span><br><span class="line">        TimedSupervisorTask task = <span class="keyword">new</span> <span class="type">TimedSupervisorTask</span>(<span class="string">"redis-heartbeat"</span>, scheduled, heartbeatExecutor, <span class="number">10</span>,</span><br><span class="line">                TimeUnit.SECONDS, <span class="number">100</span>, <span class="keyword">new</span> <span class="type">RedisTimer</span>());</span><br><span class="line"></span><br><span class="line">        scheduled.schedule(task, <span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 监控Redis状态</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    protected <span class="class"><span class="keyword">class</span> <span class="title">RedisTimer</span> <span class="keyword"><span class="keyword">implements</span> <span class="type">Runnable</span></span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        <span class="keyword">public</span> void run() &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                List&lt;RedisClientInfo&gt; clientList = redisTemplate.getClientList();</span><br><span class="line">                <span class="keyword">if</span> (clientList == <span class="literal">null</span> || clientList.isEmpty()) &#123;</span><br><span class="line">                    HealthPolicyBean.redisHealth = <span class="literal">false</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    HealthPolicyBean.redisHealth = <span class="literal">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                HealthPolicyBean.redisHealth = <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>自定义HealthIndicator</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Cc健康指示器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CcHealthIndicator</span> <span class="keyword">implements</span> <span class="title">HealthIndicator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Health <span class="title">health</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (HealthPolicyBean.dbHealth &amp;&amp; HealthPolicyBean.redisHealth &amp;&amp; HealthPolicyBean.mongoHealth) &#123;</span><br><span class="line">          <span class="comment">// 当所有组件都正常时才返回UP</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Health.Builder(Status.UP).build();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Health.Builder(Status.DOWN).build();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>自定义HealthCheckHandler</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Cc健康管理器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CcHealthCheckHandler</span> <span class="keyword">implements</span> <span class="title">HealthCheckHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> CcHealthIndicator ccHealthIndicator;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> InstanceInfo.<span class="function">InstanceStatus <span class="title">getStatus</span><span class="params">(InstanceInfo.InstanceStatus currentStatus)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (ccHealthIndicator.health().getStatus().equals(Status.UP)) &#123;</span><br><span class="line">            <span class="keyword">return</span> InstanceInfo.InstanceStatus.UP;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> InstanceInfo.InstanceStatus.DOWN;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>方法调用流程图</strong></p><p><img src="/images/image-20200411021933621.png" alt="image-20200411021933621"></p></li></ol><h3 id="区别"><a class="markdownIt-Anchor" href="#区别"></a> 区别</h3><p>我们打开Redis服务，启动Eureka Server、Client123和Client456。</p><ul><li><p>Redis运行中</p><p>Redis正常运行时，两个服务都处于正常情况</p><p><img src="/images/image-20200411022923590.png" alt="image-20200411022923590"></p></li><li><p>Redis停止</p><p>将Redis服务停掉，等待一个renew周期后，服务状态发生变化，使用默认HealthCheckHandler的CUSER-SERVICE的status仍然为UP，而我们自定义HealthCheckHandler的EUREKA-HEALTH服务的status已经变成了DOWN，符合正常要求。</p><p><img src="/images/image-20200411023355326.png" alt="image-20200411023355326"></p></li></ul><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>在实际的生产工作中，尽量不要使用默认的HealthCheckHandler，不然就算是我们项目的MySQL、Redis、MongoDB、MQ都挂掉了，只要项目的进程还存活，那么status就很大的可能是UP，但实际上项目已经无法正常提供服务了，会给我们的项目带来很大的麻烦。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;注册中心的心跳机制有两种形式：客户端主动上报和客户端被动响应。Eureka属于是主动上报类型的，Client通过renew机制频繁的向Serve
      
    
    </summary>
    
    
      <category term="SpringBoot" scheme="http://luxiaowan.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringCloud" scheme="http://luxiaowan.github.io/tags/SpringCloud/"/>
    
      <category term="Eureka" scheme="http://luxiaowan.github.io/tags/Eureka/"/>
    
  </entry>
  
  <entry>
    <title>Eureka服务注册详解</title>
    <link href="http://luxiaowan.github.io/2020/04/10/Eureka%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E8%AF%A6%E8%A7%A3/"/>
    <id>http://luxiaowan.github.io/2020/04/10/Eureka服务注册详解/</id>
    <published>2020-04-10T03:00:00.000Z</published>
    <updated>2020-04-10T14:41:02.989Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>服务注册与发现是Spring Cloud Eureka的核心功能，首先我们需要一个Eureka Server，然后再来一个Eureka Client，那么Client的服务是怎么自动注册到Server的呢？我们都知道SpringBoot是约定大于配置的一个框架，自动配置是在启动的时候扫描/META-INF/spring.factories文件中EnableAutoConfiguration下的所有的*AutoConfiguration类，看一下eureka-client包下的spring.factories文件内容</p><p><img src="/images/image-20200410145122079.png" alt="image-20200410145122079"></p><p>我们主要关注两个类<code>EurekaClientAutoConfiguration</code>和<code>EurekaDiscoveryClientConfiguration</code></p><p>在类EurekaClientAutoConfiguration的定义上我们可以看到这个类是在<code>EurekaDiscoveryClientConfiguration</code>初始化完成之后再进行初始化的，这不是重点，重点来看<code>EurekaClientAutoConfiguration</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@AutoConfigureAfter</span>(name = &#123;</span><br><span class="line">  <span class="string">"org.springframework.cloud.autoconfigure.RefreshAutoConfiguration"</span>,</span><br><span class="line">  <span class="string">"org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration"</span>,</span><br><span class="line">  <span class="string">"org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationAutoConfiguration"</span> &#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EurekaClientAutoConfiguration</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="注册服务"><a class="markdownIt-Anchor" href="#注册服务"></a> 注册服务</h3><p>EurekaClientAutoConfiguration类的主要功能是配置EurekaClient。其中有个关键的内部类<code>RefreshableEurekaClientConfiguration</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span>(proxyBeanMethods = <span class="keyword">false</span>)</span><br><span class="line"><span class="meta">@ConditionalOnRefreshScope</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">RefreshableEurekaClientConfiguration</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="keyword">private</span> ApplicationContext context;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="keyword">private</span> AbstractDiscoveryClientOptionalArgs&lt;?&gt; optionalArgs;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Bean</span>(destroyMethod = <span class="string">"shutdown"</span>)</span><br><span class="line">  <span class="meta">@ConditionalOnMissingBean</span>(value = EurekaClient.class, search = SearchStrategy.CURRENT)</span><br><span class="line">  <span class="meta">@org</span>.springframework.cloud.context.config.annotation.RefreshScope</span><br><span class="line">  <span class="meta">@Lazy</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> EurekaClient <span class="title">eurekaClient</span><span class="params">(ApplicationInfoManager manager, EurekaClientConfig config, EurekaInstanceConfig instance, @Autowired(required = <span class="keyword">false</span>)</span> HealthCheckHandler healthCheckHandler) </span>&#123;</span><br><span class="line">    ApplicationInfoManager appManager;</span><br><span class="line">    <span class="keyword">if</span> (AopUtils.isAopProxy(manager)) &#123;</span><br><span class="line">      appManager = ProxyUtils.getTargetObject(manager);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      appManager = manager;</span><br><span class="line">    &#125;</span><br><span class="line">    CloudEurekaClient cloudEurekaClient = <span class="keyword">new</span> CloudEurekaClient(appManager, config, <span class="keyword">this</span>.optionalArgs, <span class="keyword">this</span>.context);</span><br><span class="line">    cloudEurekaClient.registerHealthCheck(healthCheckHandler);</span><br><span class="line">    <span class="keyword">return</span> cloudEurekaClient;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个类被<code>@ConditionalOnRefreshScope</code>标注了，因为在<code>spring-cloud-context</code>包的<code>spring.factories</code>中配置了RefreshAutoConfiguration，且<code>@ConditionalOnRefreshScope</code>的实例化取决于RefreshAutoConfiguration</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Target</span>(&#123; ElementType.TYPE, ElementType.METHOD &#125;)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@ConditionalOnClass</span>(RefreshScope.class)</span><br><span class="line"><span class="meta">@ConditionalOnBean</span>(RefreshAutoConfiguration.class)<span class="comment">// 重点</span></span><br><span class="line"><span class="meta">@ConditionalOnProperty</span>(value = <span class="string">"eureka.client.refresh.enable"</span>, havingValue = <span class="string">"true"</span>,</span><br><span class="line">                       matchIfMissing = <span class="keyword">true</span>)</span><br><span class="line"><span class="meta">@interface</span> ConditionalOnRefreshScope &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>既然<code>RefreshableEurekaClientConfiguration</code>类被实例化了，那么里面的<code>EurekaClient</code>也同样被实例化了，在<code>eurekaClient()</code>方法中返回的是<code>CloudEurekaClient</code>类的实例，那么关键就是这个类了。</p><img src="/images/image-20200410153201415.png" alt="image-20200410153201415" style="zoom: 56%;"><p><code>CloudEurekaClient</code>继承自<code>DiscoveryClient</code>，并且在构造器中是直接调了父类的构造器去处理具体逻辑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args,</span><br><span class="line">                    Provider&lt;BackupRegistry&gt; backupRegistryProvider, EndpointRandomizer endpointRandomizer) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 创建调度线程池，只给heartbeat和cacheRefresh使用，所以核心线程池为2即可</span></span><br><span class="line">    scheduler = Executors.newScheduledThreadPool(<span class="number">2</span>,</span><br><span class="line">                                                 <span class="keyword">new</span> ThreadFactoryBuilder()</span><br><span class="line">                                                 .setNameFormat(<span class="string">"DiscoveryClient-%d"</span>)</span><br><span class="line">                                                 .setDaemon(<span class="keyword">true</span>)</span><br><span class="line">                                                 .build());</span><br><span class="line"></span><br><span class="line">    heartbeatExecutor = <span class="keyword">new</span> ThreadPoolExecutor(</span><br><span class="line">      <span class="number">1</span>, clientConfig.getHeartbeatExecutorThreadPoolSize(), <span class="number">0</span>, TimeUnit.SECONDS,</span><br><span class="line">      <span class="keyword">new</span> SynchronousQueue&lt;Runnable&gt;(),</span><br><span class="line">      <span class="keyword">new</span> ThreadFactoryBuilder()</span><br><span class="line">      .setNameFormat(<span class="string">"DiscoveryClient-HeartbeatExecutor-%d"</span>)</span><br><span class="line">      .setDaemon(<span class="keyword">true</span>)</span><br><span class="line">      .build()</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    cacheRefreshExecutor = <span class="keyword">new</span> ThreadPoolExecutor(</span><br><span class="line">      <span class="number">1</span>, clientConfig.getCacheRefreshExecutorThreadPoolSize(), <span class="number">0</span>, TimeUnit.SECONDS,</span><br><span class="line">      <span class="keyword">new</span> SynchronousQueue&lt;Runnable&gt;(),</span><br><span class="line">      <span class="keyword">new</span> ThreadFactoryBuilder()</span><br><span class="line">      .setNameFormat(<span class="string">"DiscoveryClient-CacheRefreshExecutor-%d"</span>)</span><br><span class="line">      .setDaemon(<span class="keyword">true</span>)</span><br><span class="line">      .build()</span><br><span class="line">    );</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Failed to initialize DiscoveryClient!"</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 从远程获取所有的服务</span></span><br><span class="line">  <span class="keyword">if</span> (clientConfig.shouldFetchRegistry() &amp;&amp; !fetchRegistry(<span class="keyword">false</span>)) &#123;</span><br><span class="line">    fetchRegistryFromBackup();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 在所有后台任务启动之前调用并执行预注册处理程序</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.preRegistrationHandler != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">this</span>.preRegistrationHandler.beforeRegistration();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (clientConfig.shouldRegisterWithEureka() &amp;&amp; clientConfig.shouldEnforceRegistrationAtInit()) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (!register() ) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Registration error at startup. Invalid server response."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable th) &#123;</span><br><span class="line">      logger.error(<span class="string">"Registration error at startup: &#123;&#125;"</span>, th.getMessage());</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(th);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 初始化调度任务（cacheRefreshTask、heartbeatTask）</span></span><br><span class="line">  initScheduledTasks();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>DiscoveryClient</code>构造器中调用的最核心的两个方法是<code>fetchRegistry()</code>和<code>initScheduledTasks()</code>，<code>fetchRegistry()</code>方法中调用了<code>getAndStoreFullRegistry()</code>，最终在此方法中向Eureka Server发送了获取所有实例的请求</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getAndStoreFullRegistry</span><span class="params">()</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> currentUpdateGeneration = fetchRegistryGeneration.get();</span><br><span class="line"></span><br><span class="line">  Applications apps = <span class="keyword">null</span>;</span><br><span class="line">  EurekaHttpResponse&lt;Applications&gt; httpResponse = clientConfig.getRegistryRefreshSingleVipAddress() == <span class="keyword">null</span></span><br><span class="line">    ? eurekaTransport.queryClient.getApplications(remoteRegionsRef.get())</span><br><span class="line">    : eurekaTransport.queryClient.getVip(clientConfig.getRegistryRefreshSingleVipAddress(), remoteRegionsRef.get());</span><br><span class="line">  <span class="keyword">if</span> (httpResponse.getStatusCode() == Status.OK.getStatusCode()) &#123;</span><br><span class="line">    apps = httpResponse.getEntity();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>操作完成之后，调用<code>DiscoveryClient</code>的<code>initScheduledTasks()</code>方法，在这个方法中，注册两个定时任务，一个是以指定的时间间隔获取注册表信息的任务，另一个是在给定的时间间隔内更新租约的heartbeat任务，并且在任务都初始化完成之后调用<code>InstanceInfoReplicator#start</code>方法初始化一个注册远程服务的定时任务。类<code>InstanceInfoReplicator</code>实际上是一个线程，实现自Runnable接口，在他的run方法里调用了DiscoveryClient的register()方法通过REST调用向eureka服务注册。</p><ul><li><p>Eureka接口：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">POST</span>    <span class="string">/eureka/apps/&#123;appName&#125;</span>                                            <span class="string">注册新的实例</span> </span><br><span class="line"><span class="string">DELETE</span>  <span class="string">/eureka/apps/&#123;appName&#125;/&#123;instanceId&#125;</span>                               <span class="string">注销应用实例</span> </span><br><span class="line"><span class="string">PUT</span>     <span class="string">/eureka/apps/&#123;appName&#125;/&#123;instanceId&#125;</span>                               <span class="string">应用实例发送心跳</span> </span><br><span class="line"><span class="string">GET</span>     <span class="string">/eureka/apps</span>                                                    <span class="string">查询所有的实例</span> </span><br><span class="line"><span class="string">GET</span>     <span class="string">/eureka/apps/&#123;appName&#125;</span>                                            <span class="string">查询指定appId的实例</span> </span><br><span class="line"><span class="string">GET</span>     <span class="string">/eureka/apps/&#123;appName&#125;/&#123;instanceId&#125;</span>                               <span class="string">查询指定appId和instanceId的实例</span> </span><br><span class="line"><span class="string">GET</span>     <span class="string">/eureka/instances/&#123;instanceId&#125;</span>                                  <span class="string">查询指定的instanceId的实例</span> </span><br><span class="line"><span class="string">PUT</span>     <span class="string">/eureka/apps/&#123;appName&#125;/&#123;instanceId&#125;/status?value=OUT_OF_SERVICE</span>   <span class="string">暂停应用实例</span> </span><br><span class="line"><span class="string">PUT</span>     <span class="string">/eureka/apps/&#123;appName&#125;/&#123;instanceId&#125;/status?value=UP</span>               <span class="string">恢复应用实例</span> </span><br><span class="line"><span class="string">PUT</span>     <span class="string">/eureka/apps/&#123;appName&#125;/&#123;instanceId&#125;/metadata?key=value</span>            <span class="string">更新元数据信息</span> </span><br><span class="line"><span class="string">GET</span>     <span class="string">/eureka/vips/&#123;vipAddress&#125;</span>                                       <span class="string">根据vip地址查询</span> </span><br><span class="line"><span class="string">GET</span>     <span class="string">/eureka/svips/&#123;svipAddress&#125;</span>                                     <span class="string">根据svip地址查询</span></span><br></pre></td></tr></table></figure></li></ul><p>这些接口被定义在eureka-core.jar的<code>com.netflix.eureka.resources</code>包中</p><ul><li><p>Eureka核心类</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">InstanceInfo :              注册的服务实例,里面包含服务实例的各项属性</span><br><span class="line">LeaseInfo :                 <span class="type">Eureka</span>用这个类来标识应用实例的租约信息</span><br><span class="line">ServiceInstance :           发现的实例信息的抽象接口,约定了服务发现的实例应用有哪些通用信息</span><br><span class="line">InstanceStatus :            用于标识服务实例的状态,是一个枚举类,主要有状态<span class="type">UP</span>,DOWN,STARTING,OUT_OF_SERVICE,UNKNOWN</span><br><span class="line">EurekaServerConfigBean :    <span class="type">Eureka</span> Server的核心配置类，里面包含了Eureka Server的各项核心属性信息</span><br></pre></td></tr></table></figure></li></ul><h3 id="renew续约心跳"><a class="markdownIt-Anchor" href="#renew续约心跳"></a> renew续约心跳</h3><p>Eureka的续约需要每隔一段时间执行一次，目的是要告诉Eureka Server客户端还活着，以免Eureka Server将其当作是宕机的服务而剔除掉。</p><p>Client默认是每隔30秒发送一次renew请求，可以通过配置信息<code>eureka.instance.lease-renewal-interval-in-seconds</code>修改。</p><p>Server收到renew请求后，根据接收到的参数找到对应的实例，更新实例的续约时间，再将最新的续约时间同步到集群中的其他Server节点，最终完成续约。</p><p><img src="/images/eureka_renew.png" alt="eureka_renew"></p><p>Client端的续约定时任务是在实例化之后在<code>initScheduledTasks()</code>方法中被定义的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initScheduledTasks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (clientConfig.shouldRegisterWithEureka()) &#123;</span><br><span class="line">    <span class="keyword">int</span> renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs();</span><br><span class="line">    <span class="keyword">int</span> expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound();</span><br><span class="line">    logger.info(<span class="string">"Starting heartbeat executor: "</span> + <span class="string">"renew interval is: &#123;&#125;"</span>, renewalIntervalInSecs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建心跳实例</span></span><br><span class="line">    heartbeatTask = <span class="keyword">new</span> TimedSupervisorTask(</span><br><span class="line">      <span class="string">"heartbeat"</span>,</span><br><span class="line">      scheduler,</span><br><span class="line">      heartbeatExecutor,</span><br><span class="line">      renewalIntervalInSecs,</span><br><span class="line">      TimeUnit.SECONDS,</span><br><span class="line">      expBackOffBound,</span><br><span class="line">      <span class="keyword">new</span> HeartbeatThread()</span><br><span class="line">    );</span><br><span class="line">    scheduler.schedule(</span><br><span class="line">      heartbeatTask,</span><br><span class="line">      renewalIntervalInSecs, TimeUnit.SECONDS);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    logger.info(<span class="string">"Not registering with Eureka server per configuration"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码中可以看到心跳最终使用的是类<code>HeartbeatThread</code>，这个类实际上就是一个线程类，通过ScheduledExecutorService来执行：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">HeartbeatThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (renew()) &#123;</span><br><span class="line">      lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">renew</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 调用接口进行续约</span></span><br><span class="line">    httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, <span class="keyword">null</span>);</span><br><span class="line">    <span class="comment">// 若Server端返回服务不存在，则重新将服务注册到Server</span></span><br><span class="line">    <span class="keyword">if</span> (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) &#123;</span><br><span class="line">      REREGISTER_COUNTER.increment();</span><br><span class="line">      <span class="keyword">long</span> timestamp = instanceInfo.setIsDirtyWithTime();</span><br><span class="line">      <span class="keyword">boolean</span> success = register();</span><br><span class="line">      <span class="keyword">if</span> (success) &#123;</span><br><span class="line">        instanceInfo.unsetIsDirty(timestamp);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> success;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> httpResponse.getStatusCode() == Status.OK.getStatusCode();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Eureka Server根据Jersey框架实现HTTP请求，续约请求最终会被<code>com.netflix.eureka.resources.InstanceResource#renewLease</code>接口接收到，然后通过InstanceRegistry递交给PeerAwareInstanceRegistryImpl，最终递交给AbstractInstanceRegistry#renew处理具体的操作，经过一系列rule操作之后，最终调用Lease#renew完成对lastUpdateTimestamp的更新。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">renew</span><span class="params">(String appName, String id, <span class="keyword">boolean</span> isReplication)</span> </span>&#123;</span><br><span class="line">  RENEW.increment(isReplication);</span><br><span class="line">  Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(appName);</span><br><span class="line">  Lease&lt;InstanceInfo&gt; leaseToRenew = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (gMap != <span class="keyword">null</span>) &#123;</span><br><span class="line">    leaseToRenew = gMap.get(id);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (leaseToRenew == <span class="keyword">null</span>) &#123;</span><br><span class="line">    RENEW_NOT_FOUND.increment(isReplication);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    InstanceInfo instanceInfo = leaseToRenew.getHolder();</span><br><span class="line">    <span class="keyword">if</span> (instanceInfo != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// touchASGCache(instanceInfo.getASGName());</span></span><br><span class="line">      <span class="comment">// 匹配服务状态</span></span><br><span class="line">      InstanceStatus overriddenInstanceStatus = <span class="keyword">this</span>.getOverriddenInstanceStatus(instanceInfo, leaseToRenew, isReplication);</span><br><span class="line">      <span class="keyword">if</span> (overriddenInstanceStatus == InstanceStatus.UNKNOWN) &#123;</span><br><span class="line">        RENEW_NOT_FOUND.increment(isReplication);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!instanceInfo.getStatus().equals(overriddenInstanceStatus)) &#123;</span><br><span class="line">        instanceInfo.setStatusWithoutDirty(overriddenInstanceStatus);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    renewsLastMin.increment();</span><br><span class="line">    leaseToRenew.renew();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>续约操作成功完成后，会调用PeerAwareInstanceRegistryImpl#replicateToPeers方法通知其他Eureka节点</p><blockquote><p>renew控制：</p><p>eureka.instance.lease-renewal-interval-in-seconds=10#10秒renew一次，默认30秒</p><p>eureka.instance.lease-expiration-duration-in-senconds=80#如果80秒内未发送续约请求，则关闭该客户端，默认为90秒</p><p>lease-expiration-duration-in-senconds不宜过大，否则可能出现客户端已down，但还是会有流量转发给它；但是也不宜过小，不然客户端可能会因为出现网络抖动而被移除。大于lease-renewal-interval-in-seconds两三倍以上。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;服务注册与发现是Spring Cloud Eureka的核心功能，首先我们需要一个Eureka Server，然后再来一个Eureka Clie
      
    
    </summary>
    
    
      <category term="SpringBoot" scheme="http://luxiaowan.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringCloud" scheme="http://luxiaowan.github.io/tags/SpringCloud/"/>
    
      <category term="Eureka" scheme="http://luxiaowan.github.io/tags/Eureka/"/>
    
  </entry>
  
  <entry>
    <title>MySQL执行计划explain解析</title>
    <link href="http://luxiaowan.github.io/2020/04/10/MySQL%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92explain%E8%A7%A3%E6%9E%90/"/>
    <id>http://luxiaowan.github.io/2020/04/10/MySQL执行计划explain解析/</id>
    <published>2020-04-09T17:03:00.000Z</published>
    <updated>2020-04-09T17:22:58.427Z</updated>
    
    <content type="html"><![CDATA[<h3 id="用法"><a class="markdownIt-Anchor" href="#用法"></a> 用法</h3><p><code>explain table</code>或<code>explain EXTENDED table</code></p><h3 id="参数解释"><a class="markdownIt-Anchor" href="#参数解释"></a> 参数解释</h3><p><img src="/images/image-20200410010618626.png" alt="image-20200410010618626"></p><ul><li><p>id：select查询的序列号，可以当做是执行顺序</p><ul><li>id相同时，执行顺序由上至下</li><li>如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行</li><li>id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行</li></ul></li><li><p>select_type：查询中每个select子句的类型</p><ul><li><p>SIMPLE(简单SELECT,不使用UNION或子查询等)</p></li><li><p>PRIMARY(查询中若包含任何复杂的子部分,最外层的select被标记为PRIMARY)</p></li><li><p>UNION(UNION中的第二个或后面的SELECT语句)</p></li><li><p>DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询)</p></li><li><p>UNION RESULT(UNION的结果)</p></li><li><p>SUBQUERY(子查询中的第一个SELECT)</p></li><li><p>DEPENDENT SUBQUERY(子查询中的第一个SELECT，取决于外面的查询)</p></li><li><p>DERIVED(派生表的SELECT, FROM子句的子查询)</p></li><li><p>UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行)</p></li></ul></li><li><p>table：显示这一行的数据是关于哪张表的，有时不是真实的表名字,看到的是derivedx(x是个数字,我的理解是第几步执行的结果)</p></li><li><p>partitions：分区号</p></li><li><p>type：表示MySQL在表中找到所需行的方式，又称“访问类型”，常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）</p><ul><li>ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行</li><li>index：Full Index Scan，index与ALL区别为index类型只遍历索引树</li><li>range：只检索给定范围的行，使用一个索引来选择行</li><li>ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</li><li>eq_ref：类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件</li><li>const、system：当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用system</li><li>NULL：MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。</li></ul></li><li><p>possible_keys：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用</p><p>该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询</p></li><li><p>Key：显示MySQL实际决定使用的键（索引）</p><p>如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。</p></li><li><p>key_len：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的）</p><p><code>不损失精确性的情况下，长度越短越好</code></p></li><li><p>ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</p></li><li><p>rows：表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数</p></li><li><p>Extra：该列包含MySQL解决查询的详细信息,有以下几种情况：</p><ul><li><p>Using filesort</p><p>MySQL有两种方式可以生成有序的结果，通过排序操作或者使用索引，当Extra中出现了Using filesort 说明MySQL使用了后者，但注意虽然叫filesort但并不是说明就是用了文件来进行排序，只要可能排序都是在内存里完成的。大部分情况下利用索引排序更快，所以一般这时也要考虑优化查询了。使用文件完成排序操作，这是可能是ordery by，group by语句的结果，这可能是一个CPU密集型的过程，可以通过选择合适的索引来改进性能，用索引来为查询结果排序。</p></li><li><p>Using temporary</p><p>用临时表保存中间结果，常用于GROUP BY 和 ORDER BY操作中，一般看到它说明查询需要优化了，就算避免不了临时表的使用也要尽量避免硬盘临时表的使用。</p></li><li><p>Not exists</p><p>MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行， 就不再搜索了</p></li><li><p>Using index</p><p>说明查询是覆盖了索引的，不需要读取数据文件，从索引树（索引文件）中即可获得信息。如果同时出现using where，表明索引被用来执行索引键值的查找，没有using where，表明索引用来读取数据而非执行查找动作。这是MySQL服务层完成的，但无需再回表查询记录。</p></li><li><p>Using index condition</p><p>这是MySQL 5.6出来的新特性，叫做“索引条件推送”。简单说一点就是MySQL原来在索引上是不能执行如like这样的操作的，但是现在可以了，这样减少了不必要的IO操作，但是只能用在二级索引上。</p></li><li><p>Using where</p><p>使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。<strong>注意</strong>：Extra列出现Using where表示MySQL服务器将存储引擎返回服务层以后再应用WHERE条件过滤</p></li><li><p>Using join buffer</p><p>使用了连接缓存：Block Nested Loop，连接算法是块嵌套循环连接;Batched Key Access，连接算法是批量索引连接</p></li><li><p>impossible where</p><p>where子句的值总是false，不能用来获取任何元组</p></li><li><p>select tables optimized away</p><p>在没有GROUP BY子句的情况下，基于索引优化MIN/MAX操作，或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。</p></li><li><p>distinct</p><p>优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作</p></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;用法&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#用法&quot;&gt;&lt;/a&gt; 用法&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;explain table&lt;/code&gt;或&lt;code&gt;explain EXTENDED table&lt;/code&gt;&lt;/p&gt;
&lt;h3 i
      
    
    </summary>
    
    
      <category term="MySQL" scheme="http://luxiaowan.github.io/categories/MySQL/"/>
    
    
  </entry>
  
  <entry>
    <title>MySQL索引建立原则</title>
    <link href="http://luxiaowan.github.io/2020/04/10/MySQL%E7%B4%A2%E5%BC%95%E5%BB%BA%E7%AB%8B%E5%8E%9F%E5%88%99/"/>
    <id>http://luxiaowan.github.io/2020/04/10/MySQL索引建立原则/</id>
    <published>2020-04-09T16:50:00.000Z</published>
    <updated>2020-04-09T17:02:53.639Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h3><p>索引的目的是提升查询数据的效率，所以我们建索引的标准应该一切从提升查询效率为基准。</p><h3 id="小技巧"><a class="markdownIt-Anchor" href="#小技巧"></a> 小技巧</h3><ol><li><p>对于有唯一值的列尽量使用唯一索引</p></li><li><p>索引长度尽量小一点，长度小的索引可以节省索引空间，也会使查找的速度得到提升，因为索引页只有16k，索引列长度小的话，一页可以容纳更多的数据</p></li><li><p>太长的列可以选择部分内容做索引，遵循最左前缀原则</p></li><li><p>更新频繁的列不适合建索引</p></li><li><p>利用断桥原则（最左前缀原则），比如建立了一个联合索引(a,b,c)，那么其实我们可利用的索引就有(a), (a,b), (a,b,c)</p></li><li><p>不要过多创建索引，索引越多占用的空间越多，而且每次增、删、改操作都会重建索引，并且索引太多的话也会增加之后的优化复杂度</p></li><li><p>尽量扩展索引，比如现有索引(a)，现在我又要对(a,b)进行索引，不需要再建一个索引(a,b)，只需要在原索引(a)的基础上新增b列即可</p></li><li><p>一次查询是不能应用多个索引，即使你查询条件中有多个索引，最终也只会选择最优的一个</p><img src="/images/image-20200410005949806.png" alt="image-20200410005949806" style="zoom:67%;"></li><li><p>&lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN 可用到索引，&lt;&gt;，not in ，!= 则不行</p></li><li><p>like “xxxx%” 是可以用到索引的，like “%xxxx” 和 like “%xxx%” 则不行（但会用到索引下推）</p></li><li><p>NULL会使索引的效果大打折扣</p></li><li><p>索引列若出现函数或计算，则索引不会生效</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#前言&quot;&gt;&lt;/a&gt; 前言&lt;/h3&gt;
&lt;p&gt;索引的目的是提升查询数据的效率，所以我们建索引的标准应该一切从提升查询效率为基准。&lt;/p&gt;
&lt;h3 id=&quot;小技巧&quot;&gt;&lt;a class=&quot;mar
      
    
    </summary>
    
    
      <category term="MySQL" scheme="http://luxiaowan.github.io/categories/MySQL/"/>
    
    
      <category term="索引" scheme="http://luxiaowan.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>MySQL回表、索引覆盖、索引下推</title>
    <link href="http://luxiaowan.github.io/2020/04/09/MySQL%E5%9B%9E%E8%A1%A8%E3%80%81%E7%B4%A2%E5%BC%95%E8%A6%86%E7%9B%96%E3%80%81%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/"/>
    <id>http://luxiaowan.github.io/2020/04/09/MySQL回表、索引覆盖、索引下推/</id>
    <published>2020-04-09T13:01:00.000Z</published>
    <updated>2020-04-09T16:37:44.165Z</updated>
    
    <content type="html"><![CDATA[<h3 id="准备"><a class="markdownIt-Anchor" href="#准备"></a> 准备</h3><p>创建一张表，并创建一个自增主键索引和一个组合索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE index_opt_test (</span><br><span class="line">  id int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  name varchar(11) DEFAULT NULL,</span><br><span class="line">  title varchar(11) DEFAULT NULL,</span><br><span class="line">  age int(11) DEFAULT NULL,</span><br><span class="line">  sex varchar(11) DEFAULT NULL,</span><br><span class="line">  content varchar(500) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (id),</span><br><span class="line">  KEY idx_cb (name,title,age)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure><h3 id="回表"><a class="markdownIt-Anchor" href="#回表"></a> 回表</h3><ol><li><p>什么是回表</p><p>回表是发生在二级索引上的一种数据查询操作，简单点讲就是我们要查询的列不在二级索引的列中，那么就必须根据二级索引查到主键ID，然后再根据主键ID到聚簇索引树上去查询整行的数据，这一过程就叫作回表。</p></li><li><p>为什么会回表</p><p>写一个会回表查询的SQL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id, name, age, sex from index_opt_test where name=&apos;cc&apos; and title=&apos;T7&apos; and age=35;</span><br></pre></td></tr></table></figure><p>解析：</p><p>​SQL需要查询的列包括<code>id、name、age、sex</code>，查询条件命中索引<code>idx_cb</code>，其中列<code>id、name、age</code>都在索引<code>idx_cb</code>中可以获取到，但是<code>sex</code>不能通过索引获取到，必须要获取到整行数据之后再从结果中捞出来<code>sex</code>列的数据，这种情况就必须要回表。</p></li><li><p>什么情况下不需要回表</p><p>当所有的列都能在二级索引树中查询到，就不需要再回表了，这种情况就是索引覆盖。</p></li></ol><h3 id="索引覆盖"><a class="markdownIt-Anchor" href="#索引覆盖"></a> 索引覆盖</h3><ol><li><p>什么是索引覆盖</p><p>当SQL语句中查询的列都在索引中时，我们就不需要回表去把整行数据都捞出来了，可以从非聚簇索引树中直接获取到我们需要的列的数据，这就叫索引覆盖。简单点来讲就是：所有不需要回表的查询操作都叫索引覆盖。</p></li><li><p>为什么会发生索引覆盖</p><p>关于为什么会发生索引覆盖这个问题，通过一条SQL来理解：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id, name, age from index_opt_test where name=&apos;cc&apos; and title=&apos;T7&apos;;</span><br></pre></td></tr></table></figure><p>这条SQL要查询的列<code>id、name、age</code>全部都能从非聚簇索引<code>idx_cb</code>中直接查询出来，可能会有个疑问：我们的索引列是name、title和age，为什么id明明不在组合索引中却还能发生索引覆盖？提出这个问题的同学真的是欠我一顿小烧烤，非聚簇索引的叶子节点里存的是什么东西：主键的关键字啊，我们这里主键是id，他的关键字就是id的值啊，那我们通过非聚簇索引是不是可以直接将主键id查出来，是不是就不用再回表了，不用回表是不是就发生了索引覆盖啊，就是那么简单。</p></li></ol><h3 id="索引下推"><a class="markdownIt-Anchor" href="#索引下推"></a> 索引下推</h3><ol><li><p>什么是索引下推</p><p>索引下推又叫索引条件下推(Index Condition Pushdown，简称ICP)，ICP默认是开启的，使用ICP可以减少存储引擎访问基础表的次数和Server访问存储引擎的次数。</p><ul><li><p>ICP没有启用：Server层会根据索引的断桥原则将命中的索引字段推送到引擎层获取数据，并把匹配到的数据全部返回到Server层，由Server层再根据剩余的where条件进行过滤，即使where条件中有组合索引的其他未命中的字段，也会保留在Server层做筛选，然后返回给Client</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id, name, sex from index_opt_test where name=&apos;cc&apos; and title like &apos;%7&apos; and sex=&apos;male&apos;;</span><br></pre></td></tr></table></figure><p>执行过程：</p><ol><li>Server层把name推到引擎层</li><li>引擎层根据name去idx_cb的索引树中匹配主键</li><li>回表去捞数据返回给Server层</li><li>Server层再根据title、sex筛选出最终的数据</li><li>最后返回给客户端</li></ol><p><img src="/images/image-20200410003327016.png" alt="image-20200410003327016"></p></li><li><p>ICP启用：Server层会将where条件中在组合索引中的字段全部推送到引擎层，引擎层根据断桥原则匹配出索引数据，然后将其他索引字段带入再进行一次筛选，然后拿最终匹配的主键关键字回表查询出数据后返回给Server层，Server层再根据剩余的where条件做一次筛选，然后返回给Client</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id, name, sex from index_opt_test where name=&apos;cc&apos; and title like &apos;%7&apos; and sex=&apos;male&apos;;</span><br></pre></td></tr></table></figure><p>执行过程：</p><ol><li>Server把name和title都推到引擎层</li><li>引擎层根据name去idx_cb中查询出主键关键字和title、age</li><li>再由title筛选出匹配的主键关键字</li><li>回表去捞数据返回给Server层</li><li>Server层再根据sex筛选出最终的数据</li><li>再返回给客户端</li></ol><p><img src="/images/image-20200410003348304.png" alt="image-20200410003348304"></p></li></ul></li><li><p>索引下推适用条件</p><ul><li>ICP 用于访问方法是 <code>range/ref/eq_ref/ref_or_null</code>，且需要访问表的完整行记录。</li><li>ICP适用于 InnoDB 和 MyISAM 的表，包括分区的表。</li><li>对于 InnoDB 表，ICP只适用于二级索引。ICP 的目标是减少访问表的完整行的读数量从而减少 I/O 操作。对于 InnoDB 的聚簇索引，完整的记录已经读进 InnoDB 的缓存，使用 ICP 不能减少 I/O 。</li><li>ICP 不支持建立在虚拟列上的二级索引（InnoDB 支持在虚拟列上建立二级索引）。</li><li>引用子查询、存储函数的条件没法下推，Triggered conditions 也没法下推。</li></ul><p>所以ICP 适用的一个隐含前提是二级索引必须是组合索引、且在使用索引进行扫描时只能采用最左前缀匹配原则。组合索引后面的列出现在 where 条件里，因此可以先过滤索引元组、从而减少回表读的数量。</p></li><li><p>为什么会发生索引下推</p><p>索引下推在5.6版本加入的，默认开启，可以通过命令<code>SHOW VARIABLES like '%optimizer_switch%'</code>查看当前状态</p><img src="/images/image-20200410001946545.png" alt="image-20200410001946545" style="zoom: 50%;"><ul><li><p>关闭索引下推</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET optimizer_switch = &apos;index_condition_pushdown=off&apos;;</span><br></pre></td></tr></table></figure><p>执行之后查看一下状态：</p><img src="/images/image-20200410002144781.png" alt="image-20200410002144781" style="zoom:50%;"><p>然后我们执行一下SQL语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select id, name, sex from index_opt_test where name=&apos;cc&apos; and title like &apos;%7&apos; and sex=&apos;male&apos;;</span><br></pre></td></tr></table></figure><p><img src="/images/image-20200410002324446.png" alt="image-20200410002324446"></p><p>从执行计划我们可以看出当我们关闭索引下推后，Extra中的是<code>Using where</code></p></li><li><p>开启索引下推</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET optimizer_switch = &apos;index_condition_pushdown=on&apos;;</span><br></pre></td></tr></table></figure><p>执行之后查看一下状态：</p><img src="/images/image-20200410001946545.png" alt="image-20200410001946545" style="zoom: 50%;"><p>然后我们执行以下SQL语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select id, name, sex from index_opt_test where name=&apos;cc&apos; and title like &apos;%7&apos; and sex=&apos;male&apos;;</span><br></pre></td></tr></table></figure><p><img src="/images/image-20200410002808326.png" alt="image-20200410002808326"></p><p>从执行计划中看到使用了<code>Using index condition</code>和<code>Using where</code>，<code>Using index condition</code>说明ICP生效了，title被推到了引擎层，而<code>Using where</code>是因为where条件中的sex字段</p></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;准备&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#准备&quot;&gt;&lt;/a&gt; 准备&lt;/h3&gt;
&lt;p&gt;创建一张表，并创建一个自增主键索引和一个组合索引&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;
      
    
    </summary>
    
    
      <category term="MySQL" scheme="http://luxiaowan.github.io/categories/MySQL/"/>
    
    
      <category term="索引" scheme="http://luxiaowan.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>MySQL聚簇索引和非聚簇索引</title>
    <link href="http://luxiaowan.github.io/2020/04/09/MySQL%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E5%92%8C%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95/"/>
    <id>http://luxiaowan.github.io/2020/04/09/MySQL聚簇索引和非聚簇索引/</id>
    <published>2020-04-09T10:00:00.000Z</published>
    <updated>2020-04-09T12:20:19.744Z</updated>
    
    <content type="html"><![CDATA[<h3 id="聚簇索引"><a class="markdownIt-Anchor" href="#聚簇索引"></a> 聚簇索引</h3><p>聚簇索引是指叶子节点存储的是一整行记录，比如InnoDB的主键索引，主键和表数据存储在一起。聚簇索引并不是一种单独的索引类型，而是一种数据存储方式，因为一行数据不能同时存储在两个地方，所以一张表中只能有一个聚簇索引，因为一张表的数据存储顺序只能是一种，故只有InnoDB主键索引是聚簇索引。</p><p>聚簇索引的存放顺序和数据的物理存储顺序是一致的，即只要是索引是挨着的，那么对应的数据在磁盘上的存储位置一定也是挨着的。</p><p>这里有一个问题：如果我们不用自增的字段作为主键，而使用字符串的话，会有什么不妥的地方？我们来分析看下：</p><ul><li>自增主键：按照主键的值按顺序递增，也就是会一直往后添加数据，只需要分配新页就可以了，那么已经存储了数据的页就永远不会再分裂，物理地址则不需要变动</li><li>字符串：需要根据字符串的ASSIC码值进行计算所要存储的位置，这个过程中会引起已存储数据的物理地址发生变动，并且需要不断的进行页的分裂，带来的性能开销非常大</li></ul><h4 id="优势"><a class="markdownIt-Anchor" href="#优势"></a> 优势</h4><ol><li>可以一次性将相邻的数据加载到内存中，减少了磁盘IO次数</li><li>由于聚簇索引是将索引和数据存储在一起，那么我们找到索引位置的时候实际上就是找到了具体的数据，否则还要进行一次磁盘IO去将最终数据捞出来</li></ol><h4 id="劣势"><a class="markdownIt-Anchor" href="#劣势"></a> 劣势</h4><ol><li>插入速度严重依赖于插入顺序：如果使用的是非自增主键，则可能需要进行页的分裂，非常影响性能</li><li>主键更新代价大：更新一次主键，可能导致被更新的行发生移动，引起页的分裂，非常影响性能</li><li>二级索引查询需要再次根据主键索引回表查询整行数据，因为InnoDB的二级索引的叶子节点存储的是主键的值</li></ol><h3 id="非聚簇索引"><a class="markdownIt-Anchor" href="#非聚簇索引"></a> 非聚簇索引</h3><p>非聚簇索引的叶子节点存储的是主键值或行数据存储的物理位置，MyIsam甭管是主键还是非主键索引都是非聚簇索引索引，InnoDB的非主键索引用的也是非聚簇索引，但是这两种存储引擎的非主键索引的叶子节点存储的内容是不同的。</p><ul><li>InnoDB非聚簇索引：叶子节点存储的是主键关键字，当聚簇索引发生页分裂或移动时(主键关键字未变)，非聚簇索引不需要改变</li><li>MyIsam非聚簇索引：所有索引的叶子节点存储的都是行数据的物理磁盘存储地址，只要行数据发生位置移动时，会引起所有的索引发生改变</li></ul><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><ul><li><p>聚簇索引叶子节点存储的是行数据，非聚簇索引的叶子节点存储的是主键关键字或数据物理存储地址</p></li><li><p>InnoDB的主键索引是聚簇索引，InnoDB的二级索引和MyIsam的所有索引都是非聚簇索引</p></li><li><p>InnoDB非聚簇索引叶子节点存储的是主键关键字，MyIsam非聚簇索引叶子节点存储的是数据物理存储地址</p></li><li><p>聚簇索引尽量使用自增列，可以减少页分裂和行存储位置移动，提升性能</p></li></ul><p><img src="/images/image-20200409193050867.png" alt="image-20200409193050867"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;聚簇索引&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#聚簇索引&quot;&gt;&lt;/a&gt; 聚簇索引&lt;/h3&gt;
&lt;p&gt;聚簇索引是指叶子节点存储的是一整行记录，比如InnoDB的主键索引，主键和表数据存储在一起。聚簇索引并不是一种单独的索引类型，而是一
      
    
    </summary>
    
    
      <category term="MySQL" scheme="http://luxiaowan.github.io/categories/MySQL/"/>
    
    
      <category term="索引" scheme="http://luxiaowan.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>MySQL索引类型</title>
    <link href="http://luxiaowan.github.io/2020/04/09/MySQL%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B/"/>
    <id>http://luxiaowan.github.io/2020/04/09/MySQL索引类型/</id>
    <published>2020-04-09T07:49:49.544Z</published>
    <updated>2020-04-09T09:38:13.017Z</updated>
    
    <content type="html"><![CDATA[<h3 id="索引类型"><a class="markdownIt-Anchor" href="#索引类型"></a> 索引类型</h3><p>MySQL中我们常用的索引类型有五种：</p><ol><li>普通索引</li><li>唯一索引</li><li>主键索引</li><li>组合索引</li><li>全文索引</li></ol><p>创建表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `INDEX_TEST` (</span><br><span class="line">  `id` int(11) DEFAULT NULL,</span><br><span class="line">  `name` varchar(11) DEFAULT NULL,</span><br><span class="line">  `idno` varchar(11) DEFAULT NULL,</span><br><span class="line">  `age` int(11) DEFAULT NULL,</span><br><span class="line">  `sex` varchar(11) DEFAULT NULL,</span><br><span class="line">  `content` varchar(500) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure><h3 id="普通索引"><a class="markdownIt-Anchor" href="#普通索引"></a> 普通索引</h3><p>最基本的一种索引，没有任何限制，可以为null，可以重复，普通索引的目的就是为了加快对数据的访问速度，为那些常被用来作查询条件的字段创建一个索引</p><p>SQL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE INDEX_TEST ADD INDEX idx_normal(name);</span><br></pre></td></tr></table></figure><h3 id="唯一索引"><a class="markdownIt-Anchor" href="#唯一索引"></a> 唯一索引</h3><p>与普通索引类似，但是不同点在于被索引的字段的值不能重复，但是可以为null，比如身份证、员工编号等必须唯一的信息，被设置了唯一索引的字段在整张表中都不能重复</p><p>SQL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE INDEX_TEST ADD UNIQUE idx_unique(idno);</span><br></pre></td></tr></table></figure><h3 id="主键索引"><a class="markdownIt-Anchor" href="#主键索引"></a> 主键索引</h3><p>与唯一索引类似，但是不同点是字段值不能为null，一般一张表只能有一个主键。实际上每张表都要有一个主键字段，通常情况下我们都是在创建表的时候手动添加，如果一张InnoDB引擎的表未明确主键字段，那么InnoDB引擎会自动为表创建一个隐式的自增主键，所以最优的情况下，我们最好手动创建一个自增主键。</p><p>SQL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE INDEX_TEST ADD PRIMARY KEY idx_pk(id);</span><br></pre></td></tr></table></figure><p>创建索引的时候，索引名称可以不写。</p><h3 id="组合索引"><a class="markdownIt-Anchor" href="#组合索引"></a> 组合索引</h3><p>组合索引是创建一个包含表中多个字段的索引，组合索引的使用遵循&quot;断桥原则&quot;，也叫&quot;最左前缀原则&quot;，我们在使用组合索引的时候，会从第一个往后匹配，使用顺序影响不大，因为MySQL的优化器会进行再次优化，如果中间有断桥(漏掉了中间一个或多个字段)，则断桥左侧的字段才会被用到索引。</p><p>比如索引字段(a, b, c)，有以下情况：</p><ul><li><p>where a and c and b：索引字段全部命中</p><img src="/images/image-20200409172431883.png" alt="image-20200409172431883" style="zoom:50%;"></li><li><p>where a and c：索引命中a</p><img src="/images/image-20200409172638836.png" alt="image-20200409172638836" style="zoom:50%;"></li><li><p>where a and b：索引命中a、b</p><img src="/images/image-20200409172717610.png" alt="image-20200409172717610" style="zoom:50%;"></li><li><p>where b and c：索引未命中</p><img src="/images/image-20200409172802182.png" alt="image-20200409172802182" style="zoom:50%;"></li><li><p>where a and b order by c：索引字段全部命中</p><img src="/images/image-20200409172431883.png" alt="image-20200409172431883" style="zoom:50%;"></li></ul><p>SQL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE INDEX_TEST ADD INDEX idx_cb(age, sex);</span><br></pre></td></tr></table></figure><h3 id="全文索引"><a class="markdownIt-Anchor" href="#全文索引"></a> 全文索引</h3><p>主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多，因为建表的时候表中没有数据，而已经有了数据再创建的话，要将已存在的数据都先fulltext一下，所以慢。</p><p>SQL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE INDEX_TEST ADD FULLTEXT idx_fulltext(content);</span><br></pre></td></tr></table></figure><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>最终我们的表创建语句变成了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `index_test` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `name` varchar(11) DEFAULT NULL,</span><br><span class="line">  `age` int(11) DEFAULT NULL,</span><br><span class="line">  `sex` varchar(11) DEFAULT NULL,</span><br><span class="line">  `content` varchar(500) DEFAULT NULL,</span><br><span class="line">  `idno` varchar(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),# 主键索引</span><br><span class="line">  UNIQUE KEY `idx_unique` (`idno`),# 唯一索引</span><br><span class="line">  KEY `normal_index` (`name`),# 普通索引</span><br><span class="line">  KEY `idx_cb` (`age`,`sex`),# 组合索引</span><br><span class="line">  FULLTEXT KEY `idx_fulltext` (`content`)# 全文索引</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;索引类型&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#索引类型&quot;&gt;&lt;/a&gt; 索引类型&lt;/h3&gt;
&lt;p&gt;MySQL中我们常用的索引类型有五种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;普通索引&lt;/li&gt;
&lt;li&gt;唯一索引&lt;/li&gt;
&lt;li&gt;主键索引&lt;
      
    
    </summary>
    
    
      <category term="MySQL" scheme="http://luxiaowan.github.io/categories/MySQL/"/>
    
    
      <category term="索引" scheme="http://luxiaowan.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
</feed>
